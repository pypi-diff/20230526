# Comparing `tmp/tetragono-0.3.5-py3-none-any.whl.zip` & `tmp/tetragono-0.3.6-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,48 +1,48 @@
-Zip file size: 107046 bytes, number of entries: 46
--rw-r--r--  2.0 unx     1227 b- defN 23-Apr-01 11:56 tetragono/__init__.py
--rw-r--r--  2.0 unx     7329 b- defN 23-Apr-01 11:56 tetragono/abstract_lattice.py
--rw-r--r--  2.0 unx    15984 b- defN 23-Apr-01 11:56 tetragono/abstract_state.py
--rw-r--r--  2.0 unx     8264 b- defN 23-Apr-01 11:56 tetragono/common_toolkit.py
--rw-r--r--  2.0 unx     3757 b- defN 23-Apr-01 11:56 tetragono/conversion.py
--rw-r--r--  2.0 unx     7561 b- defN 23-Apr-01 11:56 tetragono/exact_state.py
--rw-r--r--  2.0 unx    26080 b- defN 23-Apr-01 11:56 tetragono/shell.py
--rw-r--r--  2.0 unx    35546 b- defN 23-Apr-01 11:56 tetragono/simple_update_lattice.py
--rw-r--r--  2.0 unx     3985 b- defN 23-Apr-01 11:56 tetragono/tensor_element.py
--rw-r--r--  2.0 unx      893 b- defN 23-Apr-01 11:56 tetragono/ansatz_product_state/__init__.py
--rw-r--r--  2.0 unx    13309 b- defN 23-Apr-01 11:56 tetragono/ansatz_product_state/gradient.py
--rw-r--r--  2.0 unx    24023 b- defN 23-Apr-01 11:56 tetragono/ansatz_product_state/observer.py
--rw-r--r--  2.0 unx    10305 b- defN 23-Apr-01 11:56 tetragono/ansatz_product_state/sampling.py
--rw-r--r--  2.0 unx     7583 b- defN 23-Apr-01 11:56 tetragono/ansatz_product_state/state.py
--rw-r--r--  2.0 unx     1637 b- defN 23-Apr-01 11:56 tetragono/ansatz_product_state/ansatzes/__init__.py
--rw-r--r--  2.0 unx     7838 b- defN 23-Apr-01 11:56 tetragono/ansatz_product_state/ansatzes/abstract_ansatz.py
--rw-r--r--  2.0 unx     7510 b- defN 23-Apr-01 11:56 tetragono/ansatz_product_state/ansatzes/closed_string.py
--rw-r--r--  2.0 unx     5321 b- defN 23-Apr-01 11:56 tetragono/ansatz_product_state/ansatzes/convolutional_neural.py
--rw-r--r--  2.0 unx     2134 b- defN 23-Apr-01 11:56 tetragono/ansatz_product_state/ansatzes/marshall.py
--rw-r--r--  2.0 unx     7560 b- defN 23-Apr-01 11:56 tetragono/ansatz_product_state/ansatzes/open_string.py
--rw-r--r--  2.0 unx     6634 b- defN 23-Apr-01 11:56 tetragono/ansatz_product_state/ansatzes/product_ansatz.py
--rw-r--r--  2.0 unx     6596 b- defN 23-Apr-01 11:56 tetragono/ansatz_product_state/ansatzes/sum_ansatz.py
--rw-r--r--  2.0 unx      911 b- defN 23-Apr-01 11:56 tetragono/auxiliaries/__init__.py
--rw-r--r--  2.0 unx    33568 b- defN 23-Apr-01 11:56 tetragono/auxiliaries/double_layer_auxiliaries.py
--rw-r--r--  2.0 unx    43009 b- defN 23-Apr-01 11:56 tetragono/auxiliaries/single_layer_auxiliaries.py
--rw-r--r--  2.0 unx     7828 b- defN 23-Apr-01 11:56 tetragono/auxiliaries/three_line_auxiliaries.py
--rw-r--r--  2.0 unx     1288 b- defN 23-Apr-01 11:56 tetragono/common_tensor/Fermi.py
--rw-r--r--  2.0 unx     2603 b- defN 23-Apr-01 11:56 tetragono/common_tensor/FermiU1_tJ.py
--rw-r--r--  2.0 unx     2386 b- defN 23-Apr-01 11:56 tetragono/common_tensor/Fermi_Hubbard.py
--rw-r--r--  2.0 unx     1638 b- defN 23-Apr-01 11:56 tetragono/common_tensor/No.py
--rw-r--r--  2.0 unx     1411 b- defN 23-Apr-01 11:56 tetragono/common_tensor/Parity.py
--rw-r--r--  2.0 unx     2382 b- defN 23-Apr-01 11:56 tetragono/common_tensor/Parity_Hubbard.py
--rw-r--r--  2.0 unx      872 b- defN 23-Apr-01 11:56 tetragono/common_tensor/__init__.py
--rw-r--r--  2.0 unx     1506 b- defN 23-Apr-01 11:56 tetragono/common_tensor/tensor_toolkit.py
--rw-r--r--  2.0 unx      884 b- defN 23-Apr-01 11:56 tetragono/sampling_lattice/__init__.py
--rw-r--r--  2.0 unx    14463 b- defN 23-Apr-01 11:56 tetragono/sampling_lattice/gradient.py
--rw-r--r--  2.0 unx    32329 b- defN 23-Apr-01 11:56 tetragono/sampling_lattice/lattice.py
--rw-r--r--  2.0 unx    34709 b- defN 23-Apr-01 11:56 tetragono/sampling_lattice/observer.py
--rw-r--r--  2.0 unx    15311 b- defN 23-Apr-01 11:56 tetragono/sampling_lattice/sampling.py
--rw-r--r--  2.0 unx      731 b- defN 23-Apr-01 11:56 tetragono/sampling_lattice/squash/__init__.py
--rw-r--r--  2.0 unx     6063 b- defN 23-Apr-01 11:56 tetragono/sampling_lattice/squash/horizontal.py
--rw-r--r--  2.0 unx     6088 b- defN 23-Apr-01 11:56 tetragono/sampling_lattice/squash/vertical.py
--rw-r--r--  2.0 unx      644 b- defN 23-Apr-01 11:56 tetragono-0.3.5.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-01 11:56 tetragono-0.3.5.dist-info/WHEEL
--rw-r--r--  2.0 unx       10 b- defN 23-Apr-01 11:56 tetragono-0.3.5.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     4378 b- defN 23-Apr-01 11:56 tetragono-0.3.5.dist-info/RECORD
-46 files, 426180 bytes uncompressed, 99912 bytes compressed:  76.6%
+Zip file size: 107827 bytes, number of entries: 46
+-rw-r--r--  2.0 unx     1227 b- defN 23-May-26 16:06 tetragono/__init__.py
+-rw-r--r--  2.0 unx     7329 b- defN 23-May-26 16:06 tetragono/abstract_lattice.py
+-rw-r--r--  2.0 unx    15984 b- defN 23-May-26 16:06 tetragono/abstract_state.py
+-rw-r--r--  2.0 unx     8264 b- defN 23-May-26 16:06 tetragono/common_toolkit.py
+-rw-r--r--  2.0 unx     3757 b- defN 23-May-26 16:06 tetragono/conversion.py
+-rw-r--r--  2.0 unx     7674 b- defN 23-May-26 16:06 tetragono/exact_state.py
+-rw-r--r--  2.0 unx    22956 b- defN 23-May-26 16:06 tetragono/shell.py
+-rw-r--r--  2.0 unx    35857 b- defN 23-May-26 16:06 tetragono/simple_update_lattice.py
+-rw-r--r--  2.0 unx     3985 b- defN 23-May-26 16:06 tetragono/tensor_element.py
+-rw-r--r--  2.0 unx      893 b- defN 23-May-26 16:06 tetragono/ansatz_product_state/__init__.py
+-rw-r--r--  2.0 unx    13383 b- defN 23-May-26 16:06 tetragono/ansatz_product_state/gradient.py
+-rw-r--r--  2.0 unx    24064 b- defN 23-May-26 16:06 tetragono/ansatz_product_state/observer.py
+-rw-r--r--  2.0 unx    10305 b- defN 23-May-26 16:06 tetragono/ansatz_product_state/sampling.py
+-rw-r--r--  2.0 unx     7554 b- defN 23-May-26 16:06 tetragono/ansatz_product_state/state.py
+-rw-r--r--  2.0 unx     1637 b- defN 23-May-26 16:06 tetragono/ansatz_product_state/ansatzes/__init__.py
+-rw-r--r--  2.0 unx     7838 b- defN 23-May-26 16:06 tetragono/ansatz_product_state/ansatzes/abstract_ansatz.py
+-rw-r--r--  2.0 unx     7510 b- defN 23-May-26 16:06 tetragono/ansatz_product_state/ansatzes/closed_string.py
+-rw-r--r--  2.0 unx     5321 b- defN 23-May-26 16:06 tetragono/ansatz_product_state/ansatzes/convolutional_neural.py
+-rw-r--r--  2.0 unx     2134 b- defN 23-May-26 16:06 tetragono/ansatz_product_state/ansatzes/marshall.py
+-rw-r--r--  2.0 unx     7560 b- defN 23-May-26 16:06 tetragono/ansatz_product_state/ansatzes/open_string.py
+-rw-r--r--  2.0 unx     6634 b- defN 23-May-26 16:06 tetragono/ansatz_product_state/ansatzes/product_ansatz.py
+-rw-r--r--  2.0 unx     6596 b- defN 23-May-26 16:06 tetragono/ansatz_product_state/ansatzes/sum_ansatz.py
+-rw-r--r--  2.0 unx      911 b- defN 23-May-26 16:06 tetragono/auxiliaries/__init__.py
+-rw-r--r--  2.0 unx    34048 b- defN 23-May-26 16:06 tetragono/auxiliaries/double_layer_auxiliaries.py
+-rw-r--r--  2.0 unx    43009 b- defN 23-May-26 16:06 tetragono/auxiliaries/single_layer_auxiliaries.py
+-rw-r--r--  2.0 unx     7828 b- defN 23-May-26 16:06 tetragono/auxiliaries/three_line_auxiliaries.py
+-rw-r--r--  2.0 unx     1300 b- defN 23-May-26 16:06 tetragono/common_tensor/Fermi.py
+-rw-r--r--  2.0 unx     2627 b- defN 23-May-26 16:06 tetragono/common_tensor/FermiU1_tJ.py
+-rw-r--r--  2.0 unx     2386 b- defN 23-May-26 16:06 tetragono/common_tensor/Fermi_Hubbard.py
+-rw-r--r--  2.0 unx     1638 b- defN 23-May-26 16:06 tetragono/common_tensor/No.py
+-rw-r--r--  2.0 unx     1423 b- defN 23-May-26 16:06 tetragono/common_tensor/Parity.py
+-rw-r--r--  2.0 unx     2382 b- defN 23-May-26 16:06 tetragono/common_tensor/Parity_Hubbard.py
+-rw-r--r--  2.0 unx      872 b- defN 23-May-26 16:06 tetragono/common_tensor/__init__.py
+-rw-r--r--  2.0 unx     1506 b- defN 23-May-26 16:06 tetragono/common_tensor/tensor_toolkit.py
+-rw-r--r--  2.0 unx      884 b- defN 23-May-26 16:06 tetragono/sampling_lattice/__init__.py
+-rw-r--r--  2.0 unx    14658 b- defN 23-May-26 16:06 tetragono/sampling_lattice/gradient.py
+-rw-r--r--  2.0 unx    35897 b- defN 23-May-26 16:06 tetragono/sampling_lattice/lattice.py
+-rw-r--r--  2.0 unx    35361 b- defN 23-May-26 16:06 tetragono/sampling_lattice/observer.py
+-rw-r--r--  2.0 unx    15472 b- defN 23-May-26 16:06 tetragono/sampling_lattice/sampling.py
+-rw-r--r--  2.0 unx      731 b- defN 23-May-26 16:06 tetragono/sampling_lattice/squash/__init__.py
+-rw-r--r--  2.0 unx     6063 b- defN 23-May-26 16:06 tetragono/sampling_lattice/squash/horizontal.py
+-rw-r--r--  2.0 unx     6088 b- defN 23-May-26 16:06 tetragono/sampling_lattice/squash/vertical.py
+-rw-r--r--  2.0 unx      624 b- defN 23-May-26 16:06 tetragono-0.3.6.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-26 16:06 tetragono-0.3.6.dist-info/WHEEL
+-rw-r--r--  2.0 unx       10 b- defN 23-May-26 16:06 tetragono-0.3.6.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     4378 b- defN 23-May-26 16:06 tetragono-0.3.6.dist-info/RECORD
+46 files, 428650 bytes uncompressed, 100693 bytes compressed:  76.5%
```

## zipnote {}

```diff
@@ -120,20 +120,20 @@
 
 Filename: tetragono/sampling_lattice/squash/horizontal.py
 Comment: 
 
 Filename: tetragono/sampling_lattice/squash/vertical.py
 Comment: 
 
-Filename: tetragono-0.3.5.dist-info/METADATA
+Filename: tetragono-0.3.6.dist-info/METADATA
 Comment: 
 
-Filename: tetragono-0.3.5.dist-info/WHEEL
+Filename: tetragono-0.3.6.dist-info/WHEEL
 Comment: 
 
-Filename: tetragono-0.3.5.dist-info/top_level.txt
+Filename: tetragono-0.3.6.dist-info/top_level.txt
 Comment: 
 
-Filename: tetragono-0.3.5.dist-info/RECORD
+Filename: tetragono-0.3.6.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## tetragono/exact_state.py

```diff
@@ -82,15 +82,17 @@
             The state vector
         """
         names = [
             f"P_{l1}_{l2}_{orbit}" for l1 in range(self.L1) for l2 in range(self.L2)
             for orbit in sorted(self.physics_edges[l1, l2])
         ]
         edges = [
-            self.physics_edges[l1, l2, orbit] for l1 in range(self.L1) for l2 in range(self.L2)
+            self.physics_edges[l1, l2, orbit]
+            for l1 in range(self.L1)
+            for l2 in range(self.L2)
             for orbit in sorted(self.physics_edges[l1, l2])
         ]
         names.append("T")
         edges.append(self._total_symmetry_edge)
         vector = self.Tensor(names, edges).randn()
         vector /= vector.norm_2()
         return vector
@@ -125,15 +127,17 @@
             # v <- a v - H v = (a - H) v => E = a - |v'|/|v|
             # temporary_vector: H v
             temporary_vector = self.vector.same_shape().zero()
             for positions, value in self.hamiltonians:
                 # H v = sum_i H_i v
                 temporary_vector += (
                     value  #
-                    .edge_rename({f"O{t}": f"P_{i}_{j}_{orbit}" for t, [i, j, orbit] in enumerate(positions)})  #
+                    .edge_rename({
+                        f"O{t}": f"P_{i}_{j}_{orbit}" for t, [i, j, orbit] in enumerate(positions)
+                    })  #
                     .contract(self.vector,
                               {(f"I{t}", f"P_{i}_{j}_{orbit}") for t, [i, j, orbit] in enumerate(positions)}))
             # To calculate a v - H v => v *= a; v -= H v
             self.vector *= total_approximate_energy
             self.vector -= temporary_vector
 
             # Get the new norm, original norm should be set as 1.
@@ -172,21 +176,22 @@
         if len(positions) == 0:
             result = self.vector
         else:
             positions = [position if len(position) == 3 else (position[0], position[1], 0) for position in positions]
             result = (
                 self.vector  #
                 .contract(
-                    observer.edge_rename(
-                        {f"O{t}": f"P_{l1}_{l2}_{orbit}" for t, [l1, l2, orbit] in enumerate(positions)}),
-                    {(f"P_{l1}_{l2}_{orbit}", f"I{t}") for t, [l1, l2, orbit] in enumerate(positions)}))
+                    observer.edge_rename({
+                        f"O{t}": f"P_{l1}_{l2}_{orbit}" for t, [l1, l2, orbit] in enumerate(positions)
+                    }), {(f"P_{l1}_{l2}_{orbit}", f"I{t}") for t, [l1, l2, orbit] in enumerate(positions)}))
         result = (
             result  #
             .contract(
-                self.vector.conjugate(), {(f"P_{l1}_{l2}_{orbit}", f"P_{l1}_{l2}_{orbit}") for l1 in range(self.L1)
+                self.vector.conjugate(), {(f"P_{l1}_{l2}_{orbit}", f"P_{l1}_{l2}_{orbit}")
+                                          for l1 in range(self.L1)
                                           for l2 in range(self.L2)
                                           for orbit in self.physics_edges[l1, l2]} | {("T", "T")}))
         return complex(result).real
 
     def observe_energy(self):
         """
         Observe the energy per site.
```

## tetragono/shell.py

```diff
@@ -60,24 +60,43 @@
                 k, v = arg.split("=")
                 self.kwargs[k] = self._parse(v)
             else:
                 v = self._parse(arg)
                 self.args.append(v)
 
 
-def sharedoc(func_with_doc):
+class AutoCmdMeta(type):
 
-    def decorator(func_without_doc):
-        func_without_doc.__doc__ = func_with_doc.__doc__
-        return func_without_doc
+    def _auto_func_generator(name, doc):
 
-    return decorator
+        def _auto_func(self, line):
+            config = Config(line)
+            getattr(self, name)(*config.args, **config.kwargs)
 
+        _auto_func.__doc__ = doc
+        return _auto_func
 
-class TetragonoCommandApp(cmd.Cmd):
+    def __new__(cls, name, bases, attrs):
+        auto_attrs = {}
+        for key, value in attrs.items():
+            if hasattr(value, "_auto_cmd_meta_mark"):
+                auto_attrs[f"do_{key}"] = cls._auto_func_generator(key, value.__doc__)
+
+        return type.__new__(cls, name, bases, attrs | auto_attrs)
+
+
+class AutoCmd(cmd.Cmd, metaclass=AutoCmdMeta):
+
+    @staticmethod
+    def decorator(function):
+        function._auto_cmd_meta_mark = None
+        return function
+
+
+class TetragonoCommandApp(AutoCmd):
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self.prompt = "TET> "
         self.stored_line = ""
         self.license = """
 Copyright (C) 2019-2023 Hao Zhang<zh970205@mail.ustc.edu.cn>
@@ -131,80 +150,68 @@
 
     def do_quit(self, line):
         """
         Exit tetra shell.
         """
         return True
 
-    def do_seed(self, line):
+    @AutoCmd.decorator
+    def seed(self, random_seed):
         """
         Set random seed.
 
         Parameters
         ----------
         random_seed : int
             The new random seed.
         """
-        config = Config(line)
-        self.seed(*config.args, **config.kwargs)
-
-    @sharedoc(do_seed)
-    def seed(self, random_seed):
         TAT.random.seed(random_seed)
 
     @staticmethod
     def ex_ap_create(lattice_type, model_name, *args, **kwargs):
         abstract_state = get_imported_function(model_name, "abstract_state")
         if len(args) == 1 and args[0] == "help":
             showln(abstract_state.__doc__.replace("\n", "\n    "))
             return None
         else:
             state = lattice_type(abstract_state(*args, **kwargs))
         return state
 
-    def do_numpy_hamiltonian(self, line):
+    @AutoCmd.decorator
+    def numpy_hamiltonian(self, file, model, *args, **kwargs):
         """
         Export hamiltonian as a numpy array to a file.
 
         Parameters
         ----------
-        file : str
+        file : str | None
             The file that the hamiltonian is exported to.
         model : str
             The model names.
         args, kwargs
             Arguments passed to model creater function.
         """
-        config = Config(line)
-        self.numpy_hamiltonian(*config.args, **config.kwargs)
-
-    @sharedoc(do_numpy_hamiltonian)
-    def numpy_hamiltonian(self, file, model, *args, **kwargs):
         state = self.ex_ap_create(lambda x: x, model, *args, **kwargs)
         result = state.numpy_hamiltonian()
-        if result is not None:
+        if result is not None and file is not None:
             write_to_file(result, file)
         return result
 
-    def do_ex_create(self, line):
+    @AutoCmd.decorator
+    def ex_create(self, *args, **kwargs):
         """
         Create a state used for exact update.
 
         Parameters
         ----------
         model : str
             The model names.
         args, kwargs
             Arguments passed to model creater function.
         """
-        config = Config(line)
-        self.ex_create(*config.args, **config.kwargs)
-
-    @sharedoc(do_ex_create)
-    def ex_create(self, *args, **kwargs):
         state = self.ex_ap_create(ExactState, *args, **kwargs)
         if state is not None:
             self.ex = state
 
     @staticmethod
     def su_gm_create(lattice_type, model_name, *args, **kwargs):
         abstract_lattice = get_imported_function(model_name, "abstract_lattice")
@@ -215,594 +222,487 @@
             state = lattice_type(abstract_lattice(*args, **kwargs))
 
         # pre normalize the tensor
         for l1, l2 in state.sites():
             state[l1, l2] /= state[l1, l2].norm_max()
         return state
 
-    def do_su_create(self, line):
+    @AutoCmd.decorator
+    def su_create(self, *args, **kwargs):
         """
         Create a lattice used for simple update.
 
         Parameters
         ----------
         model : str
             The model names.
         args, kwargs
             Arguments passed to model creater function.
         """
-        config = Config(line)
-        self.su_create(*config.args, **config.kwargs)
-
-    @sharedoc(do_su_create)
-    def su_create(self, *args, **kwargs):
         state = self.su_gm_create(SimpleUpdateLattice, *args, **kwargs)
         if state is not None:
             self.su = state
 
-    def do_su_dump(self, line):
+    @AutoCmd.decorator
+    def su_dump(self, name):
         """
         Dump the simple update lattice into file.
 
         Parameters
         ----------
         name : str
             The file name.
         """
-        config = Config(line)
-        self.su_dump(*config.args, **config.kwargs)
-
-    @sharedoc(do_su_dump)
-    def su_dump(self, name):
-        write_to_file(self.su, name)
+        if self.su is None:
+            showln("su is None")
+        else:
+            write_to_file(self.su, name)
 
-    def do_su_load(self, line):
+    @AutoCmd.decorator
+    def su_load(self, name):
         """
         Load the simple update lattice from file.
 
         Parameters
         ----------
         name : str
             The file name.
         """
-        config = Config(line)
-        self.su_load(*config.args, **config.kwargs)
-
-    @sharedoc(do_su_load)
-    def su_load(self, name):
         self.su = read_from_file(name)
 
-    def do_su_update(self, line):
+    @AutoCmd.decorator
+    def su_update(self, total_step, delta_tau, new_dimension):
         """
         Do simple update.
 
         Parameters
         ----------
         total_step : int
             The simple update total step to do.
         delta_tau : float
             The imaginary time, delta tau.
         new_dimension : int
             The new cut dimension used in simple update, or the amplitude of dimension expandance.
         """
-        config = Config(line)
-        self.su_update(*config.args, **config.kwargs)
-
-    @sharedoc(do_su_update)
-    def su_update(self, total_step, delta_tau, new_dimension):
         self.su.update(total_step, delta_tau, new_dimension)
 
-    def do_su_energy(self, line):
+    @AutoCmd.decorator
+    def su_energy(self, cut_dimension):
         """
         Calculate simple update lattice with double layer auxiliaries.
 
         Parameters
         ----------
         cut_dimension : int
             The cut_dimension used in double layer auxiliaries.
         """
-        config = Config(line)
-        self.su_energy(*config.args, **config.kwargs)
-
-    @sharedoc(do_su_energy)
-    def su_energy(self, cut_dimension):
         self.su.initialize_auxiliaries(cut_dimension)
         showln("Simple update lattice energy is", self.su.observe_energy())
 
-    def do_su_to_ex(self, line):
+    @AutoCmd.decorator
+    def su_to_ex(self):
         """
         Convert simple update lattice to exact lattice.
         """
-        config = Config(line)
-        self.su_to_ex(*config.args, **config.kwargs)
-
-    @sharedoc(do_su_to_ex)
-    def su_to_ex(self):
         self.ex = conversion.simple_update_lattice_to_exact_state(self.su)
 
-    def do_su_to_gm(self, line):
+    @AutoCmd.decorator
+    def su_to_gm(self):
         """
         Convert simple update lattice to sampling lattice.
         """
-        config = Config(line)
-        self.su_to_gm(*config.args, **config.kwargs)
-
-    @sharedoc(do_su_to_gm)
-    def su_to_gm(self):
         self.gm = conversion.simple_update_lattice_to_sampling_lattice(self.su)
 
-    def do_ex_update(self, line):
+    @AutoCmd.decorator
+    def ex_update(self, total_step, approximate_energy):
         """
         Do exact update.
 
         Parameters
         ----------
         total_step : int
             The update total step to do.
         approximate_energy : float
             The approximate energy per site, it should ensure the ground state energy is the largest after shifting.
         """
-        config = Config(line)
-        self.ex_update(*config.args, **config.kwargs)
-
-    @sharedoc(do_ex_update)
-    def ex_update(self, total_step, approximate_energy):
         self.ex.update(total_step, approximate_energy)
 
-    def do_ex_energy(self, line):
+    @AutoCmd.decorator
+    def ex_energy(self):
         """
         Calculate exact energy.
         """
-        config = Config(line)
-        self.ex_energy(*config.args, **config.kwargs)
-
-    @sharedoc(do_ex_energy)
-    def ex_energy(self):
         showln("Exact state energy is", self.ex.observe_energy())
 
-    def do_ex_dump(self, line):
+    @AutoCmd.decorator
+    def ex_dump(self, name):
         """
         Dump the exact update lattice into file.
 
         Parameters
         ----------
         name : str
             The file name.
         """
-        config = Config(line)
-        self.ex_dump(*config.args, **config.kwargs)
-
-    @sharedoc(do_ex_dump)
-    def ex_dump(self, name):
-        write_to_file(self.ex, name)
+        if self.ex is None:
+            showln("ex is None")
+        else:
+            write_to_file(self.ex, name)
 
-    def do_ex_load(self, line):
+    @AutoCmd.decorator
+    def ex_load(self, name):
         """
         Load the exact update lattice from file.
 
         Parameters
         ----------
         name : str
             The file name.
         """
-        config = Config(line)
-        self.ex_load(*config.args, **config.kwargs)
-
-    @sharedoc(do_ex_load)
-    def ex_load(self, name):
         self.ex = read_from_file(name)
 
-    def do_gm_create(self, line):
+    @AutoCmd.decorator
+    def gm_create(self, *args, **kwargs):
         """
         Create a lattice used for gradient method.
 
         Parameters
         ----------
         model : str
             The model names.
         args, kwargs
             Arguments passed to model creater function.
         """
-        config = Config(line)
-        self.gm_create(*config.args, **config.kwargs)
-
-    @sharedoc(do_gm_create)
-    def gm_create(self, *args, **kwargs):
         state = self.su_gm_create(SamplingLattice, *args, **kwargs)
         if state is not None:
             self.gm = state
 
-    def do_gm_run(self, line):
+    @AutoCmd.decorator
+    def gm_run(self, *args, **kwargs):
         """
         Do gradient descent. see sampling_lattice/gradient.py for details.
         """
-        config = Config(line)
-        self.gm_run(*config.args, **config.kwargs)
+        for _ in gm_gradient_descent(self.gm, *args, **kwargs, sampling_configurations=self.gm_conf):
+            pass
 
-    @sharedoc(do_gm_run)
-    def gm_run(self, *args, **kwargs):
-        gm_gradient_descent(self.gm, *args, **kwargs, sampling_configurations=self.gm_conf)
+    def gm_run_g(self, *args, **kwargs):
+        yield from gm_gradient_descent(self.gm, *args, **kwargs, sampling_configurations=self.gm_conf)
 
-    def do_gm_dump(self, line):
+    @AutoCmd.decorator
+    def gm_dump(self, name):
         """
         Dump the sampling lattice into file.
 
         Parameters
         ----------
         name : str
             The file name.
         """
-        config = Config(line)
-        self.gm_dump(*config.args, **config.kwargs)
-
-    @sharedoc(do_gm_dump)
-    def gm_dump(self, name):
-        write_to_file(self.gm, name)
+        if self.gm is None:
+            showln("gm is None")
+        else:
+            write_to_file(self.gm, name)
 
-    def do_gm_conf_dump(self, line):
+    @AutoCmd.decorator
+    def gm_conf_dump(self, name):
         """
         Dump the sampling lattice configuration into file.
 
         Parameters
         ----------
         name : str
             The file name.
         """
-        config = Config(line)
-        self.gm_conf_dump(*config.args, **config.kwargs)
-
-    @sharedoc(do_gm_conf_dump)
-    def gm_conf_dump(self, name):
-        write_to_file(self.gm_conf, name)
+        if self.gm_conf is None:
+            showln("gm_conf is None")
+        else:
+            write_to_file(self.gm_conf, name)
 
-    def do_gm_load(self, line):
+    @AutoCmd.decorator
+    def gm_load(self, name):
         """
         Load the sampling lattice from file.
 
         Parameters
         ----------
         name : str
             The file name.
         """
-        config = Config(line)
-        self.gm_load(*config.args, **config.kwargs)
-
-    @sharedoc(do_gm_load)
-    def gm_load(self, name):
         self.gm = read_from_file(name)
 
-    def do_gm_conf_load(self, line):
+    @AutoCmd.decorator
+    def gm_conf_load(self, name):
         """
         Load the sampling lattice configuration from file.
 
         Parameters
         ----------
         name : str
             The file name.
         """
-        config = Config(line)
-        self.gm_conf_load(*config.args, **config.kwargs)
-
-    @sharedoc(do_gm_conf_load)
-    def gm_conf_load(self, name):
         self.gm_conf = read_from_file(name)
 
-    def do_gm_conf_create(self, line):
+    @AutoCmd.decorator
+    def gm_conf_create(self, module_name):
         """
         Create configuration of sampling lattice.
 
         Parameters
         ----------
         module_name : str
             The module name to create initial configuration of sampling lattice.
         """
-        config = Config(line)
-        self.gm_conf_create(*config.args, **config.kwargs)
-
-    @sharedoc(do_gm_conf_create)
-    def gm_conf_create(self, module_name):
         with seed_differ:
             # This configuration should never be used, so cut dimension is -1
             configuration = gm_Configuration(self.gm, -1)
             configuration = get_imported_function(module_name, "initial_configuration")(configuration)
             self.gm_conf = mpi_comm.allgather(configuration.export_configuration())
 
-    def do_gm_hamiltonian(self, line):
+    @AutoCmd.decorator
+    def gm_clear_symmetry(self):
+        """
+        Clear the symmetry of sampling lattice.
+        """
+        self.gm = self.gm.clear_symmetry()
+
+    @AutoCmd.decorator
+    def gm_hamiltonian(self, model, *args, **kwargs):
         """
         Replace the hamiltonian of the sampling lattice with another one.
 
         Parameters
         ----------
         model : str
             The model names.
         args, kwargs
             Arguments passed to model creater function.
         """
-        config = Config(line)
-        self.gm_hamiltonian(*config.args, **config.kwargs)
-
-    @sharedoc(do_gm_hamiltonian)
-    def gm_hamiltonian(self, model, *args, **kwargs):
         new_state = self.ex_ap_create(lambda x: x, model, *args, **kwargs)
         self.gm._hamiltonians = new_state._hamiltonians
 
-    def do_gm_expand(self, line):
+    @AutoCmd.decorator
+    def gm_expand(self, new_dimension, epsilon):
         """
         Expand dimension of sampling lattice.
 
         Parameters
         ----------
         new_dimension : int | float
             The new dimension, or the amplitude of dimension expandance.
         epsilon : float
             The relative error added into tensor.
         """
-        config = Config(line)
-        self.gm_expand(*config.args, **config.kwargs)
-
-    @sharedoc(do_gm_expand)
-    def gm_expand(self, new_dimension, epsilon):
         self.gm.expand_dimension(new_dimension, epsilon)
 
-    def do_gm_to_ex(self, line):
+    @AutoCmd.decorator
+    def gm_to_ex(self):
         """
         Convert sampling lattice to exact lattice.
         """
-        config = Config(line)
-        self.gm_to_ex(*config.args, **config.kwargs)
-
-    @sharedoc(do_gm_to_ex)
-    def gm_to_ex(self):
         self.ex = conversion.sampling_lattice_to_exact_state(self.gm)
 
-    def do_ap_create(self, line):
+    @AutoCmd.decorator
+    def ap_create(self, *args, **kwargs):
         """
         Create a ansatz product state.
 
         Parameters
         ----------
         model : str
             The model names.
         args, kwargs
             Arguments passed to model creater function.
         """
-        config = Config(line)
-        self.ap_create(*config.args, **config.kwargs)
-
-    @sharedoc(do_ap_create)
-    def ap_create(self, *args, **kwargs):
         state = self.ex_ap_create(AnsatzProductState, *args, **kwargs)
         if state is not None:
             self.ap = state
 
-    def do_ap_dump(self, line):
+    @AutoCmd.decorator
+    def ap_dump(self, name):
         """
         Dump the ansatz product state into file.
 
         Parameters
         ----------
         name : str
             The file name.
         """
-        config = Config(line)
-        self.ap_dump(*config.args, **config.kwargs)
-
-    @sharedoc(do_ap_dump)
-    def ap_dump(self, name):
-        write_to_file(self.ap, name)
+        if self.ap is None:
+            showln("ap is None")
+        else:
+            write_to_file(self.ap, name)
 
-    def do_ap_load(self, line):
+    @AutoCmd.decorator
+    def ap_load(self, name):
         """
         Load the ansatz product state from file.
 
         Parameters
         ----------
         name : str
             The file name.
         """
-        config = Config(line)
-        self.ap_load(*config.args, **config.kwargs)
-
-    @sharedoc(do_ap_load)
-    def ap_load(self, name):
         self.ap = read_from_file(name)
 
-    def do_ap_ansatz_set(self, line):
+    @AutoCmd.decorator
+    def ap_ansatz_set(self, name, ansatz, *args, **kwargs):
         """
         Set the ansatz for ansatz product state.
 
         Parameters
         ----------
         name : str
             The subansatz name in this state.
         ansatz : str
             The ansatz names.
         args, kwargs
             Arguments passed to ansatz creater function.
         """
-        config = Config(line)
-        self.ap_ansatz_set(*config.args, **config.kwargs)
-
-    @sharedoc(do_ap_ansatz_set)
-    def ap_ansatz_set(self, name, ansatz, *args, **kwargs):
         create_ansatz = get_imported_function(ansatz, "ansatz")
         if len(args) == 1 and args[0] == "help":
             showln(create_ansatz.__doc__.replace("\n", "\n    "))
         else:
             self.ap.set_ansatz(create_ansatz(self.ap, *args, **kwargs), name)
 
-    def do_ap_ansatz_add(self, line):
+    @AutoCmd.decorator
+    def ap_ansatz_add(self, name, ansatz, *args, **kwargs):
         """
         Add the ansatz for ansatz product state.
 
         Parameters
         ----------
         name : str
             The subansatz name in this state.
         ansatz : str
             The ansatz names.
         args, kwargs
             Arguments passed to ansatz creater function.
         """
-        config = Config(line)
-        self.ap_ansatz_add(*config.args, **config.kwargs)
-
-    @sharedoc(do_ap_ansatz_add)
-    def ap_ansatz_add(self, name, ansatz, *args, **kwargs):
         create_ansatz = get_imported_function(ansatz, "ansatz")
         if len(args) == 1 and args[0] == "help":
             showln(create_ansatz.__doc__.replace("\n", "\n    "))
         else:
             self.ap.add_ansatz(create_ansatz(self.ap, *args, **kwargs), name)
 
-    def do_ap_ansatz_mul(self, line):
+    @AutoCmd.decorator
+    def ap_ansatz_mul(self, name, ansatz, *args, **kwargs):
         """
         Mul the ansatz for ansatz product state.
 
         Parameters
         ----------
         name : str
             The subansatz name in this state.
         ansatz : str
             The ansatz names.
         args, kwargs
             Arguments passed to ansatz creater function.
         """
-        config = Config(line)
-        self.ap_ansatz_mul(*config.args, **config.kwargs)
-
-    @sharedoc(do_ap_ansatz_mul)
-    def ap_ansatz_mul(self, name, ansatz, *args, **kwargs):
         create_ansatz = get_imported_function(ansatz, "ansatz")
         if len(args) == 1 and args[0] == "help":
             showln(create_ansatz.__doc__.replace("\n", "\n    "))
         else:
             self.ap.mul_ansatz(create_ansatz(self.ap, *args, **kwargs), name)
 
-    def do_ap_ansatz_show(self, line):
+    @AutoCmd.decorator
+    def ap_ansatz_show(self):
         """
         Show the ansatz for ansatz product state.
         """
-        config = Config(line)
-        self.ap_ansatz_show(*config.args, **config.kwargs)
-
-    @sharedoc(do_ap_ansatz_show)
-    def ap_ansatz_show(self):
         self.ap.show_ansatz()
 
-    def do_ap_ansatz_lock(self, line):
+    @AutoCmd.decorator
+    def ap_ansatz_lock(self, path=""):
         """
         Lock the ansatz for ansatz product state.
 
         Parameters
         ----------
         path : str, default=""
             The path of ansatz to lock.
         """
-        config = Config(line)
-        self.ap_ansatz_lock(*config.args, **config.kwargs)
-
-    @sharedoc(do_ap_ansatz_lock)
-    def ap_ansatz_lock(self, path=""):
         self.ap.ansatz.lock(path)
 
-    def do_ap_ansatz_unlock(self, line):
+    @AutoCmd.decorator
+    def ap_ansatz_unlock(self, path=""):
         """
         Unlock the ansatz for ansatz product state.
 
         Parameters
         ----------
         path : str, default=""
             The path of ansatz to unlock.
         """
-        config = Config(line)
-        self.ap_ansatz_unlock(*config.args, **config.kwargs)
-
-    @sharedoc(do_ap_ansatz_unlock)
-    def ap_ansatz_unlock(self, path=""):
         self.ap.ansatz.unlock(path)
 
-    def do_ap_run(self, line):
+    @AutoCmd.decorator
+    def ap_run(self, *args, **kwargs):
         """
         Do gradient descent on ansatz product state. see ansatz_product_state/gradient.py for details.
         """
-        config = Config(line)
-        self.ap_run(*config.args, **config.kwargs)
+        for _ in ap_gradient_descent(self.ap, *args, **kwargs, sampling_configurations=self.ap_conf):
+            pass
 
-    @sharedoc(do_ap_run)
-    def ap_run(self, *args, **kwargs):
-        ap_gradient_descent(self.ap, *args, **kwargs, sampling_configurations=self.ap_conf)
+    def ap_run_g(self, *args, **kwargs):
+        yield from ap_gradient_descent(self.ap, *args, **kwargs, sampling_configurations=self.ap_conf)
 
-    def do_ap_conf_create(self, line):
+    @AutoCmd.decorator
+    def ap_conf_create(self, module_name):
         """
         Create configuration of ansatz product state.
 
         Parameters
         ----------
         module_name : str
             The module name to create initial configuration of ansatz product state.
         """
-        config = Config(line)
-        self.ap_conf_create(*config.args, **config.kwargs)
-
-    @sharedoc(do_ap_conf_create)
-    def ap_conf_create(self, module_name):
         with seed_differ:
             configuration = ap_Configuration(self.ap)
             configuration = get_imported_function(module_name, "initial_configuration")(configuration)
             self.ap_conf = mpi_comm.allgather(configuration.export_configuration())
 
-    def do_ap_conf_dump(self, line):
+    @AutoCmd.decorator
+    def ap_conf_dump(self, name):
         """
         Dump the ansatz product state configuration into file.
 
         Parameters
         ----------
         name : str
             The file name.
         """
-        config = Config(line)
-        self.ap_conf_dump(*config.args, **config.kwargs)
-
-    @sharedoc(do_ap_conf_dump)
-    def ap_conf_dump(self, name):
-        write_to_file(self.ap_conf, name)
+        if self.ap_conf is None:
+            showln("ap_conf is None")
+        else:
+            write_to_file(self.ap_conf, name)
 
-    def do_ap_conf_load(self, line):
+    @AutoCmd.decorator
+    def ap_conf_load(self, name):
         """
         Load the ansatz product state configuration from file.
 
         Parameters
         ----------
         name : str
             The file name.
         """
-        config = Config(line)
-        self.ap_conf_load(*config.args, **config.kwargs)
-
-    @sharedoc(do_ap_conf_load)
-    def ap_conf_load(self, name):
         self.ap_conf = read_from_file(name)
 
-    def do_ap_hamiltonian(self, line):
+    @AutoCmd.decorator
+    def ap_hamiltonian(self, model, *args, **kwargs):
         """
         Replace the hamiltonian of the ansatz product state with another one.
 
         Parameters
         ----------
         model : str
             The model names.
         args, kwargs
             Arguments passed to model creater function.
         """
-        config = Config(line)
-        self.ap_hamiltonian(*config.args, **config.kwargs)
-
-    @sharedoc(do_ap_hamiltonian)
-    def ap_hamiltonian(self, model, *args, **kwargs):
         new_state = self.ex_ap_create(lambda x: x, model, *args, **kwargs)
         self.ap._hamiltonians = new_state._hamiltonians
 
 
 class TetragonoScriptApp(TetragonoCommandApp):
 
     def __init__(self, *args, **kwargs):
@@ -874,14 +774,15 @@
     gm_load = app.gm_load
     gm_expand = app.gm_expand
     gm_to_ex = app.gm_to_ex
     gm_conf_dump = app.gm_conf_dump
     gm_conf_load = app.gm_conf_load
     gm_conf_create = app.gm_conf_create
     gm_hamiltonian = app.gm_hamiltonian
+    gm_clear_symmetry = app.gm_clear_symmetry
 
     ap_create = app.ap_create
     ap_dump = app.ap_dump
     ap_load = app.ap_load
     ap_ansatz_set = app.ap_ansatz_set
     ap_ansatz_add = app.ap_ansatz_add
     ap_ansatz_mul = app.ap_ansatz_mul
@@ -889,7 +790,10 @@
     ap_ansatz_lock = app.ap_ansatz_lock
     ap_ansatz_unlock = app.ap_ansatz_unlock
     ap_run = app.ap_run
     ap_conf_create = app.ap_conf_create
     ap_conf_dump = app.ap_conf_dump
     ap_conf_load = app.ap_conf_load
     ap_hamiltonian = app.ap_hamiltonian
+
+    gm_run_g = app.gm_run_g
+    ap_run_g = app.ap_run_g
```

## tetragono/simple_update_lattice.py

```diff
@@ -19,14 +19,23 @@
 from copyreg import _slotnames
 import numpy as np
 from .auxiliaries import DoubleLayerAuxiliaries
 from .abstract_lattice import AbstractLattice
 from .common_toolkit import show, showln, mpi_comm, mpi_rank, mpi_size
 
 
+def max_parallel_size_shown(state, pool=set()):
+    state_id = id(state)
+    if state_id in pool:
+        return True
+    else:
+        pool.add(state_id)
+        return False
+
+
 class SimpleUpdateLatticeEnvironment:
     """
     Environment handler for simple update lattice.
     """
 
     __slots__ = ["owner"]
 
@@ -312,36 +321,38 @@
         """
         # Yield proper positions set until remained set is empty
         while input_plan:
             used_orbits = set()  # set[tuple[int, int, int]]
             merged_dimensions = {}  # map[tuple[int, int], int]
             result = set()  # set[tuple[tuple[int, int, int], ...]]
             # Try to add every positions in the set
+            not_first = False
             for positions in sorted(input_plan):
                 # Create a copy for auxiliary variables
                 used_orbits_tmp = used_orbits.copy()
                 merged_dimensions_tmp = merged_dimensions.copy()
                 # Try to add positions to result
                 for position in positions:
                     # Check position one by one
                     if position not in used_orbits_tmp:
                         # Not used, so add it now
                         used_orbits_tmp.add(position)
                         site = position[0], position[1]
                         if site not in merged_dimensions_tmp:
                             merged_dimensions_tmp[site] = 1
                         merged_dimensions_tmp[site] *= self.physics_edges[position].dimension
-                        if merged_dimensions_tmp[site] > threshold:
+                        if not_first and merged_dimensions_tmp[site] > threshold:
                             # Check failed, break the loop, and it will try to add next positions to result
                             break
                 else:
                     # All check passed, add it to result
                     result.add(positions)
                     used_orbits = used_orbits_tmp
                     merged_dimensions = merged_dimensions_tmp
+                not_first = True
             input_plan -= result
             yield result
 
     def _get_merge_hamiltonian_plan_with_check_large_physical_dimension(self, threshold=6):
         """
         Get the hamiltonian merging plan for simple update.
 
@@ -372,16 +383,19 @@
         tuple[tuple[int, int, int], ...], Tensor
             The merged result positions and tensor.
         """
         result_positions = tuple(sorted(set.union(*(set(positions) for positions in positions_list))))
         result_tensor = None
         for positions in positions_list:
             rename = {index: result_positions.index(position) for index, position in enumerate(positions)}
-            tensor = self._hamiltonians[positions].edge_rename({f"I{i}": f"I{j}" for i, j in rename.items()} |
-                                                               {f"O{i}": f"O{j}" for i, j in rename.items()})
+            tensor = self._hamiltonians[positions].edge_rename({
+                f"I{i}": f"I{j}" for i, j in rename.items()
+            } | {
+                f"O{i}": f"O{j}" for i, j in rename.items()
+            })
 
             empty = [(index, position) for index, position in enumerate(result_positions) if position not in positions]
             if len(empty) != 0:
                 empty_out_name = [f"O{index}" for index, position in empty]
                 empty_in_name = [f"I{index}" for index, position in empty]
                 empty_out_edge = [self.physics_edges[position] for index, position in empty]
                 empty_in_edge = [self.physics_edges[position].conjugated() for index, position in empty]
@@ -403,15 +417,15 @@
         Parameters
         ----------
         total_step : int
             The total step number of the simple update.
         delta_tau : float
             The delta tau in the evolution operator.
         new_dimension : int | float
-            The dimension cut used in svd of simple update, or the amplitude of dimension expandance.
+            The dimension cut used in svd of simple update, or the threshold for the singular value.
         """
 
         # Create updater first
         # updater U_i = exp(- delta_tau H_i)
         # At this step, get the coordinates of every hamiltonian term instead of original knowning specific orbit only.
         updaters = []
         for positions, hamiltonian_term in map(self._get_merge_hamiltonian,
@@ -460,15 +474,16 @@
             # The max mpi rank is the max parallel size.
             if index > max_index:
                 max_index = index
             # Update updaters list for the next iterations
             updaters = remained_updaters
             # Append this bundle to updaters_bundles.
             updaters_bundles.append((this_bundle, coordinates_map))
-        showln(f"Simple update max parallel size is {max_index}")
+        if not max_parallel_size_shown(self):
+            showln(f"Simple update max parallel size is {max_index}")
 
         # Run simple update
         for step in range(total_step):
             show(f"Simple update, {total_step=}, {delta_tau=}, {new_dimension=}, {step=}")
             # Trotter expansion
             # run updater bundle by bundle.
             for bundle, coordinates_map in updaters_bundles:
@@ -568,15 +583,17 @@
         """
         coordinate = coordinates[0]
         orbits = [orbit for index, orbit in index_and_orbit]
         self[coordinate] = (
             self[coordinate]  #
             .contract(evolution_operator,
                       {(f"P{orbit}", f"I{body_index}") for body_index, orbit in enumerate(orbits)})  #
-            .edge_rename({f"O{body_index}": f"P{orbit}" for body_index, orbit in enumerate(orbits)}))
+            .edge_rename({
+                f"O{body_index}": f"P{orbit}" for body_index, orbit in enumerate(orbits)
+            }))
 
     def _single_term_simple_update_double_site_nearest_horizontal(self, coordinates, index_and_orbit,
                                                                   evolution_operator, new_dimension):
         """
         See Also
         --------
         _single_term_simple_update
@@ -605,40 +622,45 @@
         else:
             raise RuntimeError("Wrong simple update dispatch")
         body = len(index_and_orbit)
         left = self[i, j]
         right = self[i, j + 1]
         right = self._try_multiple(right, i, j + 1, "L", division=True)
         original_dimension = left.edges("R").dimension
-        if isinstance(new_dimension, float):
-            new_dimension = round(original_dimension * new_dimension)
         left_q, left_r = left.qr("r", {*(f"P{orbit}" for body_index, orbit in left_index_and_orbit), "R"}, "R", "L")
         right_q, right_r = right.qr("r", {*(f"P{orbit}" for body_index, orbit in right_index_and_orbit), "L"}, "L", "R")
         u, s, v = (
             left_r  #
-            .edge_rename({f"P{orbit}": f"P{body_index}" for body_index, orbit in left_index_and_orbit})  #
+            .edge_rename({
+                f"P{orbit}": f"P{body_index}" for body_index, orbit in left_index_and_orbit
+            })  #
             .contract(
-                right_r.edge_rename({f"P{orbit}": f"P{body_index}" for body_index, orbit in right_index_and_orbit}),
-                {("R", "L")})  #
+                right_r.edge_rename({
+                    f"P{orbit}": f"P{body_index}" for body_index, orbit in right_index_and_orbit
+                }), {("R", "L")})  #
             .contract(evolution_operator, {(f"P{body_index}", f"I{body_index}") for body_index in range(body)})  #
             .svd({*(f"O{body_index}" for body_index, orbit in left_index_and_orbit), "L"}, "R", "L", "L", "R",
                  new_dimension))
         s /= s.norm_2()
         self.environment[i, j, "R"] = s
         u = self._try_multiple(u, i, j, "R")
         u = (
             u  #
             .contract(left_q, {("L", "R")})  #
-            .edge_rename({f"O{body_index}": f"P{orbit}" for body_index, orbit in left_index_and_orbit}))
+            .edge_rename({
+                f"O{body_index}": f"P{orbit}" for body_index, orbit in left_index_and_orbit
+            }))
         self[i, j] = u
         v = self._try_multiple(v, i, j + 1, "L")
         v = (
             v  #
             .contract(right_q, {("R", "L")})  #
-            .edge_rename({f"O{body_index}": f"P{orbit}" for body_index, orbit in right_index_and_orbit}))
+            .edge_rename({
+                f"O{body_index}": f"P{orbit}" for body_index, orbit in right_index_and_orbit
+            }))
         self[i, j + 1] = v
 
     def _single_term_simple_update_double_site_nearest_vertical(self, coordinates, index_and_orbit, evolution_operator,
                                                                 new_dimension):
         """
         See Also
         --------
@@ -668,39 +690,44 @@
         else:
             raise RuntimeError("Wrong simple update dispatch")
         body = len(index_and_orbit)
         up = self[i, j]
         down = self[i + 1, j]
         down = self._try_multiple(down, i + 1, j, "U", division=True)
         original_dimension = up.edges("D").dimension
-        if isinstance(new_dimension, float):
-            new_dimension = round(original_dimension * new_dimension)
         up_q, up_r = up.qr("r", {*(f"P{orbit}" for body_index, orbit in up_index_and_orbit), "D"}, "D", "U")
         down_q, down_r = down.qr("r", {*(f"P{orbit}" for body_index, orbit in down_index_and_orbit), "U"}, "U", "D")
         u, s, v = (
             up_r  #
-            .edge_rename({f"P{orbit}": f"P{body_index}" for body_index, orbit in up_index_and_orbit})  #
-            .contract(down_r.edge_rename({f"P{orbit}": f"P{body_index}" for body_index, orbit in down_index_and_orbit}),
-                      {("D", "U")})  #
+            .edge_rename({
+                f"P{orbit}": f"P{body_index}" for body_index, orbit in up_index_and_orbit
+            })  #
+            .contract(down_r.edge_rename({
+                f"P{orbit}": f"P{body_index}" for body_index, orbit in down_index_and_orbit
+            }), {("D", "U")})  #
             .contract(evolution_operator, {(f"P{body_index}", f"I{body_index}") for body_index in range(body)})  #
             .svd({*(f"O{body_index}" for body_index, orbit in up_index_and_orbit), "U"}, "D", "U", "U", "D",
                  new_dimension))
         s /= s.norm_2()
         self.environment[i, j, "D"] = s
         u = self._try_multiple(u, i, j, "D")
         u = (
             u  #
             .contract(up_q, {("U", "D")})  #
-            .edge_rename({f"O{body_index}": f"P{orbit}" for body_index, orbit in up_index_and_orbit}))
+            .edge_rename({
+                f"O{body_index}": f"P{orbit}" for body_index, orbit in up_index_and_orbit
+            }))
         self[i, j] = u
         v = self._try_multiple(v, i + 1, j, "U")
         v = (
             v  #
             .contract(down_q, {("D", "U")})  #
-            .edge_rename({f"O{body_index}": f"P{orbit}" for body_index, orbit in down_index_and_orbit}))
+            .edge_rename({
+                f"O{body_index}": f"P{orbit}" for body_index, orbit in down_index_and_orbit
+            }))
         self[i + 1, j] = v
 
     def _try_multiple(self, tensor, i, j, direction, *, division=False, square_root=False):
         """
         Try to multiple environment to a given tensor.
 
         Parameters
```

## tetragono/ansatz_product_state/gradient.py

```diff
@@ -297,9 +297,12 @@
                 state.bcast_state()
 
                 # Save state
                 if save_state_file:
                     write_to_file(state, save_state_file.replace("%s", str(grad_step)).replace("%t", time_str))
                 if save_configuration_file:
                     write_to_file(sampling_configurations, save_configuration_file)
+
+                # Yield the energy
+                yield observer.energy
             if sigint_handler():
                 break
```

## tetragono/ansatz_product_state/observer.py

```diff
@@ -37,24 +37,27 @@
 
     def __enter__(self):
         """
         Enter sampling loop, flush all cached data in the observer object.
         """
         self._start = True
         self._result = {
-            name: {positions: 0.0 for positions, observer in observers.items()
-                  } for name, observers in self._observer.items()
+            name: {
+                positions: 0.0 for positions, observer in observers.items()
+            } for name, observers in self._observer.items()
         }
         self._result_square = {
-            name: {positions: 0.0 for positions, observer in observers.items()
-                  } for name, observers in self._observer.items()
+            name: {
+                positions: 0.0 for positions, observer in observers.items()
+            } for name, observers in self._observer.items()
         }
         self._result_reweight = {
-            name: {positions: 0.0 for positions, observer in observers.items()
-                  } for name, observers in self._observer.items()
+            name: {
+                positions: 0.0 for positions, observer in observers.items()
+            } for name, observers in self._observer.items()
         }
         self._count = 0
         self._total_weight = 0.0
         self._total_weight_square = 0.0
         self._total_log_ws = 0.0
         self._total_energy = 0.0
         self._total_energy_square = 0.0
@@ -441,16 +444,16 @@
         -------
         dict[str, dict[tuple[tuple[int, int, int], ...], tuple[float, float]]]
             The observer result of each observer set name and each site positions list.
         """
         return {
             name: {
                 positions:
-                self._expect_and_deviation(self._result[name][positions], self._result_square[name][positions],
-                                           self._result_reweight[name][pisitions]) for positions in data
+                    self._expect_and_deviation(self._result[name][positions], self._result_square[name][positions],
+                                               self._result_reweight[name][pisitions]) for positions in data
             } for name, data in self._observer.items()
         }
 
     @property
     def total_energy(self):
         """
         Get the observed energy.
```

## tetragono/ansatz_product_state/state.py

```diff
@@ -65,18 +65,17 @@
         Export the configuration of all the sites.
 
         Returns
         -------
         list[list[dict[int, EdgePoint]]]
             The configuration data of all the sites
         """
-        return [[{orbit: self._configuration[l1, l2, orbit]
-                  for orbit in self.owner.physics_edges[l1, l2]}
-                 for l2 in range(self.owner.L2)]
-                for l1 in range(self.owner.L1)]
+        return [[{
+            orbit: self._configuration[l1, l2, orbit] for orbit in self.owner.physics_edges[l1, l2]
+        } for l2 in range(self.owner.L2)] for l1 in range(self.owner.L1)]
 
     def import_configuration(self, config):
         """
         Import the configuration of all the sites.
 
         Parameters
         ----------
```

## tetragono/auxiliaries/double_layer_auxiliaries.py

```diff
@@ -614,49 +614,57 @@
                 right_dot = self._up_to_down_site[i - 1, j + 1]()
                 result = safe_contract(
                     left_part,
                     safe_rename(
                         self._lattice_n[i][j](), {
                             "R": "RN",
                             "D": "DN",
-                            **{f"P{orbit}": f"O{body_index}" for body_index, orbit in left_index_and_orbit}
+                            **{
+                                f"P{orbit}": f"O{body_index}" for body_index, orbit in left_index_and_orbit
+                            }
                         }),
                     {("RN", "L"), ("DN", "U")},
                 )
                 result = safe_contract(
                     result,
                     safe_rename(
                         self._lattice_c[i][j](), {
                             "R": "RC",
                             "D": "DC",
-                            **{f"P{orbit}": f"I{body_index}" for body_index, orbit in left_index_and_orbit}
+                            **{
+                                f"P{orbit}": f"I{body_index}" for body_index, orbit in left_index_and_orbit
+                            }
                         }),
                     {("RC", "L"), ("DC", "U"), ("T", "T")},
                     contract_all_physics_edges=True,
                 )
                 result = safe_contract(result, safe_rename(left_dot, {"R": "R3"}), {("R3", "L"), ("DN", "UN"),
                                                                                     ("DC", "UC")})
                 result = safe_contract(result, safe_rename(right_dot, {"R": "R1"}), {("R1", "L")})
                 result = safe_contract(
                     result,
                     safe_rename(
                         self._lattice_n[i][j + 1](), {
                             "R": "RN",
                             "D": "DN",
-                            **{f"P{orbit}": f"O{body_index}" for body_index, orbit in right_index_and_orbit}
+                            **{
+                                f"P{orbit}": f"O{body_index}" for body_index, orbit in right_index_and_orbit
+                            }
                         }),
                     {("RN", "L"), ("DN", "U")},
                 )
                 result = safe_contract(
                     result,
                     safe_rename(
                         self._lattice_c[i][j + 1](), {
                             "R": "RC",
                             "D": "DC",
-                            **{f"P{orbit}": f"I{body_index}" for body_index, orbit in right_index_and_orbit}
+                            **{
+                                f"P{orbit}": f"I{body_index}" for body_index, orbit in right_index_and_orbit
+                            }
                         }),
                     {("RC", "L"), ("DC", "U"), ("T", "T")},
                     contract_all_physics_edges=True,
                 )
                 result = safe_contract(result, right_part, {("R1", "L1"), ("R3", "L3"), ("RN", "LN"), ("RC", "LC"),
                                                             ("DN", "UN"), ("DC", "UC")})
                 return result
@@ -684,48 +692,56 @@
                 down_part = self._inline_down_to_up_tailed[i + 2, j]()
                 down_dot = self._left_to_right_site[i + 1, j - 1]()
                 result = safe_contract(
                     up_part,
                     safe_rename(self._lattice_n[i][j](), {
                         "R": "RN",
                         "D": "DN",
-                        **{f"P{orbit}": f"O{body_index}" for body_index, orbit in up_index_and_orbit}
+                        **{
+                            f"P{orbit}": f"O{body_index}" for body_index, orbit in up_index_and_orbit
+                        }
                     }),
                     {("RN", "L"), ("DN", "U")},
                 )
                 result = safe_contract(
                     result,
                     safe_rename(self._lattice_c[i][j](), {
                         "R": "RC",
                         "D": "DC",
-                        **{f"P{orbit}": f"I{body_index}" for body_index, orbit in up_index_and_orbit}
+                        **{
+                            f"P{orbit}": f"I{body_index}" for body_index, orbit in up_index_and_orbit
+                        }
                     }),
                     {("RC", "L"), ("DC", "U"), ("T", "T")},
                     contract_all_physics_edges=True,
                 )
                 result = safe_contract(result, safe_rename(up_dot, {"D": "D3"}), {("D3", "U"), ("RN", "LN"),
                                                                                   ("RC", "LC")})
                 result = safe_contract(result, safe_rename(down_dot, {"D": "D1"}), {("D1", "U")})
                 result = safe_contract(
                     result,
                     safe_rename(
                         self._lattice_n[i + 1][j](), {
                             "R": "RN",
                             "D": "DN",
-                            **{f"P{orbit}": f"O{body_index}" for body_index, orbit in down_index_and_orbit}
+                            **{
+                                f"P{orbit}": f"O{body_index}" for body_index, orbit in down_index_and_orbit
+                            }
                         }),
                     {("RN", "L"), ("DN", "U")},
                 )
                 result = safe_contract(
                     result,
                     safe_rename(
                         self._lattice_c[i + 1][j](), {
                             "R": "RC",
                             "D": "DC",
-                            **{f"P{orbit}": f"I{body_index}" for body_index, orbit in down_index_and_orbit}
+                            **{
+                                f"P{orbit}": f"I{body_index}" for body_index, orbit in down_index_and_orbit
+                            }
                         }),
                     {("RC", "L"), ("DC", "U"), ("T", "T")},
                     contract_all_physics_edges=True,
                 )
                 result = safe_contract(result, down_part, {("D1", "U1"), ("D3", "U3"), ("RN", "LN"), ("RC", "LC"),
                                                            ("DN", "UN"), ("DC", "UC")})
                 return result
```

## tetragono/common_tensor/Fermi.py

```diff
@@ -20,16 +20,20 @@
 from .tensor_toolkit import Fedge, Tedge, rename_io
 
 Tensor = TAT.Fermi.Z.Tensor
 
 EF = Fedge[0, 1]
 ET = Tedge[0, -1]
 
-CP = Tensor(["O0", "I0", "T"], [EF, ET, Fedge[-1,]]).range(1, 0)
-CM = Tensor(["O0", "I0", "T"], [EF, ET, Tedge[+1,]]).range(1, 0)
+CP = Tensor(["O0", "I0", "T"], [EF, ET, Fedge[
+    -1,
+]]).range(1, 0)
+CM = Tensor(["O0", "I0", "T"], [EF, ET, Tedge[
+    +1,
+]]).range(1, 0)
 C0C1 = rename_io(CP, [0]).contract(rename_io(CM, [1]), {("T", "T")})
 C1C0 = rename_io(CP, [1]).contract(rename_io(CM, [0]), {("T", "T")})
 CC = C0C1 + C1C0
 
 I = Tensor(["O0", "I0"], [EF, ET]).identity({("I0", "O0")})
 
 N = rename_io(CP, [0]).contract(rename_io(CM, [0]), {("T", "T"), ("I0", "O0")})
```

## tetragono/common_tensor/FermiU1_tJ.py

```diff
@@ -21,18 +21,26 @@
 
 Tensor = TAT.FermiU1.Z.Tensor
 
 # Empty, Down, Up
 EF = Fedge[(0, 0), (+1, -1), (+1, +1)]
 ET = Tedge[(0, 0), (-1, +1), (-1, -1)]
 
-CPU = Tensor(["O0", "I0", "T"], [EF, ET, Fedge[(-1, -1),]]).range(1, 0)
-CPD = Tensor(["O0", "I0", "T"], [EF, ET, Fedge[(-1, +1),]]).range(1, 0)
-CMU = Tensor(["O0", "I0", "T"], [EF, ET, Tedge[(+1, +1),]]).range(1, 0)
-CMD = Tensor(["O0", "I0", "T"], [EF, ET, Tedge[(+1, -1),]]).range(1, 0)
+CPU = Tensor(["O0", "I0", "T"], [EF, ET, Fedge[
+    (-1, -1),
+]]).range(1, 0)
+CPD = Tensor(["O0", "I0", "T"], [EF, ET, Fedge[
+    (-1, +1),
+]]).range(1, 0)
+CMU = Tensor(["O0", "I0", "T"], [EF, ET, Tedge[
+    (+1, +1),
+]]).range(1, 0)
+CMD = Tensor(["O0", "I0", "T"], [EF, ET, Tedge[
+    (+1, -1),
+]]).range(1, 0)
 
 C0UC1U = rename_io(CPU, [0]).contract(rename_io(CMU, [1]), {("T", "T")})
 C0DC1D = rename_io(CPD, [0]).contract(rename_io(CMD, [1]), {("T", "T")})
 C1UC0U = rename_io(CPU, [1]).contract(rename_io(CMU, [0]), {("T", "T")})
 C1DC0D = rename_io(CPD, [1]).contract(rename_io(CMD, [0]), {("T", "T")})
 CC = C0UC1U + C0DC1D + C1UC0U + C1DC0D
```

## tetragono/common_tensor/Parity.py

```diff
@@ -20,17 +20,21 @@
 from .tensor_toolkit import Fedge, Tedge, rename_io
 
 Tensor = TAT.Parity.Z.Tensor
 
 EF = Fedge[False, True]
 ET = Tedge[False, True]
 
-CP = Tensor(["O0", "I0", "T"], [EF, ET, Fedge[True,]]).zero()
+CP = Tensor(["O0", "I0", "T"], [EF, ET, Fedge[
+    True,
+]]).zero()
 CP[{"O0": (True, 0), "I0": (False, 0), "T": (True, 0)}] = 1
-CM = Tensor(["O0", "I0", "T"], [EF, ET, Tedge[True,]]).zero()
+CM = Tensor(["O0", "I0", "T"], [EF, ET, Tedge[
+    True,
+]]).zero()
 CM[{"O0": (False, 0), "I0": (True, 0), "T": (True, 0)}] = 1
 C0C1 = rename_io(CP, [0]).contract(rename_io(CM, [1]), {("T", "T")})
 C1C0 = rename_io(CP, [1]).contract(rename_io(CM, [0]), {("T", "T")})
 CC = C0C1 + C1C0
 
 I = Tensor(["O0", "I0"], [EF, ET]).identity({("I0", "O0")})
```

## tetragono/sampling_lattice/gradient.py

```diff
@@ -250,14 +250,16 @@
                             configuration_pool.append((possibility, configuration))
                         show(f"sampling {sampling_step}/{sampling_total_step}, energy={observer.energy}")
                 # Save configuration
                 gathered_configurations = mpi_comm.allgather(configuration.export_configuration())
                 sampling_configurations.clear()
                 sampling_configurations += gathered_configurations
             showln(f"sampling done, total_step={sampling_total_step}, energy={observer.energy}")
+            if sampling_method == "direct":
+                showln(f"direct sampling stability is {observer.stability}")
 
             # Measure log
             if measurement and mpi_rank == 0:
                 for measurement_name in measurement_names:
                     measurement_result = observer.result[measurement_name]
                     get_imported_function(measurement_name, "save_result")(state, measurement_result, grad_step)
             # Energy log
@@ -317,9 +319,12 @@
                 # sampling is not needed to refresh since every gradient step will use a new sampling object.
 
                 # Save state
                 if save_state_file:
                     write_to_file(state, save_state_file.replace("%s", str(grad_step)).replace("%t", time_str))
                 if save_configuration_file:
                     write_to_file(sampling_configurations, save_configuration_file)
+
+                # Yield the energy
+                yield observer.energy
             if sigint_handler():
                 break
```

## tetragono/sampling_lattice/lattice.py

```diff
@@ -15,16 +15,17 @@
 # You should have received a copy of the GNU General Public License
 # along with this program.  If not, see <https://www.gnu.org/licenses/>.
 #
 
 from copyreg import _slotnames
 import numpy as np
 from ..auxiliaries import SingleLayerAuxiliaries
+from ..abstract_state import AbstractState
 from ..abstract_lattice import AbstractLattice
-from ..common_toolkit import lattice_prod_sum, lattice_conjugate, showln, bcast_lattice_buffer, safe_rename
+from ..common_toolkit import lattice_prod_sum, lattice_conjugate, showln, bcast_lattice_buffer, safe_rename, mpi_size, mpi_rank, mpi_comm
 
 
 class Configuration(SingleLayerAuxiliaries):
     """
     Configuration system for square sampling lattice.
     """
 
@@ -64,18 +65,17 @@
             The cut dimension in single layer auxiliaries.
         """
         super().__init__(owner.L1, owner.L2, cut_dimension, False, owner.Tensor)
         self.owner: SamplingLattice = owner
 
         # EdgePoint = tuple[self.Symmetry, int]
         # The data storage for spin configuration, access it by configuration[l1, l2, orbit] instead.
-        self._configuration = [[{orbit: None
-                                 for orbit in self.owner.physics_edges[l1, l2]}
-                                for l2 in range(self.owner.L2)]
-                               for l1 in range(self.owner.L1)]
+        self._configuration = [[{
+            orbit: None for orbit in self.owner.physics_edges[l1, l2]
+        } for l2 in range(self.owner.L2)] for l1 in range(self.owner.L1)]
         self._set_site_without_orbit()
         # The holes cache for this configuration, access it by configuration.holes()
         self._holes = None
 
     def _set_site_without_orbit(self):
         """
         Set super() item for sites without orbit. It is needed to be called when initializing a configuration.
@@ -343,16 +343,18 @@
             The holes of this configuration.
         """
         if self._holes is None:
             # Prepare
             ws = self.hole(())  # |s|psi>
             inv_ws_conj = ws / (ws.norm_2()**2)  # |s|psi> / <psi|s|psi>
             inv_ws = inv_ws_conj.conjugate()  # <psi|s| / <psi|s|psi>
-            all_name = {("T", "T")} | {(f"P_{l1}_{l2}_{orbit}", f"P_{l1}_{l2}_{orbit}") for l1 in range(self.owner.L1)
-                                       for l2 in range(self.owner.L2) for orbit in self.owner.physics_edges[l1, l2]}
+            all_name = {("T", "T")} | {(f"P_{l1}_{l2}_{orbit}", f"P_{l1}_{l2}_{orbit}")
+                                       for l1 in range(self.owner.L1)
+                                       for l2 in range(self.owner.L2)
+                                       for orbit in self.owner.physics_edges[l1, l2]}
 
             # Calculate
             holes = [[None for l2 in range(self.owner.L2)] for l1 in range(self.owner.L1)]
             # <psi|s|partial_x psi> / <psi|s|psi>
             for l1, l2 in self.owner.sites():
                 hole = self.hole(((l1, l2),))  # |s|partial_x psi>
                 # The right side is open in fact, because of partial_x, which is not Hilbert space, it is tensor space.
@@ -367,15 +369,17 @@
                 # Rename to the correct edge names.
                 hole = safe_rename(
                     hole, {
                         "L0": "R",
                         "R0": "L",
                         "U0": "D",
                         "D0": "U",
-                        **{f"P_{l1}_{l2}_{orbit}": f"P{orbit}" for orbit in self.owner.physics_edges[l1, l2]},
+                        **{
+                            f"P_{l1}_{l2}_{orbit}": f"P{orbit}" for orbit in self.owner.physics_edges[l1, l2]
+                        },
                     })
 
                 # hole owns conjugated physics edge, because of partial_x. Expand it by connecting it with a physics
                 # edge but one dimension, and a conjugated edge but full dimension tensor, which is just what
                 # _get_shrinker returns.
                 for orbit, shrinker in self._get_shrinker((l1, l2), self._configuration[l1][l2]):
                     hole = hole.contract(shrinker, {(f"P{orbit}", "P")}).edge_rename({"Q": f"P{orbit}"})
@@ -461,15 +465,17 @@
             the configuration object.
 
         Returns
         -------
         tuple[EdgePoint, ...]
             the config list.
         """
-        return tuple(configuration[l1, l2, orbit] for l1 in range(self.owner.L1) for l2 in range(self.owner.L2)
+        return tuple(configuration[l1, l2, orbit]
+                     for l1 in range(self.owner.L1)
+                     for l2 in range(self.owner.L2)
                      for orbit in self.owner.physics_edges[l1, l2])
 
     def _config_list_replace(self, config, replacement):
         """
         Get the replaced config.
 
         Parameters
@@ -754,38 +760,80 @@
             value = self.Tensor(old.names, [
                 self.physics_edges[l1, l2, int(name[1:])] if name.startswith("P") else old.edges(name)
                 for name in old.names
             ]).zero()
             value += old
         self._lattice[l1, l2] = value
 
+    def _expand_dimension_vertical_1(self):
+        for l1, l2 in self.sites():
+            if l1 != 0 and l1 % 2 == 0:
+                yield l1 - 1, l2
+
+    def _expand_dimension_vertical_2(self):
+        for l1, l2 in self.sites():
+            if l1 != 0 and l1 % 2 == 1:
+                yield l1 - 1, l2
+
+    def _expand_dimension_horizontal_1(self):
+        for l1, l2 in self.sites():
+            if l2 != 0 and l2 % 2 == 0:
+                yield l1, l2 - 1
+
+    def _expand_dimension_horizontal_2(self):
+        for l1, l2 in self.sites():
+            if l2 != 0 and l2 % 2 == 1:
+                yield l1, l2 - 1
+
+    def _bcast_site_from(self, l1, l2, root):
+        self[l1, l2] = mpi_comm.bcast(self[l1, l2], root=root)
+
     def expand_dimension(self, new_dimension, epsilon):
         """
         Expand dimension of sampling lattice. If new_dimension equals to the origin dimension and epsilon is zero, this
         function will only fix the lattice gauge.
 
         Parameters
         ----------
         new_dimension : int | float
             The new dimension, or the amplitude of dimension expandance.
         epsilon : float
             The relative error added into tensor.
         """
-        for l1, l2 in self.sites():
-            if l1 != 0 and l1 % 2 == 0:
-                self._expand_vertical(l1 - 1, l2, new_dimension, epsilon)
-        for l1, l2 in self.sites():
-            if l1 != 0 and l1 % 2 == 1:
-                self._expand_vertical(l1 - 1, l2, new_dimension, epsilon)
-        for l1, l2 in self.sites():
-            if l2 != 0 and l2 % 2 == 0:
-                self._expand_horizontal(l1, l2 - 1, new_dimension, epsilon)
-        for l1, l2 in self.sites():
-            if l2 != 0 and l2 % 2 == 1:
-                self._expand_horizontal(l1, l2 - 1, new_dimension, epsilon)
+        for index, [l1, l2] in enumerate(self._expand_dimension_vertical_1()):
+            if index % mpi_size == mpi_rank:
+                self._expand_vertical(l1, l2, new_dimension, epsilon)
+        for index, [l1, l2] in enumerate(self._expand_dimension_vertical_1()):
+            root = index % mpi_size
+            self._bcast_site_from(l1, l2, root)
+            self._bcast_site_from(l1 + 1, l2, root)
+
+        for index, [l1, l2] in enumerate(self._expand_dimension_vertical_2()):
+            if index % mpi_size == mpi_rank:
+                self._expand_vertical(l1, l2, new_dimension, epsilon)
+        for index, [l1, l2] in enumerate(self._expand_dimension_vertical_2()):
+            root = index % mpi_size
+            self._bcast_site_from(l1, l2, root)
+            self._bcast_site_from(l1 + 1, l2, root)
+
+        for index, [l1, l2] in enumerate(self._expand_dimension_horizontal_1()):
+            if index % mpi_size == mpi_rank:
+                self._expand_horizontal(l1, l2, new_dimension, epsilon)
+        for index, [l1, l2] in enumerate(self._expand_dimension_horizontal_1()):
+            root = index % mpi_size
+            self._bcast_site_from(l1, l2, root)
+            self._bcast_site_from(l1, l2 + 1, root)
+
+        for index, [l1, l2] in enumerate(self._expand_dimension_horizontal_2()):
+            if index % mpi_size == mpi_rank:
+                self._expand_horizontal(l1, l2, new_dimension, epsilon)
+        for index, [l1, l2] in enumerate(self._expand_dimension_horizontal_2()):
+            root = index % mpi_size
+            self._bcast_site_from(l1, l2, root)
+            self._bcast_site_from(l1, l2 + 1, root)
 
     def _expand_horizontal(self, l1, l2, new_dimension, epsilon):
         left = self[l1, l2]
         right = self[l1, l2 + 1]
         original_dimension = left.edges("R").dimension
         if isinstance(new_dimension, float):
             new_dimension = round(original_dimension * new_dimension)
@@ -869,7 +917,51 @@
             self._lattice[l1, l2] -= step_size * gradient[l1, l2]
 
     def bcast_lattice(self, root=0):
         """
         Bcast the lattice, to ensure the data keep the same across different process.
         """
         bcast_lattice_buffer(self._lattice, root=root)
+
+    def clear_symmetry(self):
+        """
+        Clear symmetry for the model
+
+        Returns
+        -------
+        SamplingLattice
+            The result lattice with NoSymmetry tensor(for bosonic system) or ParitySymmetry tensor(for fermionic system).
+        """
+        lattice = [[self[l1, l2].clear_symmetry() for l2 in range(self.L2)] for l1 in range(self.L1)]
+        hamiltonians = {key: value.clear_symmetry() for key, value in self._hamiltonians.items()}
+
+        # Find which tensor contains T edge
+        for l1, l2 in self.sites():
+            t_edge_tensor = lattice[l1][l2]
+            if "T" in t_edge_tensor.names:
+                break
+
+        # AbstractState
+        state = AbstractState(type(t_edge_tensor), self.L1, self.L2)
+        [(t_edge_symmetry, _)] = t_edge_tensor.edges("T").segments
+        state.total_symmetry = -t_edge_symmetry
+        for l1, l2 in self.sites():
+            tensor = lattice[l1][l2]
+            for name in tensor.names:
+                if name.startswith("P"):
+                    orbit = int(name[1:])
+                    state.physics_edges[l1, l2, orbit] = tensor.edges(name)
+        state._hamiltonians = hamiltonians
+
+        # AbstractLattice
+        state = AbstractLattice(state)
+        for l1, l2 in self.sites():
+            if l1 != 0:
+                state.virtual_bond[l1, l2, "U"] = lattice[l1][l2].edges("U")
+            if l2 != 0:
+                state.virtual_bond[l1, l2, "L"] = lattice[l1][l2].edges("L")
+
+        # SamplingLattice
+        state = SamplingLattice(state)
+        state._lattice = np.array(lattice)
+
+        return state
```

## tetragono/sampling_lattice/observer.py

```diff
@@ -40,24 +40,27 @@
 
     def __enter__(self):
         """
         Enter sampling loop, flush all cached data in the observer object.
         """
         self._start = True
         self._result_reweight = {
-            name: {positions: 0.0 for positions, observer in observers.items()
-                  } for name, observers in self._observer.items()
+            name: {
+                positions: 0.0 for positions, observer in observers.items()
+            } for name, observers in self._observer.items()
         }
         self._result_reweight_square = {
-            name: {positions: 0.0 for positions, observer in observers.items()
-                  } for name, observers in self._observer.items()
+            name: {
+                positions: 0.0 for positions, observer in observers.items()
+            } for name, observers in self._observer.items()
         }
         self._result_square_reweight_square = {
-            name: {positions: 0.0 for positions, observer in observers.items()
-                  } for name, observers in self._observer.items()
+            name: {
+                positions: 0.0 for positions, observer in observers.items()
+            } for name, observers in self._observer.items()
         }
         self._count = 0
         self._total_weight = 0.0
         self._total_weight_square = 0.0
         self._total_log_ws = 0.0
         self._total_energy_reweight = 0.0
         self._total_energy_reweight_square = 0.0
@@ -334,16 +337,18 @@
 
         reweight = ws.norm_2()**2 / possibility  # <psi|s|psi> / p(s)
         self._total_weight += reweight
         self._total_weight_square += reweight * reweight
         self._total_log_ws += np.log(np.abs(complex(ws)))
 
         inv_ws_conj = ws / (ws.norm_2()**2)  # |s|psi> / <psi|s|psi>
-        all_name = {("T", "T")} | {(f"P_{l1}_{l2}_{orbit}", f"P_{l1}_{l2}_{orbit}") for l1 in range(self.owner.L1)
-                                   for l2 in range(self.owner.L2) for orbit in self.owner.physics_edges[l1, l2]}
+        all_name = {("T", "T")} | {(f"P_{l1}_{l2}_{orbit}", f"P_{l1}_{l2}_{orbit}")
+                                   for l1 in range(self.owner.L1)
+                                   for l2 in range(self.owner.L2)
+                                   for orbit in self.owner.physics_edges[l1, l2]}
         for name, observers in self._observer.items():
             if name == "energy":
                 Es = 0.0
             for positions, observer in observers.items():
                 body = len(positions)
                 positions_configuration = tuple(configuration[l1l2o] for l1l2o in positions)
                 element_pool = tensor_element(observer)
@@ -404,14 +409,30 @@
                         if self._cache_natural_delta:
                             with open(os.path.join(self._cache_natural_delta, str(mpi_rank)), "ab") as file:
                                 pickle.dump(holes, file)
                             self._Deltas.append((reweight, Es, None))
                         else:
                             self._Deltas.append((reweight, Es, holes))
 
+    @property
+    def stability(self):
+        """
+        The stability of the sampling method.
+        """
+        N = self._count
+        expect = self._total_weight / N
+        expect_square = expect**2
+        square_expect = self._total_weight_square / N
+        variance = square_expect - expect_square
+        if variance < 0.0:
+            deviation = 0.0
+        else:
+            deviation = variance**0.5
+        return deviation / expect
+
     def _expect_and_deviation(self, total_reweight, total_reweight_square, total_square_reweight_square):
         """
         Get the expect value and deviation.
 
         Parameters
         ----------
         total_reweight : float
@@ -454,17 +475,18 @@
         Returns
         -------
         dict[str, dict[tuple[tuple[int, int, int], ...], tuple[float, float]]]
             The observer result of each observer set name and each site positions list.
         """
         return {
             name: {
-                positions: self._expect_and_deviation(self._result_reweight[name][positions],
-                                                      self._result_reweight_square[name][positions],
-                                                      self._result_square_reweight_square[name][positions])
+                positions:
+                    self._expect_and_deviation(self._result_reweight[name][positions],
+                                               self._result_reweight_square[name][positions],
+                                               self._result_square_reweight_square[name][positions])
                 for positions in data
             } for name, data in self._observer.items()
         }
 
     @property
     def total_energy(self):
         """
@@ -562,62 +584,66 @@
         delta = self._delta_to_array(self._Delta) / self._total_weight
 
         dtype = np.dtype(self.owner.Tensor.dtype)
         btype = self.owner.Tensor.btype
 
         Delta = []
         Energy = []
-        for _, energy_s, delta_s in self._weights_and_deltas():
-            Delta.append(self._delta_to_array(delta_s) - delta)
-            Energy.append(energy_s.conjugate() - energy)
-        Delta = np.asfortranarray(Delta, dtype=dtype)
-        Energy = np.asfortranarray(Energy, dtype=dtype)
+        for reweight_s, energy_s, delta_s in self._weights_and_deltas():
+            param = (reweight_s / self._total_weight)**(1 / 2)
+            Delta.append((self._delta_to_array(delta_s) - delta) * param)
+            Energy.append((energy_s.conjugate() - energy) * param)
+        Delta = np.asarray(Delta, dtype=dtype)
+        Energy = np.asarray(Energy, dtype=dtype)
 
         # A x = b
-        # AT A x = AT b
-        b = Energy  # Ns
-        b_square = mpi_comm.allreduce(np.dot(np.conj(b), b).real)
+        # DT r D x = DT r E
 
-        # A = Delta, NsNp
-        def A(v):
+        # Delta, NsNp
+        def D(v):
             return Delta @ v
 
-        def AT(v):
+        def DT(v):
             result = np.conj(Delta.T) @ v
             allreduce_buffer(result)
             return result
 
-        x = np.zeros_like(Delta[0])  # Np
-        r = b - A(x)  # Ns
-        p = s = AT(r)  # Np
-        gamma = (np.conj(s) @ s).real
+        def A(v):
+            return DT(D(v))
+
+        b = DT(Energy)
+        b_square = np.dot(np.conj(b), b).real
+
+        x = np.zeros_like(b)
+        r = b - A(x)
+        p = r
+        r_square = np.dot(np.conj(r), r).real
         # loop
         t = 0
         while True:
             if t == step:
                 reason = "max step count reached"
                 break
             if error != 0.0:
-                if error**2 > gamma / b_square:
-                    reason = "gamma is small enough"
+                if error**2 > r_square / b_square:
+                    reason = "r^2 is small enough"
                     break
-            show(f"conjugate gradient step={t} gamma/b^2={gamma/b_square}")
-            q = A(p)
-            alpha = gamma / mpi_comm.allreduce((np.conj(q) @ q).real)
+            show(f"conjugate gradient step={t} r^2/b^2={r_square/b_square}")
+            Dp = D(p)
+            alpha = r_square / mpi_comm.allreduce((np.conj(Dp) @ Dp).real)
             x = x + alpha * p
-            r = r - alpha * q
-            s = AT(r)
-            new_gamma = (np.conj(s) @ s).real
-            beta = new_gamma / gamma
-            gamma = new_gamma
-            p = s + beta * p
+            r = r - alpha * DT(Dp)
+            new_r_square = np.dot(np.conj(r), r).real
+            beta = new_r_square / r_square
+            r_square = new_r_square
+            p = r + beta * p
             t += 1
 
         x = 2 * x
-        showln(f"natural gradient calculated step={t} gamma/b^2={gamma/b_square} {reason}")
+        showln(f"natural gradient calculated step={t} r^2/b^2={r_square/b_square} {reason}")
         return lattice_conjugate(self._array_to_delta(np.conj(x)))
 
     def _delta_to_array(self, delta):
         # Both delta and result array is in bra space
         result = []
         for l1, l2 in self.owner.sites():
             result.append(delta[l1][l2].transpose(self._Delta[l1][l2].names).storage)
```

## tetragono/sampling_lattice/sampling.py

```diff
@@ -295,16 +295,17 @@
                     rho = []
                     for seg in hole_edge.segments:
                         symmetry, _ = seg
                         block_rho = hole.blocks[[("I", -symmetry), ("O", symmetry)]]
                         diag_rho = np.diagonal(block_rho)
                         rho = [*rho, *diag_rho]
                     rho = np.array(rho).real
-                    if len(rho) == 0:
-                        # Block mismatch, redo a sampling.
+                    rho = np.maximum(rho, 0)  # Sometimes there is some negative value because of numeric error.
+                    if np.sum(rho) == 0:
+                        # Block mismatch, or total possibility at this step too small, redo a sampling.
                         return self()
                     rho = rho / np.sum(rho)
                     choice = self._choice(random(), rho)
                     # Choose the configuration of this orbit
                     possibility *= rho[choice]
                     config[orbit] = configuration[l1, l2, orbit] = hole_edge.point_by_index(choice)
                     # config updated for this orbit, now calculating the next item of iterator becomes valid.
```

## Comparing `tetragono-0.3.5.dist-info/METADATA` & `tetragono-0.3.6.dist-info/METADATA`

 * *Files 6% similar despite different names*

```diff
@@ -1,28 +1,25 @@
 Metadata-Version: 2.1
 Name: tetragono
-Version: 0.3.5
+Version: 0.3.6
 Summary: OBC square tensor network state(PEPS) library
 Home-page: https://github.com/USTC-TNS/TAT/tree/TAT/tetragono
 Author: Hao Zhang
 Author-email: zh970205@mail.ustc.edu.cn
 License: GPLv3
-Platform: UNKNOWN
 Requires-Python: >=3.8
 Description-Content-Type: text/markdown
-Requires-Dist: PyScalapack (==0.3.5)
-Requires-Dist: PyTAT (==0.3.5)
-Requires-Dist: lazy-graph (==0.3.5)
+Requires-Dist: PyTAT (==0.3.6)
+Requires-Dist: lazy-graph (==0.3.6)
+Requires-Dist: tetraux (==0.3.6)
+Requires-Dist: PyScalapack (==0.3.6)
 Requires-Dist: mpi4py
 Requires-Dist: numpy
-Requires-Dist: tetraux (==0.3.5)
 Provides-Extra: aps
 Requires-Dist: torch ; extra == 'aps'
 
 
 
 # tetragono
 
 tetragono is an OBC square tensor network state(PEPS) library.
 
-
-
```

## Comparing `tetragono-0.3.5.dist-info/RECORD` & `tetragono-0.3.6.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,46 +1,46 @@
 tetragono/__init__.py,sha256=SKDpJ8rfvKr1kEsQ8oYf0E3nXj-w4nvsuZXJwwFcTLE,1227
 tetragono/abstract_lattice.py,sha256=Wdwe7kiQ5hab0FOykkLkz0HlJw29YKG7fUgoJI5XVTY,7329
 tetragono/abstract_state.py,sha256=R5E4F9LqiAgWM1O8H5TpGbfWBHQ3MjOU-iw9bPVIkYE,15984
 tetragono/common_toolkit.py,sha256=ac1JNadKD1cWVndPUpYGbPwvXEhfH5ldgSQ8_yVmw9Q,8264
 tetragono/conversion.py,sha256=Yi264qNKnv4Q21opgyAVzXWxEyKelkcwUl8QICATpDU,3757
-tetragono/exact_state.py,sha256=x5XssjNLzbk-yT-XJVQnJQN1I8zraIiL8JWO8SkISqQ,7561
-tetragono/shell.py,sha256=RRgoB6gfu4Hcnoje276yrDx9ppJLBNtE5-koVWtbYJA,26080
-tetragono/simple_update_lattice.py,sha256=HgT5XFjkigt4lIiWFsVwW9xpjOwjPpxhFz-VhLJutDY,35546
+tetragono/exact_state.py,sha256=HRNaQX42CrK79tFz68-7fxFfjYLe1JMdUwjlUtFrryQ,7674
+tetragono/shell.py,sha256=bT0TgxJtoBo4xSqDg73n2YnPETZ2EcbmrEom1pV2EQo,22956
+tetragono/simple_update_lattice.py,sha256=m2olxl9Ly22AHB2d2cSFlPvXju9wTsyLEuHvV4mwDGw,35857
 tetragono/tensor_element.py,sha256=yKK4n9zXetbB88ph-tmKwilNE2JoLrfKaeuTL9vH-Jk,3985
 tetragono/ansatz_product_state/__init__.py,sha256=5DBFvqxJ_GtLb_jZMgK32JF-fKU9gL6_kCDWX8wEdyA,893
-tetragono/ansatz_product_state/gradient.py,sha256=IHuLe6w3rMapm5eawSUuyxS9lptXWNzud-cWuo278hs,13309
-tetragono/ansatz_product_state/observer.py,sha256=Tk3MbplDZxf9euu1A9uRTmtMg-glLrfR5ln1GP0xZVE,24023
+tetragono/ansatz_product_state/gradient.py,sha256=Y4P0p-U87lZgoXoSaob5HVU7b8KGy4EFxK_Ykcsuht0,13383
+tetragono/ansatz_product_state/observer.py,sha256=e2WclUYhYb4lOfX4GqAY4ivPFMoU8yUKUjQf72axFmo,24064
 tetragono/ansatz_product_state/sampling.py,sha256=jaiXSo8kEb0Z3ZbBlXan6wT4IouWXc6XHd2b_0Vs61M,10305
-tetragono/ansatz_product_state/state.py,sha256=yDWnwBpaDdV91tH3_5NpLeXJ63779GY2ghBJNK5a3P0,7583
+tetragono/ansatz_product_state/state.py,sha256=CW5r3HseZIgfQqNGKlYcH07KbRnmn5Z30byySr6UI_s,7554
 tetragono/ansatz_product_state/ansatzes/__init__.py,sha256=oTL4gsJmuzAmV2JWUwNBlQw1c1FmHDWTdZgNp5T67cw,1637
 tetragono/ansatz_product_state/ansatzes/abstract_ansatz.py,sha256=XvgFkcFI5ALsqraO-7-W4ADIZH3Etq4NFMPxQ1EovBc,7838
 tetragono/ansatz_product_state/ansatzes/closed_string.py,sha256=LZAMLHq2r2lXyynarrzxnaK9iFW88CjjYmj8xfsYZBc,7510
 tetragono/ansatz_product_state/ansatzes/convolutional_neural.py,sha256=kgBfnoomM71IH8so_QdOiyNz-1Wg0Px4g8gfIJ6bJGY,5321
 tetragono/ansatz_product_state/ansatzes/marshall.py,sha256=cHk7W8HCyuzYs92utZmmJLD3oL5-iSMiHwsyTinfHOA,2134
 tetragono/ansatz_product_state/ansatzes/open_string.py,sha256=EAG1SjaC8dB5t9d9QWc9gWMDUSRwH4gJwfxFRWsKANc,7560
 tetragono/ansatz_product_state/ansatzes/product_ansatz.py,sha256=sBdoEXcuft_M8Tkl28Ne70zno0fugB4YzG_klwSOIMc,6634
 tetragono/ansatz_product_state/ansatzes/sum_ansatz.py,sha256=Yal-sACb5O50UZZSBleuO-MQveFJVrnfgsGdfBRoFbM,6596
 tetragono/auxiliaries/__init__.py,sha256=BuElunryV7uhMGZcmNFeWaOBTtgw-zmWcMedQwtQdQg,911
-tetragono/auxiliaries/double_layer_auxiliaries.py,sha256=uMKwEsPuIwfjq52ILeb3DIct5KDsuoGEmKEl5GkW3LA,33568
+tetragono/auxiliaries/double_layer_auxiliaries.py,sha256=VV0QpO5oEX3N_Ygvp2FpvIMTU65rBRuRKDYX7ZLGZsQ,34048
 tetragono/auxiliaries/single_layer_auxiliaries.py,sha256=De2XW5MY9NXrC7tyoBM1feUCPXs_jaBgV9egXuX9FpY,43009
 tetragono/auxiliaries/three_line_auxiliaries.py,sha256=ssjaSKrv0MYewI95jCLSrhNGDbyeWRwf-RS6qXfXQHU,7828
-tetragono/common_tensor/Fermi.py,sha256=WB6zXE2KPHrXASAW46XXxEIBCcmUiCMOERjJreLQFs0,1288
-tetragono/common_tensor/FermiU1_tJ.py,sha256=ikuPuPH-4-bJfEA_e8pFkc4CNSGSqabP-9vqbsN8vjE,2603
+tetragono/common_tensor/Fermi.py,sha256=by8IFqkOM57fJV6s9BQUoUw4wbQoIvWav4uTYNxDHn8,1300
+tetragono/common_tensor/FermiU1_tJ.py,sha256=0hQb9mZQ2unqSAoieIZczWXOKbjvQrmddEi1j4SDjrI,2627
 tetragono/common_tensor/Fermi_Hubbard.py,sha256=tPTRNi3eaTDsm12re4I8n3pl8ypfVFeK2rzYZL2Lyx4,2386
 tetragono/common_tensor/No.py,sha256=6GLdNks-lZ2RSsgzjNB7NYAK1rU8uFNNdUPDTDdG3C8,1638
-tetragono/common_tensor/Parity.py,sha256=wWwGGhu4b-IKa3BxIWY-HoZvACMUtpht8w38uoQiOZ0,1411
+tetragono/common_tensor/Parity.py,sha256=xNX090aL8otsqG4CUk7LF6vAGQaKyiwfqxp_6ryVRTk,1423
 tetragono/common_tensor/Parity_Hubbard.py,sha256=6MMPhyblf41ORGAkrDdZwUoLybmF-c_WghxMMsYM2B0,2382
 tetragono/common_tensor/__init__.py,sha256=cqKSR7Jm5-hpbY0e_dRrfVba8RldEohOqpZr2DnyPwM,872
 tetragono/common_tensor/tensor_toolkit.py,sha256=XWZOlARsC2-BAQDJ1loixb7oqsnfG6FYjf4WuW1G1lI,1506
 tetragono/sampling_lattice/__init__.py,sha256=Ep2mwoPBKbpgAd4tmJAKJoUnvAJOvjpxack4TxPZsP8,884
-tetragono/sampling_lattice/gradient.py,sha256=YMb81CKVuTU9rPgUSPBiqaEXKwnFElTMoChZx7uNYdk,14463
-tetragono/sampling_lattice/lattice.py,sha256=5M7q1I1ZA3HW-C08R26aJVutKhNyy-YqfMpbeTGqHIo,32329
-tetragono/sampling_lattice/observer.py,sha256=oCxsPtU0YMTRmkzQpMrdKL3AQOL0zZ5PDsP8tCu0l90,34709
-tetragono/sampling_lattice/sampling.py,sha256=dLPvFs-NF2Iy9EZbRs98LtwG_Ulu-KYYCJhWLw7tooM,15311
+tetragono/sampling_lattice/gradient.py,sha256=-cmdy03-U8WCSN2mMayKToQsFdeSZY1ouetSPpKo2ac,14658
+tetragono/sampling_lattice/lattice.py,sha256=qNgrpSr4VxjgXbDH2YZ_96PkCiQtGdeSJfB7-eyCr5o,35897
+tetragono/sampling_lattice/observer.py,sha256=WYdyJX6Pfy8sONarpdjUuTCJc_KbhBgay-MzZXiMomM,35361
+tetragono/sampling_lattice/sampling.py,sha256=aLhkjiXfe6-Y6ItFdDlByzvoA01VIofsfzX81KYJVRQ,15472
 tetragono/sampling_lattice/squash/__init__.py,sha256=2bhLts1_sFa3WNmqRdYaZv1CiFfa62LqKWT53Knz994,731
 tetragono/sampling_lattice/squash/horizontal.py,sha256=qVC_foae5bSyXFEDY3lSPAnklCcy50ALtCCm6_q1A2Y,6063
 tetragono/sampling_lattice/squash/vertical.py,sha256=AunBlkcaynMTmsmAQhmounBwQZ8PE11wwFymoKxu6OQ,6088
-tetragono-0.3.5.dist-info/METADATA,sha256=3fGqb1l5EnErzo-aJosj2ke04tv90iSHQ9syyghRj6I,644
-tetragono-0.3.5.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-tetragono-0.3.5.dist-info/top_level.txt,sha256=J168-VGmhebpOx5plaLrG-AKOYYuPUXo4M8TzdlklTo,10
-tetragono-0.3.5.dist-info/RECORD,,
+tetragono-0.3.6.dist-info/METADATA,sha256=uWhZrvPk5FkxQb8pYuMFpEG4ssICYw_M0xmypanmxdk,624
+tetragono-0.3.6.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+tetragono-0.3.6.dist-info/top_level.txt,sha256=J168-VGmhebpOx5plaLrG-AKOYYuPUXo4M8TzdlklTo,10
+tetragono-0.3.6.dist-info/RECORD,,
```

