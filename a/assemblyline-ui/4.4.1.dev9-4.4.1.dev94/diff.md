# Comparing `tmp/assemblyline_ui-4.4.1.dev9-py3-none-any.whl.zip` & `tmp/assemblyline_ui-4.4.1.dev94-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,70 +1,72 @@
-Zip file size: 143521 bytes, number of entries: 68
--rw-r--r--  2.0 unx       11 b- defN 23-Mar-24 16:14 assemblyline_ui/VERSION
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-24 16:13 assemblyline_ui/__init__.py
--rw-r--r--  2.0 unx     5518 b- defN 23-Mar-24 16:13 assemblyline_ui/app.py
--rw-r--r--  2.0 unx     5373 b- defN 23-Mar-24 16:13 assemblyline_ui/config.py
--rw-r--r--  2.0 unx     3598 b- defN 23-Mar-24 16:13 assemblyline_ui/error.py
--rw-r--r--  2.0 unx      740 b- defN 23-Mar-24 16:13 assemblyline_ui/gunicorn_config.py
--rw-r--r--  2.0 unx      115 b- defN 23-Mar-24 16:13 assemblyline_ui/gunicorn_config_socketio.py
--rw-r--r--  2.0 unx      777 b- defN 23-Mar-24 16:13 assemblyline_ui/healthz.py
--rw-r--r--  2.0 unx      199 b- defN 23-Mar-24 16:13 assemblyline_ui/http_exceptions.py
--rw-r--r--  2.0 unx     2322 b- defN 23-Mar-24 16:13 assemblyline_ui/logger.py
--rw-r--r--  2.0 unx       85 b- defN 23-Mar-24 16:13 assemblyline_ui/patched.py
--rw-r--r--  2.0 unx     2359 b- defN 23-Mar-24 16:13 assemblyline_ui/socketsrv.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-24 16:13 assemblyline_ui/api/__init__.py
--rw-r--r--  2.0 unx    14347 b- defN 23-Mar-24 16:13 assemblyline_ui/api/base.py
--rw-r--r--  2.0 unx     3915 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/__init__.py
--rw-r--r--  2.0 unx    28791 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/alert.py
--rw-r--r--  2.0 unx     2289 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/archive.py
--rw-r--r--  2.0 unx    33320 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/authentication.py
--rw-r--r--  2.0 unx     5141 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/bundle.py
--rw-r--r--  2.0 unx     2560 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/error.py
--rw-r--r--  2.0 unx    28236 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/file.py
--rw-r--r--  2.0 unx     4776 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/hash_search.py
--rw-r--r--  2.0 unx     6238 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/help.py
--rw-r--r--  2.0 unx     2910 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/heuristics.py
--rw-r--r--  2.0 unx    20313 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/ingest.py
--rw-r--r--  2.0 unx     5425 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/live.py
--rw-r--r--  2.0 unx    13149 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/ontology.py
--rw-r--r--  2.0 unx     6271 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/replay.py
--rw-r--r--  2.0 unx     6203 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/result.py
--rw-r--r--  2.0 unx     6278 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/retrohunt.py
--rw-r--r--  2.0 unx    17916 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/safelist.py
--rw-r--r--  2.0 unx    17041 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/search.py
--rw-r--r--  2.0 unx    38520 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/service.py
--rw-r--r--  2.0 unx    33326 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/signature.py
--rw-r--r--  2.0 unx    41933 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/submission.py
--rw-r--r--  2.0 unx    20050 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/submit.py
--rw-r--r--  2.0 unx    20300 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/system.py
--rw-r--r--  2.0 unx    11453 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/ui.py
--rw-r--r--  2.0 unx    36368 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/user.py
--rw-r--r--  2.0 unx     4734 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/webauthn.py
--rw-r--r--  2.0 unx     7060 b- defN 23-Mar-24 16:13 assemblyline_ui/api/v4/workflow.py
--rw-r--r--  2.0 unx        1 b- defN 23-Mar-24 16:13 assemblyline_ui/helper/__init__.py
--rw-r--r--  2.0 unx     1686 b- defN 23-Mar-24 16:13 assemblyline_ui/helper/discover.py
--rw-r--r--  2.0 unx     6611 b- defN 23-Mar-24 16:13 assemblyline_ui/helper/oauth.py
--rw-r--r--  2.0 unx     4926 b- defN 23-Mar-24 16:13 assemblyline_ui/helper/result.py
--rw-r--r--  2.0 unx     1642 b- defN 23-Mar-24 16:13 assemblyline_ui/helper/search.py
--rw-r--r--  2.0 unx     2938 b- defN 23-Mar-24 16:13 assemblyline_ui/helper/service.py
--rw-r--r--  2.0 unx      899 b- defN 23-Mar-24 16:13 assemblyline_ui/helper/signature.py
--rw-r--r--  2.0 unx     6834 b- defN 23-Mar-24 16:13 assemblyline_ui/helper/submission.py
--rw-r--r--  2.0 unx     6894 b- defN 23-Mar-24 16:13 assemblyline_ui/helper/user.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-24 16:13 assemblyline_ui/security/__init__.py
--rw-r--r--  2.0 unx     1337 b- defN 23-Mar-24 16:13 assemblyline_ui/security/apikey_auth.py
--rw-r--r--  2.0 unx    10096 b- defN 23-Mar-24 16:13 assemblyline_ui/security/authenticator.py
--rw-r--r--  2.0 unx    12233 b- defN 23-Mar-24 16:13 assemblyline_ui/security/ldap_auth.py
--rw-r--r--  2.0 unx     2838 b- defN 23-Mar-24 16:13 assemblyline_ui/security/oauth_auth.py
--rw-r--r--  2.0 unx     2913 b- defN 23-Mar-24 16:13 assemblyline_ui/security/second_factor_auth.py
--rw-r--r--  2.0 unx      675 b- defN 23-Mar-24 16:13 assemblyline_ui/security/userpass_auth.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-24 16:13 assemblyline_ui/sio/__init__.py
--rw-r--r--  2.0 unx     2170 b- defN 23-Mar-24 16:13 assemblyline_ui/sio/alert.py
--rw-r--r--  2.0 unx     3529 b- defN 23-Mar-24 16:13 assemblyline_ui/sio/base.py
--rw-r--r--  2.0 unx     4158 b- defN 23-Mar-24 16:13 assemblyline_ui/sio/live_submission.py
--rw-r--r--  2.0 unx     1980 b- defN 23-Mar-24 16:13 assemblyline_ui/sio/status.py
--rw-r--r--  2.0 unx     2222 b- defN 23-Mar-24 16:13 assemblyline_ui/sio/submission.py
--rw-r--r--  2.0 unx     1396 b- defN 23-Mar-24 16:14 assemblyline_ui-4.4.1.dev9.dist-info/LICENCE.md
--rw-r--r--  2.0 unx     2839 b- defN 23-Mar-24 16:14 assemblyline_ui-4.4.1.dev9.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Mar-24 16:14 assemblyline_ui-4.4.1.dev9.dist-info/WHEEL
--rw-r--r--  2.0 unx       16 b- defN 23-Mar-24 16:14 assemblyline_ui-4.4.1.dev9.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     6082 b- defN 23-Mar-24 16:14 assemblyline_ui-4.4.1.dev9.dist-info/RECORD
-68 files, 546967 bytes uncompressed, 133787 bytes compressed:  75.5%
+Zip file size: 150268 bytes, number of entries: 70
+-rw-r--r--  2.0 unx       12 b- defN 23-May-25 21:44 assemblyline_ui/VERSION
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 21:44 assemblyline_ui/__init__.py
+-rw-r--r--  2.0 unx     5636 b- defN 23-May-25 21:44 assemblyline_ui/app.py
+-rw-r--r--  2.0 unx     5453 b- defN 23-May-25 21:44 assemblyline_ui/config.py
+-rw-r--r--  2.0 unx     3598 b- defN 23-May-25 21:44 assemblyline_ui/error.py
+-rw-r--r--  2.0 unx      740 b- defN 23-May-25 21:44 assemblyline_ui/gunicorn_config.py
+-rw-r--r--  2.0 unx      115 b- defN 23-May-25 21:44 assemblyline_ui/gunicorn_config_socketio.py
+-rw-r--r--  2.0 unx      777 b- defN 23-May-25 21:44 assemblyline_ui/healthz.py
+-rw-r--r--  2.0 unx      199 b- defN 23-May-25 21:44 assemblyline_ui/http_exceptions.py
+-rw-r--r--  2.0 unx     2322 b- defN 23-May-25 21:44 assemblyline_ui/logger.py
+-rw-r--r--  2.0 unx       85 b- defN 23-May-25 21:44 assemblyline_ui/patched.py
+-rw-r--r--  2.0 unx     2479 b- defN 23-May-25 21:44 assemblyline_ui/socketsrv.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 21:44 assemblyline_ui/api/__init__.py
+-rw-r--r--  2.0 unx    14347 b- defN 23-May-25 21:44 assemblyline_ui/api/base.py
+-rw-r--r--  2.0 unx     3915 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/__init__.py
+-rw-r--r--  2.0 unx    28791 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/alert.py
+-rw-r--r--  2.0 unx     2289 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/archive.py
+-rw-r--r--  2.0 unx    33295 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/authentication.py
+-rw-r--r--  2.0 unx     5141 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/bundle.py
+-rw-r--r--  2.0 unx     2560 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/error.py
+-rw-r--r--  2.0 unx     9712 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/federated_lookup.py
+-rw-r--r--  2.0 unx    37202 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/file.py
+-rw-r--r--  2.0 unx     4776 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/hash_search.py
+-rw-r--r--  2.0 unx     6367 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/help.py
+-rw-r--r--  2.0 unx     2910 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/heuristics.py
+-rw-r--r--  2.0 unx    20361 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/ingest.py
+-rw-r--r--  2.0 unx     5477 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/live.py
+-rw-r--r--  2.0 unx    13149 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/ontology.py
+-rw-r--r--  2.0 unx     6273 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/replay.py
+-rw-r--r--  2.0 unx     6203 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/result.py
+-rw-r--r--  2.0 unx     7353 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/retrohunt.py
+-rw-r--r--  2.0 unx    17918 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/safelist.py
+-rw-r--r--  2.0 unx    19968 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/search.py
+-rw-r--r--  2.0 unx    39047 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/service.py
+-rw-r--r--  2.0 unx    33949 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/signature.py
+-rw-r--r--  2.0 unx    41999 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/submission.py
+-rw-r--r--  2.0 unx    20085 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/submit.py
+-rw-r--r--  2.0 unx    20300 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/system.py
+-rw-r--r--  2.0 unx    11502 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/ui.py
+-rw-r--r--  2.0 unx    37121 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/user.py
+-rw-r--r--  2.0 unx     4734 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/webauthn.py
+-rw-r--r--  2.0 unx     7060 b- defN 23-May-25 21:44 assemblyline_ui/api/v4/workflow.py
+-rw-r--r--  2.0 unx        1 b- defN 23-May-25 21:44 assemblyline_ui/helper/__init__.py
+-rw-r--r--  2.0 unx     1686 b- defN 23-May-25 21:44 assemblyline_ui/helper/discover.py
+-rw-r--r--  2.0 unx     7315 b- defN 23-May-25 21:44 assemblyline_ui/helper/oauth.py
+-rw-r--r--  2.0 unx     4926 b- defN 23-May-25 21:44 assemblyline_ui/helper/result.py
+-rw-r--r--  2.0 unx     1620 b- defN 23-May-25 21:44 assemblyline_ui/helper/search.py
+-rw-r--r--  2.0 unx     3218 b- defN 23-May-25 21:44 assemblyline_ui/helper/service.py
+-rw-r--r--  2.0 unx      899 b- defN 23-May-25 21:44 assemblyline_ui/helper/signature.py
+-rw-r--r--  2.0 unx     6835 b- defN 23-May-25 21:44 assemblyline_ui/helper/submission.py
+-rw-r--r--  2.0 unx     7568 b- defN 23-May-25 21:44 assemblyline_ui/helper/user.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 21:44 assemblyline_ui/security/__init__.py
+-rw-r--r--  2.0 unx     1337 b- defN 23-May-25 21:44 assemblyline_ui/security/apikey_auth.py
+-rw-r--r--  2.0 unx    10096 b- defN 23-May-25 21:44 assemblyline_ui/security/authenticator.py
+-rw-r--r--  2.0 unx    12880 b- defN 23-May-25 21:44 assemblyline_ui/security/ldap_auth.py
+-rw-r--r--  2.0 unx     2838 b- defN 23-May-25 21:44 assemblyline_ui/security/oauth_auth.py
+-rw-r--r--  2.0 unx     2913 b- defN 23-May-25 21:44 assemblyline_ui/security/second_factor_auth.py
+-rw-r--r--  2.0 unx      675 b- defN 23-May-25 21:44 assemblyline_ui/security/userpass_auth.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 21:44 assemblyline_ui/sio/__init__.py
+-rw-r--r--  2.0 unx     2170 b- defN 23-May-25 21:44 assemblyline_ui/sio/alert.py
+-rw-r--r--  2.0 unx     3529 b- defN 23-May-25 21:44 assemblyline_ui/sio/base.py
+-rw-r--r--  2.0 unx     1174 b- defN 23-May-25 21:44 assemblyline_ui/sio/file.py
+-rw-r--r--  2.0 unx     4158 b- defN 23-May-25 21:44 assemblyline_ui/sio/live_submission.py
+-rw-r--r--  2.0 unx     1980 b- defN 23-May-25 21:44 assemblyline_ui/sio/status.py
+-rw-r--r--  2.0 unx     2222 b- defN 23-May-25 21:44 assemblyline_ui/sio/submission.py
+-rw-r--r--  2.0 unx     1396 b- defN 23-May-25 21:44 assemblyline_ui-4.4.1.dev94.dist-info/LICENCE.md
+-rw-r--r--  2.0 unx     2861 b- defN 23-May-25 21:44 assemblyline_ui-4.4.1.dev94.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-25 21:44 assemblyline_ui-4.4.1.dev94.dist-info/WHEEL
+-rw-r--r--  2.0 unx       16 b- defN 23-May-25 21:44 assemblyline_ui-4.4.1.dev94.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     6270 b- defN 23-May-25 21:44 assemblyline_ui-4.4.1.dev94.dist-info/RECORD
+70 files, 575895 bytes uncompressed, 140234 bytes compressed:  75.6%
```

## zipnote {}

```diff
@@ -54,14 +54,17 @@
 
 Filename: assemblyline_ui/api/v4/bundle.py
 Comment: 
 
 Filename: assemblyline_ui/api/v4/error.py
 Comment: 
 
+Filename: assemblyline_ui/api/v4/federated_lookup.py
+Comment: 
+
 Filename: assemblyline_ui/api/v4/file.py
 Comment: 
 
 Filename: assemblyline_ui/api/v4/hash_search.py
 Comment: 
 
 Filename: assemblyline_ui/api/v4/help.py
@@ -174,32 +177,35 @@
 
 Filename: assemblyline_ui/sio/alert.py
 Comment: 
 
 Filename: assemblyline_ui/sio/base.py
 Comment: 
 
+Filename: assemblyline_ui/sio/file.py
+Comment: 
+
 Filename: assemblyline_ui/sio/live_submission.py
 Comment: 
 
 Filename: assemblyline_ui/sio/status.py
 Comment: 
 
 Filename: assemblyline_ui/sio/submission.py
 Comment: 
 
-Filename: assemblyline_ui-4.4.1.dev9.dist-info/LICENCE.md
+Filename: assemblyline_ui-4.4.1.dev94.dist-info/LICENCE.md
 Comment: 
 
-Filename: assemblyline_ui-4.4.1.dev9.dist-info/METADATA
+Filename: assemblyline_ui-4.4.1.dev94.dist-info/METADATA
 Comment: 
 
-Filename: assemblyline_ui-4.4.1.dev9.dist-info/WHEEL
+Filename: assemblyline_ui-4.4.1.dev94.dist-info/WHEEL
 Comment: 
 
-Filename: assemblyline_ui-4.4.1.dev9.dist-info/top_level.txt
+Filename: assemblyline_ui-4.4.1.dev94.dist-info/top_level.txt
 Comment: 
 
-Filename: assemblyline_ui-4.4.1.dev9.dist-info/RECORD
+Filename: assemblyline_ui-4.4.1.dev94.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## assemblyline_ui/VERSION

```diff
@@ -1 +1 @@
-4.4.1.dev9
+4.4.1.dev94
```

## assemblyline_ui/app.py

```diff
@@ -10,14 +10,15 @@
 from assemblyline_ui.api.base import api
 from assemblyline_ui.api.v4 import apiv4
 from assemblyline_ui.api.v4.alert import alert_api
 from assemblyline_ui.api.v4.archive import archive_api
 from assemblyline_ui.api.v4.authentication import auth_api
 from assemblyline_ui.api.v4.bundle import bundle_api
 from assemblyline_ui.api.v4.error import error_api
+from assemblyline_ui.api.v4.federated_lookup import federated_lookup_api
 from assemblyline_ui.api.v4.file import file_api
 from assemblyline_ui.api.v4.hash_search import hash_search_api
 from assemblyline_ui.api.v4.help import help_api
 from assemblyline_ui.api.v4.heuristics import heuristics_api
 from assemblyline_ui.api.v4.ingest import ingest_api
 from assemblyline_ui.api.v4.live import live_api
 from assemblyline_ui.api.v4.ontology import ontology_api
@@ -72,14 +73,15 @@
 app.register_blueprint(apiv4)
 app.register_blueprint(alert_api)
 app.register_blueprint(archive_api)
 app.register_blueprint(auth_api)
 app.register_blueprint(bundle_api)
 app.register_blueprint(errors)
 app.register_blueprint(error_api)
+app.register_blueprint(federated_lookup_api)
 app.register_blueprint(file_api)
 app.register_blueprint(hash_search_api)
 app.register_blueprint(help_api)
 app.register_blueprint(heuristics_api)
 app.register_blueprint(ingest_api)
 app.register_blueprint(live_api)
 app.register_blueprint(ontology_api)
```

## assemblyline_ui/config.py

```diff
@@ -84,35 +84,37 @@
 config.logging.log_to_console = config.logging.log_to_console or DEBUG
 al_log.init_logging("ui", config=config)
 
 AUDIT_KW_TARGET = ["sid",
                    "sha256",
                    "copy_sid",
                    "filter",
+                   "filters",
                    "query",
                    "username",
                    "group",
                    "rev",
-                   "wq_id",
-                   "bucket",
+                   "index",
                    "cache_key",
                    "alert_key",
                    "alert_id",
                    "url",
                    "q",
                    "fq",
                    "file_hash",
                    "heuristic_id",
                    "error_key",
-                   "mac",
-                   "vm_type",
-                   "vm_name",
                    "config_name",
                    "servicename",
-                   "vm"]
+                   "service_name",
+                   "qhash",
+                   "enabled",
+                   "is_active",
+                   "submission_id",
+                   "doc_id"]
 
 AUDIT_LOG = logging.getLogger('assemblyline.ui.audit')
 LOGGER = logging.getLogger('assemblyline.ui')
 
 if AUDIT:
     AUDIT_LOG.setLevel(logging.INFO)
```

## assemblyline_ui/socketsrv.py

```diff
@@ -9,14 +9,15 @@
 
 from flask import Flask
 from flask_socketio import SocketIO
 
 from assemblyline.common import forge, log as al_log
 from assemblyline_ui.healthz import healthz
 from assemblyline_ui.sio.alert import AlertMonitoringNamespace
+from assemblyline_ui.sio.file import FileCommentNamespace
 from assemblyline_ui.sio.live_submission import LiveSubmissionNamespace
 from assemblyline_ui.sio.status import SystemStatusNamespace
 from assemblyline_ui.sio.submission import SubmissionMonitoringNamespace
 
 CERT_BUNDLE = (
     os.environ.get('SIO_CLIENT_CERT_PATH', '/etc/assemblyline/ssl/sio/tls.crt'),
     os.environ.get('SIO_CLIENT_KEY_PATH', '/etc/assemblyline/ssl/sio/tls.key')
@@ -41,14 +42,15 @@
     app.config['SESSION_COOKIE_PATH'] = '/'
 
 # NOTE: we need to run in threading mode while debugging otherwise, use gevent
 socketio = SocketIO(app, async_mode=os.environ.get('ASYNC_MODE', 'gevent'), cors_allowed_origins='*')
 
 # Loading the different namespaces
 socketio.on_namespace(AlertMonitoringNamespace('/alerts'))
+socketio.on_namespace(FileCommentNamespace('/file_comments'))
 socketio.on_namespace(LiveSubmissionNamespace('/live_submission'))
 socketio.on_namespace(SubmissionMonitoringNamespace('/submissions'))
 socketio.on_namespace(SystemStatusNamespace('/status'))
 
 
 if __name__ == '__main__':
     app.logger.setLevel(config.logging.log_level if config.ui.debug else 60)
```

## assemblyline_ui/api/v4/authentication.py

```diff
@@ -587,15 +587,15 @@
                                     data['uname'] = new_uname
                             cur_user = {}
 
                         username = data['uname']
                         email_adr = data['email']
 
                         # Add add dynamic classification group
-                        data['classification'] = get_dynamic_classification(data['classification'], data['email'])
+                        data['classification'] = get_dynamic_classification(data['classification'], data)
 
                         # Make sure the user exists in AL and is in sync
                         if (not cur_user and oauth_provider_config.auto_create) or \
                                 (cur_user and oauth_provider_config.auto_sync):
 
                             # Update the current user
                             cur_user.update(data)
@@ -838,15 +838,15 @@
     key = hashlib.sha256(get_random_password(length=512).encode('utf-8')).hexdigest()
     try:
         send_signup_email(email, key)
         get_signup_queue(key).add({
             "uname": uname,
             "password": password,
             "email": email,
-            "groups": ['USERS'],
+            "groups": [],
             "name": uname
         })
     except Exception as e:
         LOGGER.warning(f"Sending email for signup process failed: {str(e)}")
         return make_api_response({"success": False}, "The system failed to send signup confirmation link.", 400)
 
     return make_api_response({"success": True})
@@ -890,15 +890,15 @@
             members = signup_queue.members()
             signup_queue.delete()
             if members:
                 user_info = members[0]
 
                 # Add dynamic classification group
                 user_info['classification'] = get_dynamic_classification(
-                    user_info.get('classification', Classification.UNRESTRICTED), user_info['email'])
+                    user_info.get('classification', Classification.UNRESTRICTED), user_info)
 
                 user = User(user_info)
                 username = user.uname
 
                 STORAGE.user.save(username, user)
                 return make_api_response({"success": True})
         except (KeyError, ValueError) as e:
```

## assemblyline_ui/api/v4/file.py

```diff
@@ -3,19 +3,22 @@
 import os
 import re
 import subprocess
 import tempfile
 
 from flask import request
 
+from assemblyline.odm.models.file import Comment
 from assemblyline.odm.models.user_settings import ENCODINGS as FILE_DOWNLOAD_ENCODINGS
 from assemblyline.common.codec import encode_file
 from assemblyline.common.dict_utils import unflatten
 from assemblyline.common.hexdump import dump, hexdump
 from assemblyline.common.str_utils import safe_str
+from assemblyline.datastore.collection import Index
+from assemblyline.datastore.exceptions import DataStoreException
 from assemblyline.filestore import FileStoreException
 from assemblyline.odm.models.user import ROLES
 from assemblyline_ui.api.base import api_login, make_api_response, make_subapi_blueprint, stream_file_response
 from assemblyline_ui.config import ALLOW_ZIP_DOWNLOADS, ALLOW_RAW_DOWNLOADS, FILESTORE, STORAGE, config, \
     CLASSIFICATION as Classification, ARCHIVESTORE
 from assemblyline_ui.helper.result import format_result
 from assemblyline_ui.helper.user import load_user_settings
@@ -85,14 +88,27 @@
 
         if len(processed_sha256) >= 10:
             break
 
     return output
 
 
+def parse_authors(comments):
+    authors = dict([comment['uname'], {}] for comment in comments)
+
+    def parse_author(user, avatar):
+        return {
+            "name": user['name'],
+            "avatar": avatar,
+            "email": user['email'],
+        }
+
+    return dict([author, parse_author(STORAGE.user.get(author), STORAGE.user_avatar.get(author))] for author in authors)
+
+
 @file_api.route("/ascii/<sha256>/", methods=["GET"])
 @api_login(require_role=[ROLES.file_detail])
 def get_file_ascii(sha256, **kwargs):
     """
     Return the ascii values for a file where ascii chars are replaced by DOTs.
 
     Variables:
@@ -137,14 +153,216 @@
             return make_api_response({}, "This file was not found in the system.", 404)
 
         return make_api_response(data.translate(FILTER_ASCII).decode())
     else:
         return make_api_response({}, "You are not allowed to view this file.", 403)
 
 
+@file_api.route("/comment/<sha256>/", methods=["GET"])
+@api_login(require_role=[ROLES.file_detail], allow_readonly=False)
+def get_comments(sha256, **kwargs):
+    """
+    Get all comments with their author made on a given file
+
+    Variables:
+    sha256          => A resource locator for the file (sha256)
+
+    Arguments:
+    None
+
+    Data Block:
+    None
+
+    API call example:
+    /api/v4/file/comment/123456...654321/
+
+    Result example:
+    {
+        authors: {
+            <uname>: {
+                "name":     "Administrator",
+                "avatar":   "data:image/png;base64,123...321",
+                "email":    "admin@assemblyline.cyber.gc.ca"
+            }
+        },
+        comments: [{
+            "cid":      "123...321",
+            "uname"     "admin",
+            "date":     "2023-01-01T12:00:00.000000",
+            "text":     "This is a new comment"
+        }]
+    }
+    """
+
+    file_obj = STORAGE.file.get(sha256, as_obj=False)
+    if not file_obj:
+        return make_api_response({}, "The file was not found in the system.", 404)
+    comments = file_obj.get("comments", [])
+    authors = parse_authors(comments)
+    return make_api_response({"authors": authors, "comments": comments})
+
+
+@file_api.route("/comment/<sha256>/", methods=["PUT"])
+@api_login(require_role=[ROLES.file_detail], allow_readonly=False)
+def add_comment(sha256, **kwargs):
+    """
+    Add a comment to a given file
+
+    Variables:
+    sha256          => A resource locator for the file (sha256)
+
+    Arguments:
+    None
+
+    Data Block:     => Text of the new comment being made
+    {
+        "text": "This is a new comment"
+    }
+
+    API call example:
+    /api/v4/file/comment/123456...654321/
+
+    Result example:
+    {
+        "cid":      "123...321"
+        "uname":    "admin",
+        "date":     "2023-01-01T12:00:00.000000",
+        "text":     "This is a new comment"
+    }
+    """
+
+    data = request.json
+    text = data.get('text', None)
+    if not text:
+        return make_api_response({"success": False}, err="Text field is required", status_code=400)
+
+    file_obj = STORAGE.file.get_if_exists(sha256, as_obj=False)
+    if not file_obj:
+        return make_api_response({}, "The file was not found in the system.", 404)
+
+    user = kwargs['user']
+
+    try:
+        file_obj["comments"].insert(0, Comment({
+            'uname': user['uname'],
+            'text': text
+        }))
+        STORAGE.file.save(sha256, file_obj)
+    except DataStoreException as e:
+        return make_api_response({"success": False}, err=str(e), status_code=400)
+
+    try:
+
+        file_obj = STORAGE.file.get(sha256, as_obj=False)
+        comment = file_obj.get("comments", [])[-1]
+        return make_api_response(comment)
+    except IndexError as e:
+        return make_api_response({"success": False}, err=str(e), status_code=400)
+
+
+@file_api.route("/comment/<sha256>/<cid>/", methods=["POST"])
+@api_login(require_role=[ROLES.file_detail], allow_readonly=False)
+def update_comment(sha256, cid, **kwargs):
+    """
+    Update the comment <cid> in a given file
+
+    Variables:
+    sha256          => A resource locator for the file (sha256)
+    cid             => ID of the comment
+
+    Arguments:
+    None
+
+    Data Block:     => Text of the comment to update
+    {
+        "text": "This is a new comment"
+    }
+
+    API call example:
+    /api/v4/file/comment/123456...654321/123...321/
+
+    Result example: => Comment has been successfully updated
+    { "success": True }
+    """
+
+    data = request.json
+    text = data.get('text', None)
+    if not text:
+        return make_api_response({"success": False}, err="Text field is required", status_code=400)
+
+    file_obj = STORAGE.file.get_if_exists(sha256, as_obj=False)
+    if not file_obj:
+        return make_api_response({"success": False}, "The file was not found in the system.", 404)
+
+    comment_to_be_updated = next(filter(lambda x: x['cid'] == cid, file_obj.get('comments', [])), None)
+    if (comment_to_be_updated is None):
+        return make_api_response({"success": False}, "The comment was not found within the file.", 404)
+
+    user = kwargs['user']
+    if (comment_to_be_updated['uname'] != user['uname']):
+        return make_api_response({"success": False}, "Another user's comment cannot be updated.", 401)
+
+    try:
+        def change_text(c, t):
+            c['text'] = t
+            return c
+        file_obj['comments'] = list(change_text(comment, text) if comment['cid'] ==
+                                    cid else comment for comment in file_obj['comments'])
+
+        STORAGE.file.save(sha256, file_obj)
+    except DataStoreException as e:
+        return make_api_response({"success": False}, err=str(e), status_code=400)
+
+    return make_api_response({"success": True})
+
+
+@file_api.route("/comment/<sha256>/<cid>/", methods=["DELETE"])
+@api_login(require_role=[ROLES.file_detail])
+def delete_comment(sha256, cid, **kwargs):
+    """
+    Delete the comment <cid> in a given file
+
+    Variables:
+    sha256       => A resource locator for the file (sha256)
+    cid          => ID of the comment
+
+    Arguments:
+    None
+
+    Data Block:
+    None
+
+    API call example:
+    /api/v4/file/comment/123456...654321/123...321/
+
+    Result example:
+    {"success": True}   # Has the comment been successfully deleted
+    """
+
+    file_obj = STORAGE.file.get_if_exists(sha256, as_obj=False)
+    if not file_obj:
+        return make_api_response({"success": False}, "The file was not found in the system.", 404)
+
+    comment_to_be_deleted = next(filter(lambda x: x['cid'] == cid, file_obj.get('comments', [])), None)
+    if (comment_to_be_deleted is None):
+        return make_api_response({"success": False}, "The comment was not found within the file.", 404)
+
+    user = kwargs['user']
+    if (comment_to_be_deleted['uname'] != user['uname']):
+        return make_api_response({"success": False}, "Another user's comment cannot be deleted.", 401)
+
+    try:
+        file_obj["comments"] = filter(lambda x: x['cid'] != cid, file_obj.get('comments', []))
+        STORAGE.file.save(sha256, file_obj)
+    except DataStoreException as e:
+        return make_api_response({"success": False}, err=str(e), status_code=400)
+
+    return make_api_response({"success": True})
+
+
 @file_api.route("/download/<sha256>/", methods=["GET"])
 @api_login(check_xsrf_token=False, require_role=[ROLES.file_download])
 def download_file(sha256, **kwargs):
     """
     Download the file using the default encoding method. This api
     will force the browser in download mode.
 
@@ -324,14 +542,77 @@
             return make_api_response(dump(data).decode())
         else:
             return make_api_response(hexdump(data, length=length))
     else:
         return make_api_response({}, "You are not allowed to view this file.", 403)
 
 
+@file_api.route("/label/<sha256>/", methods=["POST"])
+@api_login(allow_readonly=False, require_role=[ROLES.archive_manage])
+def set_labels(sha256, **kwargs):
+    """
+    Add one or multiple labels to a given file
+
+    Variables:
+    sha256       => A resource locator for the file (sha256)
+
+    Arguments:
+    None
+
+    Data Block:     => Dict of list of unique labels to update as comma separated string
+    {
+        "attribution": ["Qakbot"],
+        "technique": ["Downloader"],
+        "info": ["ARM"]
+    }
+
+    API call example:
+    /api/v4/file/labels/123456...654321/
+
+    Result example:
+    {
+        "success": true
+        "labels": ["Qakbot", "Downloader", "ARM"],
+        "label_categories": {
+            "attribution": ["Qakbot"],
+            "technique": ["Downloader"],
+            "info": ["ARM"]
+        }
+    }
+    """
+    user = kwargs['user']
+    categories = ['attribution', 'technique', 'info']
+    try:
+        data = {k: v for k, v in request.json.items() if k in categories}
+    except ValueError:
+        return make_api_response({"success": False}, err="Invalid list of labels received.", status_code=400)
+
+    file = STORAGE.file.get(sha256, as_obj=False, index_type=Index.HOT_AND_ARCHIVE)
+
+    if not file:
+        return make_api_response({"success": False}, err="File ID %s not found" % sha256, status_code=404)
+
+    if not Classification.is_accessible(user['classification'], file['classification']):
+        return make_api_response("", "You are not allowed to see this file...", 403)
+
+    labels = [label for category in data.values() for label in category]
+    update_data = [(STORAGE.file.UPDATE_SET, 'labels', labels)]
+    for category in categories:
+        data.setdefault(category, [])
+        update_data += [(STORAGE.file.UPDATE_SET, f'label_categories.{category}', data[category])]
+
+    if update_data:
+        STORAGE.file.update(sha256, update_data, index_type=Index.HOT)
+        STORAGE.file.update(sha256, update_data, index_type=Index.ARCHIVE)
+
+    return make_api_response(
+        {"success": True, "response": dict(labels=labels,
+                                           label_categories=data)})
+
+
 @file_api.route("/image/<sha256>/", methods=["GET"])
 @api_login(require_role=[ROLES.submission_view])
 def get_file_image_datastream(sha256, **kwargs):
     """
     Returns the image file as a datastream
 
     Variables:
@@ -654,15 +935,15 @@
                         sig = (signature['name'], h_type, signature.get('safe', False))
                         if sig not in output['signatures']:
                             output['signatures'].add(sig)
 
                 # Process tags
                 for t in sec['tags']:
                     output["tags"].setdefault(t['type'], [])
-                    t_item = (t['value'], h_type, t['safelisted'])
+                    t_item = (t['value'], h_type, t['safelisted'], sec['classification'])
                     if t_item not in output["tags"][t['type']]:
                         output["tags"][t['type']].append(t_item)
 
         output['signatures'] = list(output['signatures'])
 
         output['file_info']['classification'] = max_c12n
         return make_api_response(output)
```

## assemblyline_ui/api/v4/help.py

```diff
@@ -71,14 +71,17 @@
         else:
             return parent.get(cur_item, None)
 
     cat_map = {}
     stg_map = {}
 
     for srv in STORAGE.list_all_services(as_obj=False):
+        if not CLASSIFICATION.is_accessible(_['user']['classification'], srv.get('classification', None)):
+            continue
+
         name = srv.get('name', None)
         cat = srv.get('category', None)
         if cat and name:
             temp_cat = cat_map.get(cat, [])
             temp_cat.append(name)
             cat_map[cat] = temp_cat
```

## assemblyline_ui/api/v4/ingest.py

```diff
@@ -341,15 +341,15 @@
             binary.save(out_file)
 
         if do_upload and os.path.getsize(out_file) == 0:
             return make_api_response({}, err="File empty. Ingestion failed", status_code=400)
 
         # Apply group params if not specified
         if 'groups' not in s_params:
-            s_params['groups'] = user['groups']
+            s_params['groups'] = [g for g in user['groups'] if g in s_params['classification']]
 
         # Get generate alert parameter
         generate_alert = data.get('generate_alert', s_params.get('generate_alert', False))
         if not isinstance(generate_alert, bool):
             return make_api_response({}, "generate_alert should be a boolean", 400)
 
         # Override final parameters
```

## assemblyline_ui/api/v4/live.py

```diff
@@ -7,15 +7,15 @@
 
 SUB_API = 'live'
 live_api = make_subapi_blueprint(SUB_API, api_version=4)
 live_api._doc = "Interact with live processing messages"
 
 
 @live_api.route("/get_message/<wq_id>/", methods=["GET"])
-@api_login(allow_readonly=False, require_role=[ROLES.submission_view])
+@api_login(audit=False, allow_readonly=False, require_role=[ROLES.submission_view])
 def get_message(wq_id, **_):
     """
     Get a message from a live watch queue.
     Note: This method is not optimal because it requires the
           UI to pull the information. The prefered method is the
           socket server.
 
@@ -52,15 +52,15 @@
     else:
         response = {'type': 'error', 'err_msg': "Unknown message", 'status_code': 400, 'msg': msg}
 
     return make_api_response(response)
 
 
 @live_api.route("/get_message_list/<wq_id>/", methods=["GET"])
-@api_login(allow_readonly=False, require_role=[ROLES.submission_view])
+@api_login(audit=False, allow_readonly=False, require_role=[ROLES.submission_view])
 def get_messages(wq_id, **_):
     """
     Get all messages currently on a watch queue.
     Note: This method is not optimal because it requires the
           UI to pull the information. The prefered method is the
           socket server when possible.
 
@@ -98,15 +98,15 @@
 
         resp_list.append(response)
 
     return make_api_response(resp_list)
 
 
 @live_api.route("/outstanding_services/<sid>/", methods=["GET"])
-@api_login(allow_readonly=False, require_role=[ROLES.submission_view])
+@api_login(audit=False, allow_readonly=False, require_role=[ROLES.submission_view])
 def outstanding_services(sid, **kwargs):
     """
     List outstanding services and the number of file each
     of them still have to process.
 
     Variables:
     sid      => Submission ID
@@ -126,15 +126,15 @@
     if user and data and Classification.is_accessible(user['classification'], data['classification']):
         return make_api_response(DispatchClient(datastore=STORAGE).outstanding_services(sid))
     else:
         return make_api_response({}, "You are not allowed to access this submissions.", 403)
 
 
 @live_api.route("/setup_watch_queue/<sid>/", methods=["GET"])
-@api_login(allow_readonly=False, require_role=[ROLES.submission_view])
+@api_login(audit=False, allow_readonly=False, require_role=[ROLES.submission_view])
 def setup_watch_queue(sid, **kwargs):
     """
     Starts a watch queue to get live results
 
     Variables:
     sid      => Submission ID
```

## assemblyline_ui/api/v4/replay.py

```diff
@@ -15,15 +15,15 @@
     'alert': REPLAY_ALERT_QUEUE,
     'file': REPLAY_FILE_QUEUE,
     'submission': REPLAY_SUBMISSION_QUEUE
 }
 
 
 @replay_api.route("/queue/<message_type>/", methods=["GET"])
-@api_login(require_role=[ROLES.replay_system])
+@api_login(audit=False, require_role=[ROLES.replay_system])
 def get_message(message_type, **_):
     """
     Read a message from the queue
 
     Variables:
     message_type         =>    Type of message (file | submission | alert)
 
@@ -41,15 +41,15 @@
     if message_type not in ['file', 'submission', 'alert']:
         return make_api_response("", f"{message_type.upper()} is not a valid message type for this API.", 400)
 
     return make_api_response(QUEUE_MAP[message_type].pop(blocking=True, timeout=30))
 
 
 @replay_api.route("/queue/<message_type>/", methods=["PUT"])
-@api_login(require_role=[ROLES.replay_system])
+@api_login(audit=False, require_role=[ROLES.replay_system])
 def put_message(message_type, **_):
     """
     Put a message in a queue for processing in a worker
 
     Variables:
     message_type         =>    Type of message (file | submission | alert)
 
@@ -77,15 +77,15 @@
     else:
         return make_api_response("", f"Invalid message for type {message_type.upper()}: {message}", 400)
 
     return make_api_response({'success': True})
 
 
 @replay_api.route("/<index>/<doc_id>/", methods=["GET"])
-@api_login(audit=True, require_role=[ROLES.replay_trigger])
+@api_login(require_role=[ROLES.replay_trigger])
 def request_replay(index, doc_id, **kwargs):
     """
     Request an alert or a submission to be transfered to another system
 
     Variables:
     index         =>    Type of document to be transfered (alert or submission)
     doc_id        =>    ID of the document to transfer
@@ -112,15 +112,15 @@
     operations = [(index_ds.UPDATE_SET, 'metadata.replay', REPLAY_REQUESTED)]
     return make_api_response({
         'success': index_ds.update(doc_id, operations)
     })
 
 
 @replay_api.route("/<index>/<doc_id>/", methods=["POST"])
-@api_login(audit=True, require_role=[ROLES.replay_system])
+@api_login(require_role=[ROLES.replay_system])
 def set_replay_complete(index, doc_id, **kwargs):
     """
     Mark an alert or submission successfully transfered to another system
 
     Variables:
     index         =>    Type of document transfered (alert or submission)
     doc_id        =>    ID of the document transfered
```

## assemblyline_ui/api/v4/retrohunt.py

```diff
@@ -1,8 +1,9 @@
 import hauntedhouse
+import typing
 from flask import request
 
 from assemblyline.common.chunk import chunk
 from assemblyline.odm.models.user import ROLES
 from assemblyline.odm.models.retrohunt import Retrohunt
 from assemblyline.datastore.collection import Index
 from assemblyline_ui.api.base import api_login, make_api_response, make_subapi_blueprint
@@ -19,32 +20,50 @@
         address=config.retrohunt.url,
         api_key=config.retrohunt.api_key,
         classification=CLASSIFICATION.original_definition,
         verify=config.retrohunt.tls_verify
     )
 
 
-def prepare_search_result_detail(api_result: hauntedhouse.SearchStatus, datastore_result: dict, user_access):
+def is_finished(result):
+    if hasattr(result, 'finished'):
+        return result.finished
+    elif hasattr(result, 'stage'):
+        return result.stage.lower() == 'finished'
+    return False
+
+
+def prepare_search_result_detail(api_result: typing.Optional[hauntedhouse.SearchStatus], datastore_result: dict,
+                                 user_access, offset=0, rows=50):
+    if api_result:
+        selected_hashes = api_result.hits[offset:offset+rows]
+        errors = api_result.errors
+        truncated = api_result.truncated
+        total_hits = len(api_result.hits)
+    else:
+        selected_hashes = datastore_result['hits'][offset:offset+rows]
+        errors = datastore_result['errors']
+        truncated = datastore_result['truncated']
+        total_hits = datastore_result['total_hits']
+
     # supplement file information
     hits = []
-    for batch in chunk(api_result.hits, 1000):
+    for batch in chunk(selected_hashes, 1000):
         for doc in STORAGE.file.multiget(batch, as_obj=False, error_on_missing=False,
                                          as_dictionary=False, index_type=Index.HOT_AND_ARCHIVE):
             if CLASSIFICATION.is_accessible(user_access, doc['classification']):
                 hits.append(doc)
 
     # Mix togeather the documents from the two information sources
     datastore_result.update({
-        'total_indices': api_result.total_indices,
-        'pending_indices': api_result.pending_indices,
-        'pending_candidates': api_result.pending_candidates,
-        'errors': api_result.errors,
+        'errors': errors,
         'hits': hits,
-        'finished': api_result.finished,
-        'truncated': api_result.truncated,
+        'total_hits': total_hits,
+        'finished': True if api_result is None else is_finished(api_result),
+        'truncated': truncated,
     })
     return datastore_result
 
 
 @retrohunt_api.route("/", methods=["POST"])
 @api_login(require_role=[ROLES.retrohunt_run])
 def create(**kwargs):
@@ -91,61 +110,77 @@
         'creator': user['uname'],
         'tags': {},
         'description': description,
         'classification': classification,
         'yara_signature': signature,
         'raw_query': hauntedhouse.client.query_from_yara(signature),
         'code': status.code,
-        # 'finished': False,
-        # 'hits': [],
-        # 'error': [],
+        'finished': False,
+        'hits': [],
+        'errors': [],
     }).as_primitives()
 
     STORAGE.retrohunt.save(status.code, doc)
-    return make_api_response(prepare_search_result_detail(status, doc, user['classification']))
+    return make_api_response(prepare_search_result_detail(status, doc, user['classification'], offset=0, limit=100))
 
 
 @retrohunt_api.route("/<code>/", methods=["GET"])
 @api_login(require_role=[ROLES.retrohunt_view])
 def detail(code, **kwargs):
     """
     Get details about a completed or in progress retrohunt search.
 
     Variables:
         code                => Search code to be retrieved
 
+    Parameters:
+        offset              => how far into the hit set to return details for
+        rows                => how many rows to return details for
+
     Response Fields:
         code                => unique code identifying this search request
         creator             => user who created this search
         tags                => tags describing this search
         description         => human readable description of search
         created             => timestamp when search started
         classification      => classification string for search and results list
         yara_signature      => text of original yara signature run
         raw_query           => text of filter query derived from yara signature
 
-        total_indices       => number of filter or index blocks selected when the search started
-        pending_indices     => number of filter or index blocks remaining to process
-        pending_candidates  => number of files identified for yara runs
         errors              => a list of error messages accumulated
         hits                => list of dicts with information about what the search hit on
+        total_hits
+        offset
         finished            => boolean indicating if the search is finished
         truncated           => boolean has the list of hits been truncated at some limit
     """
     user = kwargs['user']
+    offset = int(request.args.get('offset', '0'))
+    rows = int(request.args.get('rows', '50'))
 
     # Make sure retrohunt is configured
     if haunted_house_client is None:
         return make_api_response({}, err="retrohunt not configured for this system", status_code=501)
 
     # Fetch the data from elasticsearch, use that as access filter
     doc: dict = STORAGE.retrohunt.get(code, as_obj=False)
     if doc is None:
         return make_api_response({}, err="Not Found.", status_code=404)
     if not CLASSIFICATION.is_accessible(user['classification'], doc['classification']):
         return make_api_response({}, err="Access denied.", status_code=403)
 
     # Get status information from retrohunt server
-    user = kwargs['user']
-    status = haunted_house_client.search_status_sync(code=code, access=user['classification'])
+    status = None
+    if not doc.get('finished'):
+        user = kwargs['user']
+        status = haunted_house_client.search_status_sync(code=code, access=user['classification'])
+
+        if is_finished(status):
+            doc['truncated'] = status.truncated
+            doc['hits'] = status.hits
+            doc['errors'] = status.errors
+            doc['total_hits'] = len(status.hits)
+            doc['finished'] = True
+            STORAGE.retrohunt.save(code, doc)
 
-    return make_api_response(prepare_search_result_detail(status, doc, user['classification']))
+    return make_api_response(prepare_search_result_detail(status, doc, user['classification'],
+                                                          offset=offset, rows=rows))
```

## assemblyline_ui/api/v4/safelist.py

```diff
@@ -70,15 +70,15 @@
         old['sources'] = old_src_map.values()
         return old
     except Exception as e:
         raise InvalidSafehash(f"Invalid data provided: {str(e)}")
 
 
 @safelist_api.route("/", methods=["PUT", "POST"])
-@api_login(require_role=[ROLES.safelist_manage], allow_readonly=False)
+@api_login(audit=False, require_role=[ROLES.safelist_manage], allow_readonly=False)
 def add_or_update_hash(**kwargs):
     """
     Add a hash in the safelist if it does not exist or update its list of sources if it does
 
     Arguments:
     None
 
@@ -201,15 +201,15 @@
                 STORAGE.safelist.save(qhash, data)
                 return make_api_response({'success': True, "op": "add"})
             except Exception as e:
                 return make_api_response({}, f"Invalid data provided: {str(e)}", 400)
 
 
 @safelist_api.route("/add_update_many/", methods=["POST", "PUT"])
-@api_login(audit=False,            allow_readonly=False, require_role=[ROLES.safelist_manage])
+@api_login(audit=False, allow_readonly=False, require_role=[ROLES.safelist_manage])
 def add_update_many_hashes(**_):
     """
     Add or Update a list of the safe hashes
 
     Variables:
     None
```

## assemblyline_ui/api/v4/search.py

```diff
@@ -36,15 +36,15 @@
                          "workflow_view", "retrohunt_view"])
 def search(index, **kwargs):
     """
     Search through specified index for a given query.
     Uses lucene search syntax for query.
 
     Variables:
-    index  =>   Bucket to search in (alert, submission,...)
+    index  =>   Index to search in (alert, submission,...)
 
     Arguments:
     query   =>   Query to search for
 
     Optional Arguments:
     deep_paging_id =>   ID of the next page or * to start deep paging
     filters        =>   List of additional filter queries limit the data
@@ -127,26 +127,28 @@
 def group_search(index, group_field, **kwargs):
     """
     Search through all relevant indexs for a given query and
     groups the data based on a specific field.
     Uses lucene search syntax for query.
 
     Variables:
-    index       =>   Bucket to search in (alert, submission,...)
+    index       =>   Index to search in (alert, submission,...)
     group_field  =>   Field to group on
 
     Optional Arguments:
     group_sort   =>   How to sort the results inside the group
     limit        =>   Maximum number of results return for each groups
     query        =>   Query to search for
     filters      =>   List of additional filter queries limit the data
     offset       =>   Offset in the results
     rows         =>   Max number of results
     sort         =>   How to sort the results
     fl           =>   List of fields to return
+    use_archive    =>   Allow access to the malware archive (Default: False)
+    archive_only   =>   Only access the Malware archive (Default: False)
 
     Data Block (POST ONLY):
     {"group_sort": "score desc",
      "limit": "10",
      "query": "query",
      "offset": 0,
      "rows": 100,
@@ -166,25 +168,39 @@
     collection = get_collection(index, user)
     default_sort = get_default_sort(index, user)
     if collection is None or default_sort is None:
         return make_api_response("", f"Not a valid index to search in: {index}", 400)
 
     fields = ["group_sort", "limit", "query", "offset", "rows", "sort", "fl", "timeout"]
     multi_fields = ['filters']
+    boolean_fields = ['use_archive', 'archive_only']
 
     if request.method == "POST":
         req_data = request.json
         params = {k: req_data.get(k, None) for k in fields if req_data.get(k, None) is not None}
         params.update({k: req_data.get(k, None) for k in multi_fields if req_data.get(k, None) is not None})
 
     else:
         req_data = request.args
         params = {k: req_data.get(k, None) for k in fields if req_data.get(k, None) is not None}
         params.update({k: req_data.getlist(k, None) for k in multi_fields if req_data.get(k, None) is not None})
 
+    params.update({k: str(req_data.get(k, 'false')).lower() in ['true', '']
+                   for k in boolean_fields
+                   if req_data.get(k, None) is not None})
+
+    use_archive = params.pop('use_archive', False)
+    archive_only = params.pop('archive_only', False)
+    if archive_only:
+        params['index_type'] = Index.ARCHIVE
+    elif use_archive:
+        params['index_type'] = Index.HOT_AND_ARCHIVE
+    else:
+        params['index_type'] = Index.HOT
+
     if has_access_control(index):
         params.update({'access_control': user['access_control']})
 
     params['as_obj'] = False
     params.setdefault('sort', default_sort)
 
     if not group_field:
@@ -194,16 +210,16 @@
         return make_api_response(collection.grouped_search(group_field, **params))
     except SearchException as e:
         return make_api_response("", f"SearchException: {e}", 400)
 
 
 # noinspection PyUnusedLocal
 @search_api.route("/fields/<index>/", methods=["GET"])
-@api_login(require_role=["alert_view", "heuristic_view",  "safelist_view", "signature_view", "submission_view",
-                         "workflow_view", "retrohunt_view"])
+@api_login(audit=False, require_role=["alert_view", "heuristic_view",  "safelist_view", "signature_view",
+                                      "submission_view", "workflow_view", "retrohunt_view"])
 def list_index_fields(index, **kwargs):
     """
     List all available fields for a given index
 
     Variables:
     index  =>     Which specific index you want to know the fields for
 
@@ -242,21 +258,23 @@
 def facet(index, field, **kwargs):
     """
     Perform field analysis on the selected field. (Also known as facetting in lucene)
     This essentially counts the number of instances a field is seen with each specific values
     where the documents matches the specified queries.
 
     Variables:
-    index       =>   Bucket to search in (alert, submission,...)
+    index       =>   Index to search in (alert, submission,...)
     field        =>   Field to analyse
 
     Optional Arguments:
     query        =>   Query to search for
     mincount    =>   Minimum item count for the fieldvalue to be returned
     filters      =>   Additional query to limit to output
+    use_archive    =>   Allow access to the malware archive (Default: False)
+    archive_only   =>   Only access the Malware archive (Default: False)
 
     Data Block (POST ONLY):
     {"query": "id:*",
      "mincount": "10",
      "filters": ['fq']}
 
     Result example:
@@ -274,25 +292,39 @@
 
     field_info = collection.fields().get(field, None)
     if field_info is None:
         return make_api_response("", f"Field '{field}' is not a valid field in index: {index}", 400)
 
     fields = ["query", "mincount"]
     multi_fields = ['filters']
+    boolean_fields = ['use_archive', 'archive_only']
 
     if request.method == "POST":
         req_data = request.json
         params = {k: req_data.get(k, None) for k in fields if req_data.get(k, None) is not None}
         params.update({k: req_data.get(k, None) for k in multi_fields if req_data.get(k, None) is not None})
 
     else:
         req_data = request.args
         params = {k: req_data.get(k, None) for k in fields if req_data.get(k, None) is not None}
         params.update({k: req_data.getlist(k, None) for k in multi_fields if req_data.get(k, None) is not None})
 
+    params.update({k: str(req_data.get(k, 'false')).lower() in ['true', '']
+                   for k in boolean_fields
+                   if req_data.get(k, None) is not None})
+
+    use_archive = params.pop('use_archive', False)
+    archive_only = params.pop('archive_only', False)
+    if archive_only:
+        params['index_type'] = Index.ARCHIVE
+    elif use_archive:
+        params['index_type'] = Index.HOT_AND_ARCHIVE
+    else:
+        params['index_type'] = Index.HOT
+
     if has_access_control(index):
         params.update({'access_control': user['access_control']})
 
     try:
         return make_api_response(collection.facet(field, **params))
     except SearchException as e:
         return make_api_response("", f"SearchException: {e}", 400)
@@ -302,27 +334,29 @@
 @api_login(require_role=["alert_view", "heuristic_view",  "safelist_view", "signature_view", "submission_view",
                          "workflow_view", "retrohunt_view"])
 def histogram(index, field, **kwargs):
     """
     Generate an histogram based on a time or and int field using a specific gap size
 
     Variables:
-    index       =>   Bucket to search in (alert, submission,...)
+    index       =>   Index to search in (alert, submission,...)
     field        =>   Field to generate the histogram from
 
     Optional Arguments:
     query        =>   Query to search for
     mincount     =>   Minimum item count for the fieldvalue to be returned
     filters      =>   Additional query to limit to output
     start        =>   Value at which to start creating the histogram
                        * Defaults: 0 or now-1d
     end          =>   Value at which to end the histogram
                        * Defaults: 2000 or now
     gap          =>   Size of each step in the histogram
                        * Defaults: 100 or +1h
+    use_archive    =>   Allow access to the malware archive (Default: False)
+    archive_only   =>   Only access the Malware archive (Default: False)
 
     Data Block (POST ONLY):
     {"query": "id:*",
      "mincount": "10",
      "filters": ['fq'],
      "start": 0,
      "end": 100,
@@ -333,14 +367,15 @@
      "step_0": 2,
      ...
      "step_N": 19,
     }
     """
     fields = ["query", "mincount", "start", "end", "gap"]
     multi_fields = ['filters']
+    boolean_fields = ['use_archive', 'archive_only']
     user = kwargs['user']
     check_role_for_index(index, user)
 
     collection = get_collection(index, user)
     if collection is None:
         return make_api_response("", f"Not a valid index to search in: {index}", 400)
 
@@ -363,22 +398,36 @@
     else:
         err_msg = f"Field '{field}' is of type '{field_info['type']}'. Only 'integer' or 'date' are acceptable."
         return make_api_response("", err_msg, 400)
 
     # Load API variables
     if request.method == "POST":
         req_data = request.json
-        params.update({k: req_data.get(k, None) for k in fields if req_data.get(k, None) is not None})
+        # params.update({k: req_data.get(k, None) for k in fields if req_data.get(k, None) is not None})
         params.update({k: req_data.get(k, None) for k in multi_fields if req_data.get(k, None) is not None})
 
     else:
         req_data = request.args
-        params.update({k: req_data.get(k, None) for k in fields if req_data.get(k, None) is not None})
+        # params.update({k: req_data.get(k, None) for k in fields if req_data.get(k, None) is not None})
         params.update({k: req_data.getlist(k, None) for k in multi_fields if req_data.get(k, None) is not None})
 
+    params.update({k: req_data.get(k, None) for k in fields if req_data.get(k, None) is not None})
+    params.update({k: str(req_data.get(k, 'false')).lower() in ['true', '']
+                   for k in boolean_fields
+                   if req_data.get(k, None) is not None})
+
+    use_archive = params.pop('use_archive', False)
+    archive_only = params.pop('archive_only', False)
+    if archive_only:
+        params['index_type'] = Index.ARCHIVE
+    elif use_archive:
+        params['index_type'] = Index.HOT_AND_ARCHIVE
+    else:
+        params['index_type'] = Index.HOT
+
     # Make sure access control is enforced
     if has_access_control(index):
         params.update({'access_control': user['access_control']})
 
     try:
         return make_api_response(collection.histogram(field, **params))
     except SearchException as e:
@@ -389,20 +438,22 @@
 @api_login(require_role=["alert_view", "heuristic_view",  "safelist_view", "signature_view", "submission_view",
                          "workflow_view", "retrohunt_view"])
 def stats(index, int_field, **kwargs):
     """
     Perform statistical analysis of an integer field to get its min, max, average and count values
 
     Variables:
-    index       =>   Bucket to search in (alert, submission,...)
+    index       =>   Index to search in (alert, submission,...)
     int_field    =>   Integer field to analyse
 
     Optional Arguments:
     query        =>   Query to search for
     filters      =>   Additional query to limit to output
+    use_archive    =>   Allow access to the malware archive (Default: False)
+    archive_only   =>   Only access the Malware archive (Default: False)
 
     Data Block (POST ONLY):
     {"query": "id:*",
      "filters": ['fq']}
 
     Result example:
     {                 # Stats results
@@ -424,24 +475,39 @@
         return make_api_response("", f"Field '{int_field}' is not a valid field in index: {index}", 400)
 
     if field_info['type'] not in ["integer", "float"]:
         return make_api_response("", f"Field '{int_field}' is not a numeric field.", 400)
 
     fields = ["query"]
     multi_fields = ['filters']
+    boolean_fields = ['use_archive', 'archive_only']
 
     if request.method == "POST":
         req_data = request.json
-        params = {k: req_data.get(k, None) for k in fields if req_data.get(k, None) is not None}
-        params.update({k: req_data.get(k, None) for k in multi_fields if req_data.get(k, None) is not None})
+        # params = {k: req_data.get(k, None) for k in fields if req_data.get(k, None) is not None}
+        params = {k: req_data.get(k, None) for k in multi_fields if req_data.get(k, None) is not None}
 
     else:
         req_data = request.args
-        params = {k: req_data.get(k, None) for k in fields if req_data.get(k, None) is not None}
-        params.update({k: req_data.getlist(k, None) for k in multi_fields if req_data.get(k, None) is not None})
+        # params = {k: req_data.get(k, None) for k in fields if req_data.get(k, None) is not None}
+        params = {k: req_data.getlist(k, None) for k in multi_fields if req_data.get(k, None) is not None}
+
+    params.update({k: req_data.get(k, None) for k in fields if req_data.get(k, None) is not None})
+    params.update({k: str(req_data.get(k, 'false')).lower() in ['true', '']
+                   for k in boolean_fields
+                   if req_data.get(k, None) is not None})
+
+    use_archive = params.pop('use_archive', False)
+    archive_only = params.pop('archive_only', False)
+    if archive_only:
+        params['index_type'] = Index.ARCHIVE
+    elif use_archive:
+        params['index_type'] = Index.HOT_AND_ARCHIVE
+    else:
+        params['index_type'] = Index.HOT
 
     if has_access_control(index):
         params.update({'access_control': user['access_control']})
 
     try:
         return make_api_response(collection.stats(int_field, **params))
     except SearchException as e:
```

## assemblyline_ui/api/v4/service.py

```diff
@@ -295,14 +295,17 @@
         for dep in service.get('dependencies', {}).values():
             dep['container']['registry_type'] = dep.get('registry_type', config.services.preferred_registry_type)
         service['enabled'] = service['enabled'] and enable_allowed
 
         # Load service info
         service = Service(service)
 
+        # Ensure service classification is at a minimum the default_result_classification
+        service.classification = Classification.max_classification(service.classification, service.default_result_classification)
+
         # Fix service version, we don't want to see stable if it's a stable container
         service.version = service.version.replace("stable", "")
 
         # Save service if it doesn't already exist
         if not STORAGE.service.get_if_exists(f'{service.name}_{service.version}'):
             STORAGE.service.save(f'{service.name}_{service.version}', service)
             STORAGE.service.commit()
@@ -677,34 +680,39 @@
     Data Block:
     None
 
     Result example:
      [
         {'accepts': ".*"
          'category': 'Extraction',
-         'classpath': 'al_services.alsvc_extract.Extract',
+         'classification': 'TLP:C',
          'description': "Extracts some stuff",
          'enabled': True,
          'name': 'Extract',
          'rejects': 'empty'
          'stage': 'CORE'
          },
          ...
      ]
     """
+    user = _['user']
     resp = [{'accepts': x.get('accepts', None),
              'category': x.get('category', None),
+             'classification': x.get('classification', Classification.UNRESTRICTED),
              'description': x.get('description', None),
              'enabled': x.get('enabled', False),
+             'is_external': x.get('is_external', False),
              'name': x.get('name', None),
              'privileged': x.get('privileged', False),
              'rejects': x.get('rejects', None),
              'stage': x.get('stage', None),
              'version': x.get('version', None)}
-            for x in STORAGE.list_all_services(full=True, as_obj=False)]
+            for x in STORAGE.list_all_services(full=True, as_obj=False)
+            if Classification.is_accessible(user['classification'],
+                                            x.get('classification', Classification.UNRESTRICTED))]
 
     return make_api_response(resp)
 
 
 @service_api.route("/<servicename>/", methods=["DELETE"])
 @api_login(require_role=[ROLES.administration], allow_readonly=False)
 def remove_service(servicename, **_):
```

## assemblyline_ui/api/v4/signature.py

```diff
@@ -102,16 +102,20 @@
             )
 
     old = STORAGE.signature.get(key, as_obj=False)
     if old:
         if old['data'] == data['data']:
             return make_api_response({"success": True, "id": key})
 
-        # If rule has been deprecated/disabled after initial deployment, then disable it
-        if not (data['status'] != old['status'] and data['status'] == "DISABLED"):
+        # Ensure that the last state change, if any, was made by a user and not a system account.
+        user_modified_last_state = old['state_change_user'] not in ['update_service_account', None]
+
+        # If rule state is moving to an active state but was disabled by a user before:
+        # Keep original inactive state, a user changed the state for a reason
+        if user_modified_last_state and data['status'] == 'DEPLOYED' and data['status'] != old['status']:
             data['status'] = old['status']
 
         # Preserve last state change
         data['state_change_date'] = old['state_change_date']
         data['state_change_user'] = old['state_change_user']
 
         # Preserve signature stats
@@ -183,16 +187,20 @@
     old_data = STORAGE.signature.multiget(list(names_map.values()), as_dictionary=True, as_obj=False,
                                           error_on_missing=False)
 
     plan = STORAGE.signature.get_bulk_plan()
     for rule in data:
         key = f"{rule['type']}_{rule['source']}_{rule.get('signature_id', rule['name'])}"
         if key in old_data:
-            # If rule has been deprecated/disabled after initial deployment, then disable it
-            if not (rule['status'] != old_data[key]['status'] and rule['status'] == "DISABLED"):
+            # Ensure that the last state change, if any, was made by a user and not a system account.
+            user_modified_last_state = old_data[key]['state_change_user'] not in ['update_service_account', None]
+
+            # If rule state is moving to an active state but was disabled by a user before:
+            # Keep original inactive state, a user changed the state for a reason
+            if user_modified_last_state and rule['status'] == 'DEPLOYED' and rule['status'] != old_data[key]['status']:
                 rule['status'] = old_data[key]['status']
 
             # Preserve last state change
             rule['state_change_date'] = old_data[key]['state_change_date']
             rule['state_change_user'] = old_data[key]['state_change_user']
 
             # Preserve signature stats
@@ -747,15 +755,15 @@
             found = True
             classification_changed = data['default_classification'] != source['default_classification']
         else:
             new_sources.append(source)
 
     if not found:
         return make_api_response({"success": False},
-                                 err=f"Could not found source '{data.name}' in service {service}.",
+                                 err=f"Could not found source '{data['name']}' in service {service}.",
                                  status_code=404)
 
     service_delta = STORAGE.service_delta.get(service, as_obj=False)
     if service_delta.get('update_config') is None:
         service_delta['update_config'] = {"sources": new_sources}
     else:
         service_delta['update_config']['sources'] = new_sources
```

## assemblyline_ui/api/v4/submission.py

```diff
@@ -196,26 +196,26 @@
                         if sig not in output['signatures']:
                             output['signatures'].add(sig)
 
                 # Process tags
                 for t in sec['tags']:
                     output["tags"].setdefault(t['type'], {})
                     current_htype = output["tags"][t['type']].get(t['value'], None)
-                    if not current_htype:
-                        output["tags"][t['type']][t['value']] = (h_type, t['safelisted'])
-                    else:
-                        if current_htype == 'malicious' or h_type == 'malicious':
-                            output["tags"][t['type']][t['value']] = ('malicious', t['safelisted'])
-                        elif current_htype == 'suspicious' or h_type == 'suspicious':
-                            output["tags"][t['type']][t['value']] = ('suspicious', t['safelisted'])
+                    tag_htype = h_type
+                    if current_htype:
+                        if 'malicous' in (current_htype, h_type):
+                            tag_htype = 'malicious'
+                        elif 'suspicious' in (current_htype, h_type):
+                            tag_htype = 'suspicious'
                         else:
-                            output["tags"][t['type']][t['value']] = ('info', t['safelisted'])
+                            tag_htype = 'info'
+                    output["tags"][t['type']][t['value']] = (tag_htype, t['safelisted'], sec['classification'])
 
         for t_type in output["tags"]:
-            output["tags"][t_type] = [(k, v[0], v[1]) for k, v in output['tags'][t_type].items()]
+            output["tags"][t_type] = [(k, v[0], v[1], v[2]) for k, v in output['tags'][t_type].items()]
 
         output['signatures'] = list(output['signatures'])
 
         output['file_info']['classification'] = max_c12n
         return make_api_response(output)
     else:
         return make_api_response("", "You are not allowed to view the data of this submission", 403)
@@ -637,24 +637,27 @@
 
             # Tag map
             output['map'].setdefault(sha256, [])
             if sha256 not in output['map'][sha256]:
                 output['map'][sha256].append(tag_key)
 
             # Tags
-            output['tags'][summary_type].setdefault(t['type'], {})
-            current_htype = output['tags'][summary_type][t['type']].get(t['value'], None)
+            stype = output['tags'][summary_type]
+            current_htype = stype.setdefault(t['type'], {}).get(t['value'], None)
             if not current_htype:
-                output['tags'][summary_type][t['type']][t['value']] = (t['h_type'], t['safelisted'])
+                stype[t['type']][t['value']] = (t['h_type'], t['safelisted'], t['classification'])
             elif HEUR_RANK_MAP[current_htype[0]] < HEUR_RANK_MAP[t['h_type']]:
-                output['tags'][summary_type][t['type']][t['value']] = (t['h_type'], t['safelisted'])
+                # When returning tag classification without context, the least restrictive should be used
+                current_clsf = current_htype[2]
+                min_clsf = Classification.min_classification(current_clsf, t['classification'])
+                stype[t['type']][t['value']] = (t['h_type'], t['safelisted'], min_clsf)
 
         for summary_type in output['tags']:
             for t_type in output['tags'][summary_type]:
-                output['tags'][summary_type][t_type] = [(k, v[0], v[1])
+                output['tags'][summary_type][t_type] = [(k, v[0], v[1], v[2])
                                                         for k, v in output['tags'][summary_type][t_type].items()]
 
         return make_api_response(output)
     else:
         return make_api_response("", "You are not allowed to view the data of this submission", 403)
 
 
@@ -813,15 +816,15 @@
                                                            sort='times.submitted desc', as_obj=False,
                                                            index_type=index_type, track_total_hits=track_total_hits))
     except SearchException as e:
         return make_api_response("", f"SearchException: {e}", 400)
 
 
 @submission_api.route("/report/<submission_id>/", methods=["GET"])
-@api_login(audit=False, check_xsrf_token=False, require_role=[ROLES.submission_view])
+@api_login(check_xsrf_token=False, require_role=[ROLES.submission_view])
 def get_report(submission_id, **kwargs):
     """
     Create a report for a submission based on its ID.
 
     Variables:
     submission_id   ->   ID of the submission to create the report for
```

## assemblyline_ui/api/v4/submit.py

```diff
@@ -198,15 +198,15 @@
     finally:
         if submit_result is None:
             decrement_submission_quota(user)
 
 
 # noinspection PyBroadException
 @submit_api.route("/", methods=["POST"])
-@api_login(audit=False, allow_readonly=False, require_role=[ROLES.submission_create])
+@api_login(allow_readonly=False, require_role=[ROLES.submission_create])
 def submit(**kwargs):
     """
     Submit a single file, sha256 or url for analysis
 
         Note 1:
             If you are submitting a sh256 or a URL, you must use the application/json encoding and one of
             sha256 or url parameters must be included in the data block.
@@ -309,15 +309,15 @@
         if "ui_params" in data:
             s_params = ui_to_submission_params(data['ui_params'])
         else:
             s_params = ui_to_submission_params(load_user_settings(user))
 
         s_params.update(data.get("params", {}))
         if 'groups' not in s_params:
-            s_params['groups'] = user['groups']
+            s_params['groups'] = [g for g in user['groups'] if g in s_params['classification']]
 
         s_params['quota_item'] = True
         s_params['submitter'] = user['uname']
 
         if not s_params['description']:
             s_params['description'] = default_description
```

## assemblyline_ui/api/v4/ui.py

```diff
@@ -200,15 +200,15 @@
      'started': True,                    # Has the submission started processing?
      'sid' : "c7668cfa-...-c4132285142e" # Submission ID
     }
     """
     user = kwargs['user']
 
     ui_params = request.json
-    ui_params['groups'] = kwargs['user']['groups']
+    ui_params['groups'] = [g for g in kwargs['user']['groups'] if g in ui_params['classification']]
     ui_params['quota_item'] = True
     ui_params['submitter'] = user['uname']
 
     if not Classification.is_accessible(user['classification'], ui_params['classification']):
         return make_api_response({"started": False, "sid": None}, "You cannot start a scan with higher "
                                                                   "classification then you're allowed to see", 403)
```

## assemblyline_ui/api/v4/user.py

```diff
@@ -11,14 +11,17 @@
 from assemblyline_ui.config import APPS_LIST, CLASSIFICATION, LOGGER, STORAGE, UI_MESSAGING, VERSION, config
 from assemblyline_ui.helper.search import list_all_fields
 from assemblyline_ui.helper.service import simplify_service_spec, ui_to_submission_params
 from assemblyline_ui.helper.user import (get_dynamic_classification, load_user_settings, save_user_account,
                                          save_user_settings, API_PRIV_MAP)
 from assemblyline_ui.http_exceptions import AccessDeniedException, InvalidDataException
 
+from .federated_lookup import filtered_tag_names
+
+
 SUB_API = 'user'
 user_api = make_subapi_blueprint(SUB_API, api_version=4)
 user_api._doc = "Manage the different users of the system"
 
 ALLOWED_FAVORITE_TYPE = ["alert", "search", "submission", "signature", "error"]
 classification_definition = CLASSIFICATION.get_parsed_classification_definition()
 
@@ -106,24 +109,32 @@
 
     user_data['avatar'] = STORAGE.user_avatar.get(kwargs['user']['uname'])
     user_data['username'] = user_data.pop('uname')
     user_data['is_admin'] = "administration" in user_data['roles']
 
     # System configuration
     user_data['c12nDef'] = classification_definition
+    # create tag-to-source lookup mapping
+    external_source_tags = {}
+    for source_name, tag_names in filtered_tag_names(kwargs['user']).items():
+        for tname in tag_names:
+            external_source_tags.setdefault(tname, []).append(source_name)
     user_data['configuration'] = {
         "auth": {
             "allow_2fa": config.auth.allow_2fa,
             "allow_apikeys": config.auth.allow_apikeys,
             "allow_extended_apikeys": config.auth.allow_extended_apikeys,
             "allow_security_tokens": config.auth.allow_security_tokens,
         },
         "datastore": {
             "archive": {
                 "enabled": config.datastore.archive.enabled
+            },
+            "retrohunt": {
+                "enabled": config.datastore.retrohunt.enabled
             }
         },
         "submission": {
             "dtl": config.submission.dtl,
             "max_dtl": config.submission.max_dtl,
             "sha256_sources": [x.name for x in config.submission.sha256_sources
                                if CLASSIFICATION.is_accessible(kwargs['user']['classification'],
@@ -153,14 +164,20 @@
             "allow_url_submissions": config.ui.allow_url_submissions,
             "apps": [x for x in APPS_LIST['apps']
                      if CLASSIFICATION.is_accessible(kwargs['user']['classification'],
                                                      x['classification'] or CLASSIFICATION.UNRESTRICTED,
                                                      ignore_invalid=True)],
             "banner": config.ui.banner,
             "banner_level": config.ui.banner_level,
+            "external_sources": [
+                x.name for x in getattr(config.ui, "external_sources", [])
+                if CLASSIFICATION.is_accessible(kwargs['user']['classification'],
+                                                x.classification or CLASSIFICATION.UNRESTRICTED)
+            ],
+            "external_source_tags": external_source_tags,
             "read_only": config.ui.read_only,
             "rss_feeds": config.ui.rss_feeds,
             "services_feed": config.ui.services_feed,
             "tos": config.ui.tos not in [None, ""],
             "tos_lockout": config.ui.tos_lockout,
             "tos_lockout_notify": config.ui.tos_lockout_notify not in [None, []]
         },
@@ -229,15 +246,15 @@
 
         # Data's username as to match the API call username
         data['uname'] = username
         if not data['name']:
             data['name'] = data['uname']
 
         # Add add dynamic classification group
-        data['classification'] = get_dynamic_classification(data['classification'], data['email'])
+        data['classification'] = get_dynamic_classification(data['classification'], data)
 
         # Clear non user account data
         avatar = data.pop('avatar', None)
 
         if avatar is not None:
             STORAGE.user_avatar.save(username, avatar)
 
@@ -394,15 +411,15 @@
                 return make_api_response({"success": False}, error_msg, 469)
             data['password'] = get_password_hash(new_pass)
             data.pop('new_pass_confirm', None)
         else:
             data['password'] = old_user.get('password', "__NO_PASSWORD__") or "__NO_PASSWORD__"
 
         # Apply dynamic classification
-        data['classification'] = get_dynamic_classification(data['classification'], data['email'])
+        data['classification'] = get_dynamic_classification(data['classification'], data)
 
         ret_val = save_user_account(username, data, kwargs['user'])
 
         if ret_val and \
                 not old_user['is_active'] \
                 and data['is_active'] \
                 and config.ui.tos_lockout \
@@ -699,15 +716,15 @@
     """
     List all users of the system.
 
     Variables:
     None
 
     Arguments:
-    offset        =>  Offset in the user bucket
+    offset        =>  Offset in the user index
     query         =>  Filter to apply to the user list
     rows          =>  Max number of user returned
     sort          =>  Sort order
 
     Data Block:
     None
 
@@ -720,15 +737,15 @@
        "classification": "",            # Max classification for user
        "uname": "usertest",        # Username
        "type": ['user'],           # List of all types the user is member of
        "avatar": null,             # Avatar (Always null here)
        "groups": ["TEST"]          # Groups the user is member of
        }, ...],
      "total": 10,                # Total number of users
-     "offset": 0                 # Offset in the user bucket
+     "offset": 0                 # Offset in the user index
     }
     """
     offset = int(request.args.get('offset', 0))
     rows = int(request.args.get('rows', 100))
     query = request.args.get('query', "id:*") or "id:*"
     sort = request.args.get('sort', "id asc")
```

## assemblyline_ui/helper/oauth.py

```diff
@@ -15,15 +15,19 @@
         return name
 
     return " ".join(name.split(", ", 1)[::-1])
 
 
 def parse_profile(profile, provider):
     # Find email address and normalize it for further processing
-    email_adr = profile.get('email', profile.get('emails', profile.get('preferred_username', profile.get('upn', None))))
+    email_adr = None
+    for email_key in ['email', 'emails', 'extension_selectedEmailAddress', 'otherMails', 'preferred_username', 'upn']:
+        email_adr = profile.get(email_key, None)
+        if email_adr:
+            break
 
     if isinstance(email_adr, list):
         email_adr = email_adr[0]
 
     if email_adr:
         email_adr = email_adr.lower()
         if "@" not in email_adr:
@@ -67,23 +71,26 @@
         email_hash = hashlib.md5(email_adr.encode('utf-8')).hexdigest()
         alternate = f"https://www.gravatar.com/avatar/{email_hash}?s=256&d=404&r=pg"
     else:
         alternate = None
 
     # Compute access, user_type, roles and classification using auto_properties
     access = True
+    access_set = False
     user_type = []
     roles = []
+    groups = []
     remove_roles = set()
     classification = cl_engine.UNRESTRICTED
     if provider.auto_properties:
         for auto_prop in provider.auto_properties:
-            if auto_prop.type == "access":
+            if auto_prop.type == "access" and not access_set:
                 # Set default access value for access pattern
                 access = auto_prop.value.lower() != "true"
+                access_set = True
 
             # Get values for field
             field_data = profile.get(auto_prop.field, None)
             if not isinstance(field_data, list):
                 field_data = [field_data]
 
             # Analyse field values
@@ -112,26 +119,35 @@
                             # Support of legacy configurations
                             user_type = [auto_prop.value]
                             roles = list(set(roles).union(USER_TYPE_DEP[auto_prop.value]))
                         else:
                             roles.append(auto_prop.value)
                         break
 
-                # Append roles from matching patterns
+                # Remove roles from matching patterns
                 elif auto_prop.type == "remove_role":
                     if re.match(auto_prop.pattern, value):
                         remove_roles.add(auto_prop.value)
                         break
 
                 # Compute classification from matching patterns
                 elif auto_prop.type == "classification":
                     if re.match(auto_prop.pattern, value):
                         classification = cl_engine.build_user_classification(classification, auto_prop.value)
                         break
 
+                # Append groups from matching patterns
+                elif auto_prop.type == "group":
+                    group_match = re.match(auto_prop.pattern, value)
+                    if group_match:
+                        group_value = auto_prop.value
+                        for index, gm_value in enumerate(group_match.groups()):
+                            group_value = group_value.replace(f"${index+1}", gm_value)
+                        groups.append(group_value)
+
     # if not user type was assigned
     if not user_type:
         # if also no roles were assigned
         if not roles:
             # Set the default user type
             user_type = ['user']
         else:
@@ -144,14 +160,15 @@
     # Remove all roles marked for removal
     roles = [role for role in roles if role not in remove_roles]
 
     return dict(
         access=access,
         type=user_type,
         roles=roles,
+        groups=groups,
         classification=classification,
         uname=uname,
         name=name,
         email=email_adr,
         password="__NO_PASSWORD__",
         avatar=profile.get('picture', alternate)
     )
```

## assemblyline_ui/helper/search.py

```diff
@@ -1,61 +1,61 @@
 from assemblyline.odm.models.user import ROLES
 from assemblyline_ui.config import STORAGE
 
 
-def get_collection(bucket, user):
-    return BUCKET_MAP.get(bucket, ADMIN_BUCKET_MAP.get(bucket, None) if ROLES.administration in user['roles'] else None)
+def get_collection(index, user):
+    return INDEX_MAP.get(index, ADMIN_INDEX_MAP.get(index, None) if ROLES.administration in user['roles'] else None)
 
 
-def get_default_sort(bucket, user):
-    return BUCKET_ORDER_MAP.get(bucket, ADMIN_BUCKET_ORDER_MAP.get(bucket, None)
-                                if ROLES.administration in user['roles'] else None)
+def get_default_sort(index, user):
+    return INDEX_ORDER_MAP.get(index, ADMIN_INDEX_ORDER_MAP.get(index, None)
+                               if ROLES.administration in user['roles'] else None)
 
 
-def has_access_control(bucket):
-    return bucket in BUCKET_MAP
+def has_access_control(index):
+    return index in INDEX_MAP
 
 
-ADMIN_BUCKET_MAP = {
+ADMIN_INDEX_MAP = {
     'emptyresult': STORAGE.emptyresult,
     'error': STORAGE.error,
     'user': STORAGE.user
 }
 
-ADMIN_BUCKET_ORDER_MAP = {
+ADMIN_INDEX_ORDER_MAP = {
     'emptyresult': 'expiry_ts asc',
     'error': 'created desc',
     'user': 'id asc'
 }
 
-BUCKET_MAP = {
+INDEX_MAP = {
     'alert': STORAGE.alert,
     'file': STORAGE.file,
     'heuristic': STORAGE.heuristic,
     'result': STORAGE.result,
     'signature': STORAGE.signature,
     'submission': STORAGE.submission,
     'safelist': STORAGE.safelist,
     'workflow': STORAGE.workflow,
     'retrohunt': STORAGE.retrohunt,
 }
 
-BUCKET_ORDER_MAP = {
+INDEX_ORDER_MAP = {
     'alert': "reporting_ts desc",
     'file': "seen.last desc",
     'heuristic': "heur_id asc",
     'result': "created desc",
     'signature': "type asc",
     'submission': "times.submitted desc",
     'safelist': "added desc",
     'workflow': "last_seen desc",
     'retrohunt': "created desc",
 }
 
 
 def list_all_fields(user=None):
-    fields_map = {k: BUCKET_MAP[k].fields() for k in BUCKET_MAP.keys()}
+    fields_map = {k: INDEX_MAP[k].fields() for k in INDEX_MAP.keys()}
 
     if user and user['is_admin']:
-        fields_map.update({k: ADMIN_BUCKET_MAP[k].fields() for k in ADMIN_BUCKET_MAP.keys()})
+        fields_map.update({k: ADMIN_INDEX_MAP[k].fields() for k in ADMIN_INDEX_MAP.keys()})
 
     return fields_map
```

## assemblyline_ui/helper/service.py

```diff
@@ -1,39 +1,41 @@
 from copy import copy
 from typing import Any, Optional
-from assemblyline_ui.config import config, SERVICE_LIST
+from assemblyline_ui.config import CLASSIFICATION, config, SERVICE_LIST
 from assemblyline.odm.models.submission import DEFAULT_SRV_SEL
 
 
-def get_default_service_spec(srv_list=None, user_default_values={}):
+def get_default_service_spec(srv_list=None, user_default_values={}, classification=CLASSIFICATION.UNRESTRICTED):
     if not srv_list:
         srv_list = SERVICE_LIST
 
     out = []
     for x in srv_list:
-        if x["submission_params"]:
+        if x["submission_params"] and CLASSIFICATION.is_accessible(classification, x['classification']):
             param_object = {'name': x['name'], "params": []}
             for param in x.get('submission_params'):
                 new_param = copy(param)
                 new_param['value'] = user_default_values.get(x['name'], {}).get(param['name'], param['value'])
                 param_object["params"].append(new_param)
 
             out.append(param_object)
 
     return out
 
 
-def get_default_service_list(srv_list=None, default_selection=None):
+def get_default_service_list(srv_list=None, default_selection=None, classification=CLASSIFICATION.UNRESTRICTED):
     if not default_selection:
         default_selection = DEFAULT_SRV_SEL
     if not srv_list:
         srv_list = SERVICE_LIST
 
     services = {}
     for item in srv_list:
+        if not CLASSIFICATION.is_accessible(classification, item['classification']):
+            continue
         grp = item['category']
 
         if grp not in services:
             services[grp] = []
 
         services[grp].append({"name": item["name"],
                               "category": grp,
```

## assemblyline_ui/helper/submission.py

```diff
@@ -131,15 +131,15 @@
     return None
 
 
 def get_or_create_summary(sid, results, user_classification, completed):
     user_classification = CLASSIFICATION.normalize_classification(user_classification, long_format=False)
     cache_key = f"{sid}_{user_classification}_m{config.submission.verdicts.malicious}" \
         f"_hs{config.submission.verdicts.highly_suspicious}_s{config.submission.verdicts.suspicious}" \
-        f"_i{config.submission.verdicts.info}"
+        f"_i{config.submission.verdicts.info}_"
     for illegal_char in [" ", ":", "/"]:
         cache_key = cache_key.replace(illegal_char, "")
 
     summary_cache = STORAGE.submission_summary.get_if_exists(cache_key, as_obj=False)
 
     if not summary_cache:
         summary = STORAGE.get_summary_from_keys(
```

## assemblyline_ui/helper/user.py

```diff
@@ -4,15 +4,15 @@
 from assemblyline.odm.models.user import User, load_roles, ROLES
 from assemblyline.odm.models.user_settings import UserSettings
 from assemblyline_ui.config import LOGGER, STORAGE, SUBMISSION_TRACKER, config, CLASSIFICATION as Classification, \
     SERVICE_LIST
 from assemblyline_ui.helper.service import get_default_service_spec, get_default_service_list, simplify_services
 from assemblyline_ui.http_exceptions import AccessDeniedException, InvalidDataException, AuthenticationException
 
-ACCOUNT_USER_MODIFIABLE = ["name", "avatar", "groups", "password"]
+ACCOUNT_USER_MODIFIABLE = ["name", "avatar", "password"]
 
 API_PRIV_MAP = {
     "READ": ["R"],
     "READ_WRITE": ["R", "W"],
     "WRITE": ["W"],
     "CUSTOM": ["C"]
 }
@@ -124,28 +124,41 @@
         STORAGE.user_avatar.delete(username)
     else:
         STORAGE.user_avatar.save(username, avatar)
 
     return STORAGE.user.save(username, data)
 
 
-def get_dynamic_classification(current_c12n, email):
-    if Classification.dynamic_groups and email:
-        dyn_group = email.upper().split('@')[1]
-        return Classification.build_user_classification(current_c12n, f"{Classification.UNRESTRICTED}//{dyn_group}")
-    return current_c12n
+def get_dynamic_classification(current_c12n, user_info):
+    new_c12n = Classification.normalize_classification(current_c12n, get_dynamic_groups=False)
+
+    if Classification.dynamic_groups:
+        email = user_info.get('email', None)
+        groups = user_info.get('groups', [])
+
+        if Classification.dynamic_groups_type in ['email', 'all'] and email:
+            dyn_group = email.upper().split('@')[1]
+            new_c12n = Classification.build_user_classification(
+                new_c12n, f"{Classification.UNRESTRICTED}//{dyn_group}")
+
+        if Classification.dynamic_groups_type in ['group', 'all'] and groups:
+            new_c12n = Classification.build_user_classification(
+                new_c12n, f"{Classification.UNRESTRICTED}//{', '.join(groups)}")
+
+    return new_c12n
 
 
 def get_default_user_settings(user):
     return UserSettings({"classification": Classification.default_user_classification(user),
                          "ttl": config.submission.dtl}).as_primitives()
 
 
 def load_user_settings(user):
     default_settings = get_default_user_settings(user)
+    user_classfication = user.get('classification', Classification.UNRESTRICTED)
 
     settings = STORAGE.user_settings.get_if_exists(user['uname'], as_obj=False)
     srv_list = [x for x in SERVICE_LIST if x['enabled']]
     if not settings:
         def_srv_list = None
         settings = default_settings
     else:
@@ -157,16 +170,17 @@
         # Remove all obsolete keys
         for key in list(settings.keys()):
             if key not in default_settings:
                 del settings[key]
 
         def_srv_list = settings.get('services', {}).get('selected', None)
 
-    settings['service_spec'] = get_default_service_spec(srv_list, settings.get('service_spec', {}))
-    settings['services'] = get_default_service_list(srv_list, def_srv_list)
+    # Only display services that a user is allowed to see
+    settings['service_spec'] = get_default_service_spec(srv_list, settings.get('service_spec', {}), user_classfication)
+    settings['services'] = get_default_service_list(srv_list, def_srv_list, user_classfication)
     settings['default_zip_password'] = settings.get('default_zip_password', None)
 
     # Normalize the user's classification
     settings['classification'] = Classification.normalize_classification(settings['classification'])
 
     return settings
```

## assemblyline_ui/security/ldap_auth.py

```diff
@@ -139,14 +139,15 @@
                 details['dn'] = dn
                 details['groups'] = self.get_group_list(dn, ldap_server=ldap_server)
 
                 # Parse auto-properties
                 access = True
                 user_type = []
                 roles = []
+                groups = []
                 remove_roles = set()
                 classification = self.get_user_classification(details['groups'])
                 for auto_prop in config.auth.ldap.auto_properties:
                     if auto_prop.type == "access":
                         # Set default access value for access pattern
                         access = auto_prop.value != "True"
 
@@ -190,14 +191,23 @@
                         # Compute classification from matching patterns
                         elif auto_prop.type == "classification":
                             if re.match(auto_prop.pattern, value):
                                 classification = CLASSIFICATION.build_user_classification(
                                     classification, auto_prop.value)
                                 break
 
+                        # Append groups from matching patterns
+                        elif auto_prop.type == "group":
+                            group_match = re.match(auto_prop.pattern, value)
+                            if group_match:
+                                group_value = auto_prop.value
+                                for index, gm_value in enumerate(group_match.groups()):
+                                    group_value = group_value.replace(f"${index+1}", gm_value)
+                                groups.append(group_value)
+
                 # if not user type was assigned
                 if not user_type:
                     # if also no roles were assigned
                     if not roles:
                         # Set the default user type
                         user_type = self.get_user_types(details['groups'])
                     else:
@@ -209,15 +219,15 @@
 
                 # Remove all roles marked for removal
                 roles = [role for role in roles if role not in remove_roles]
 
                 cache_entry = {"password": password_digest, "expiry": cur_time + self.CACHE_SEC_LEN,
                                "connection": ldap_server, "details": details, "cached": False,
                                "classification": classification, "type": user_type, 'roles': roles, 'dn': dn,
-                               'access': access}
+                               'access': access, 'groups': groups}
                 self.cache[user] = cache_entry
                 return cache_entry
         except Exception as e:
             # raise AuthenticationException('Unable to login to ldap server. [%s]' % str(e))
             log.exception('Unable to login to ldap server. [%s]' % str(e))
         return None
 
@@ -261,28 +271,30 @@
             if (not cur_user and config.auth.ldap.auto_create) or (cur_user and config.auth.ldap.auto_sync):
                 u_classification = ldap_info['classification']
 
                 # Normalize email address
                 email = get_attribute(ldap_info, config.auth.ldap.email_field)
                 if email is not None:
                     email = email.lower()
-                    u_classification = get_dynamic_classification(u_classification, email)
 
                 # Generate user data from ldap
                 data = dict(
                     classification=u_classification,
                     uname=username,
                     name=get_attribute(ldap_info, config.auth.ldap.name_field) or username,
                     email=email,
                     password="__NO_PASSWORD__",
                     type=ldap_info['type'],
                     roles=ldap_info['roles'],
                     dn=ldap_info['dn']
                 )
 
+                # Get the dynamic classification info
+                data['classification'] = get_dynamic_classification(u_classification, data)
+
                 # Save the user avatar avatar from ldap
                 img_data = get_attribute(ldap_info, config.auth.ldap.image_field, safe=False)
                 if img_data:
                     b64_img = base64.b64encode(img_data).decode()
                     avatar = f'data:image/{config.auth.ldap.image_format};base64,{b64_img}'
                     storage.user_avatar.save(username, avatar)
```

## Comparing `assemblyline_ui-4.4.1.dev9.dist-info/LICENCE.md` & `assemblyline_ui-4.4.1.dev94.dist-info/LICENCE.md`

 * *Files identical despite different names*

## Comparing `assemblyline_ui-4.4.1.dev9.dist-info/METADATA` & `assemblyline_ui-4.4.1.dev94.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: assemblyline-ui
-Version: 4.4.1.dev9
+Version: 4.4.1.dev94
 Summary: Assemblyline 4 - API and Socket IO server
 Home-page: https://github.com/CybercentreCanada/assemblyline-ui/
 Author: CCCS Assemblyline development team
 Author-email: assemblyline@cyber.gc.ca
 License: MIT
 Keywords: assemblyline automated malware analysis gc canada cse-cst cse cst cyber cccs
 Platform: UNKNOWN
@@ -15,16 +15,16 @@
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Description-Content-Type: text/markdown
 License-File: LICENCE.md
 Requires-Dist: assemblyline
 Requires-Dist: assemblyline-core
-Requires-Dist: werkzeug
-Requires-Dist: flask
+Requires-Dist: werkzeug (==2.2.3)
+Requires-Dist: flask (==2.2.3)
 Requires-Dist: pyqrcode
 Requires-Dist: markdown
 Requires-Dist: python-ldap
 Requires-Dist: authlib (<1.0.0)
 Requires-Dist: fido2 (<1.0.0)
 Requires-Dist: PyJWT
 Requires-Dist: gunicorn
@@ -32,15 +32,15 @@
 Requires-Dist: hauntedhouse
 Provides-Extra: socketio
 Requires-Dist: python-socketio ; extra == 'socketio'
 Requires-Dist: flask-socketio ; extra == 'socketio'
 Requires-Dist: gevent-websocket ; extra == 'socketio'
 Provides-Extra: test
 Requires-Dist: pytest ; extra == 'test'
-Requires-Dist: pytest-cov ; extra == 'test'
+Requires-Dist: pytest-mock ; extra == 'test'
 Requires-Dist: cart ; extra == 'test'
 
 # Assemblyline 4 - API and Socket IO server
 
 This component provides the User Interface as well as the different APIs and socketio endpoints for the Assemblyline 4 framework.
 
 ### Components
```

## Comparing `assemblyline_ui-4.4.1.dev9.dist-info/RECORD` & `assemblyline_ui-4.4.1.dev94.dist-info/RECORD`

 * *Files 11% similar despite different names*

```diff
@@ -1,68 +1,70 @@
-assemblyline_ui/VERSION,sha256=1UhXp18ZRh5JSiN7TVBqo6jxxtexk5UMttX1_Gg3vUY,11
+assemblyline_ui/VERSION,sha256=7tRb9rStMAW8ZkRmU6rM5MLIq9c0Eny9iFmIk9A0S0M,12
 assemblyline_ui/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-assemblyline_ui/app.py,sha256=uqiI04Nsi-K8-JiS8UBv6q3B0_lnABvTo0-EdWPkJ7U,5518
-assemblyline_ui/config.py,sha256=cTn7KXPGbzmbS6ptG7WX0DwUpq-ZPD9tXvz8jlhexlI,5373
+assemblyline_ui/app.py,sha256=9FGDKjVu5zYON95dGB5Xuiu7bNgdYJGh2kGZf2yu6g0,5636
+assemblyline_ui/config.py,sha256=-cXNzusxc1DL7juBOsYP1anKot_ALYuVfOVHudXm6-o,5453
 assemblyline_ui/error.py,sha256=WK18Vypk1KiEaFuYbG_1XvAp6rdeS-7k1YpPjXEiD7k,3598
 assemblyline_ui/gunicorn_config.py,sha256=qm2Ehn9nY_yH6Klp2acYFZ9jC7St9hSmXIW42WRXbc4,740
 assemblyline_ui/gunicorn_config_socketio.py,sha256=WWAWzrZOw1OXEiV_nNMKf-wH6A0Ckio2juCYWu-QfAE,115
 assemblyline_ui/healthz.py,sha256=IFr2ofSddFX8pvoixMmZHSlk364oKD_vURl_GRT6J2s,777
 assemblyline_ui/http_exceptions.py,sha256=5DvpspLyuE6fQfR6mpPmQiFDXahr2vr3uuTp7S9Guy8,199
 assemblyline_ui/logger.py,sha256=dgaAzJc39ajD1e3hipc291zqcHyCXMgdDSLzz6V-Jus,2322
 assemblyline_ui/patched.py,sha256=EkYqCoW64CuZvrZjE7xNwZ9bTaiVfwuYBbVUR64g42A,85
-assemblyline_ui/socketsrv.py,sha256=4EnC6Fn8StLXLoPb9F0vinnRLjDWa5-9edgOCMFx_EQ,2359
+assemblyline_ui/socketsrv.py,sha256=t5WsRAhjNv_Gn7RTm4O0Q2zHlJIq1Say4wqoinGqFh0,2479
 assemblyline_ui/api/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 assemblyline_ui/api/base.py,sha256=o4VKwtkLfrOO-aeC71SyCZMgYaU3q6TqGeUPyNuH6A8,14347
 assemblyline_ui/api/v4/__init__.py,sha256=5sJInJQ7GM-6LTIOvTPFBHE1u-kf562MjjbzX0ZBuDg,3915
 assemblyline_ui/api/v4/alert.py,sha256=4Z88giPbX6CSuRt8T3uivKwLQh0u6dTnfIyh1hUryfg,28791
 assemblyline_ui/api/v4/archive.py,sha256=xw3qcFdtV0ZG69WxV3M4PUFqQXAJvGGLrO9_4i6xGnI,2289
-assemblyline_ui/api/v4/authentication.py,sha256=X5itiGqkizIhUq-LZlvFW4dtll8raoZ1019sUVubEts,33320
+assemblyline_ui/api/v4/authentication.py,sha256=X-KEgtFdGMANCbgL_1wKJQUab9HEb-fabB8jA4eo-Ck,33295
 assemblyline_ui/api/v4/bundle.py,sha256=XCxILxICh8eZfkbOC0fYW_v2pdl7n-US24qYEW5_RrA,5141
 assemblyline_ui/api/v4/error.py,sha256=rITm-0yrZYidetWqlJUmwyHEyF6kML5Ta3c0gT-L7M4,2560
-assemblyline_ui/api/v4/file.py,sha256=77LR4oQjisfUrG_xIKdYbbZKSBfQh4_YKgzDpNc7nS8,28236
+assemblyline_ui/api/v4/federated_lookup.py,sha256=i8-KbBjhRfXlglfmNb0HQOJs05adYiAFl84XqcsYVnI,9712
+assemblyline_ui/api/v4/file.py,sha256=JMrtzzFI7SVXkl6Ufqy8gHJM9i_1y--w1tdfF46r3pI,37202
 assemblyline_ui/api/v4/hash_search.py,sha256=gcQc9XKGn4w1xjQ28bBrDJcOYNWb3sUDuESTpCLNzJU,4776
-assemblyline_ui/api/v4/help.py,sha256=r9o2SmzvRmigQdRFIpEzHxQrHjxAR9K8mvy9Ut21BO8,6238
+assemblyline_ui/api/v4/help.py,sha256=4_C82EW4Cu9XPor9pMIPB7v_0uIFZ1TG2PX1nMNm2ck,6367
 assemblyline_ui/api/v4/heuristics.py,sha256=YfTUmDYrilwdNO1Dlr0qfDRTU4fOhPpSCWARLjt1auo,2910
-assemblyline_ui/api/v4/ingest.py,sha256=KF5zRG3i2D9rnkWt9ixV7JdSQ6laUyuowOW0IMGB5IM,20313
-assemblyline_ui/api/v4/live.py,sha256=1hb8AaILPJN6w6ojkFYoCBWG4H-0HqLRLXFpTqgTOyo,5425
+assemblyline_ui/api/v4/ingest.py,sha256=TM7UGQ3toIb9qNYDc4gBgg5fPpZ2NXpMeakpBN-hz8E,20361
+assemblyline_ui/api/v4/live.py,sha256=4gz8-zbkTnLWBg2OH-AmRIolBZokDjweOZgaw1I3j3U,5477
 assemblyline_ui/api/v4/ontology.py,sha256=a8-VRuOlTOfFm2R0r_XoUeUjC3bvMZdFfl4Orc_g6wQ,13149
-assemblyline_ui/api/v4/replay.py,sha256=mmr_zb937NLv8BnwWNTIB8H3cGYgQRjW8hsX6KTCZ6Q,6271
+assemblyline_ui/api/v4/replay.py,sha256=C00LnKY47-KB3Kxk5cmk99VWGEbmJVmyYCOfoWGGIf4,6273
 assemblyline_ui/api/v4/result.py,sha256=XJPUZPdVD1SK7kwppKzFvqGngmdRr0ei6qV0Ppl-c14,6203
-assemblyline_ui/api/v4/retrohunt.py,sha256=sweD-Wqz1VG-hpiX2fBS9xeCOVzCOS2Zd07Ab7d3DFM,6278
-assemblyline_ui/api/v4/safelist.py,sha256=rs1HzJPLWU-iNAbuagsT5DtAjZfhb8UQ9AwrZ62Qcc8,17916
-assemblyline_ui/api/v4/search.py,sha256=bwerkU8HY7YvVX0Jf6bYs2SsP0_BwPWCJsdN59H4iEA,17041
-assemblyline_ui/api/v4/service.py,sha256=oYf7WBOYJncvbU6eV3Wb9HIYeN2hK8yoVtmcVKeHO6s,38520
-assemblyline_ui/api/v4/signature.py,sha256=M0Cdv2mUJr3gRv1-vpAadiVMMF_hzSF0kRs_4kkktIk,33326
-assemblyline_ui/api/v4/submission.py,sha256=u5kyPnoJuRl0zHDYI2CSE-90Gp659HvqpTy-og1S3zQ,41933
-assemblyline_ui/api/v4/submit.py,sha256=23iKpIHFwGoT7MY3BrlVZpeAR9EMmEWpOGNMZN9jVg0,20050
+assemblyline_ui/api/v4/retrohunt.py,sha256=Rq8YnBZH2R2EhroShR1lU2csaXrdk2QJ-BD8JFZm4G8,7353
+assemblyline_ui/api/v4/safelist.py,sha256=vy3sm_91zqKEUkrosZ7Rb3x1NOTeVv1KnOSe4Bt8bZ4,17918
+assemblyline_ui/api/v4/search.py,sha256=nOEYa3j1FPpgWuP0MCQgOVehFZNv75kum9FXtyz6M6s,19968
+assemblyline_ui/api/v4/service.py,sha256=JgkbMNEWsVvP5Uplu8tY_37A7P8VsmGn2wNGU-WtG8A,39047
+assemblyline_ui/api/v4/signature.py,sha256=mfsuPVF4S8Rh2T-Kcx9gNcPMvGh1UAJ9Ec7tF326yNA,33949
+assemblyline_ui/api/v4/submission.py,sha256=eWUMa-H8vnsCP_Nei9WHoAjXcQ-cAvg0nQM-Im6RlU8,41999
+assemblyline_ui/api/v4/submit.py,sha256=4Ilc9HkC6Fk68-CX5s5bCNiDBuig1j1TfMCY1FmXzoE,20085
 assemblyline_ui/api/v4/system.py,sha256=sfvyKaV_PBccwwjdAMbK93r5glYdwquDFgwhZa7oKio,20300
-assemblyline_ui/api/v4/ui.py,sha256=XEuw12btg9Hrni1P7iO3c1Z0nSJ_pyj3lqjV-BtjLII,11453
-assemblyline_ui/api/v4/user.py,sha256=UuD00z8ZZkpJxcOd4rv44y6tG5b3P2qIVwS4oV-xxYc,36368
+assemblyline_ui/api/v4/ui.py,sha256=dV441HpVXTRXbK9qSto_-MnW5gKkHOcoSzinFh25mog,11502
+assemblyline_ui/api/v4/user.py,sha256=EeUwPod2mul-Vo-rYqMkStrm-Zx6qeBlhGLdfWank8M,37121
 assemblyline_ui/api/v4/webauthn.py,sha256=FxuvXScYiMdgA-ZvojGf7CfQq4C2W8e3dWLxo7W0bx4,4734
 assemblyline_ui/api/v4/workflow.py,sha256=ygjUb_9hPOjpoR1l7A5JaC0l9h_YKJgtkFigWM_JcaI,7060
 assemblyline_ui/helper/__init__.py,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
 assemblyline_ui/helper/discover.py,sha256=oJBML1dQl0H2Ic-lm5jI4YWIpm9RRW-mGT5sP-2tb9c,1686
-assemblyline_ui/helper/oauth.py,sha256=xLeMtspcqISdr70-koqwucWMbg1Jjrw0omt5h8QZPAU,6611
+assemblyline_ui/helper/oauth.py,sha256=YUhpH01ymHVQrKBmjmgcw0buIECb77M01mE3mfIgi-U,7315
 assemblyline_ui/helper/result.py,sha256=u79F3IKN1EcVOkfk1CvQNEwbIWyiq9Wj8OHp3zuwmBc,4926
-assemblyline_ui/helper/search.py,sha256=_Ia2FuHlXnv7Kjd7wqyI8HBCbZ0mKVgJrL51bGU6T40,1642
-assemblyline_ui/helper/service.py,sha256=QDqSUjVFw3SCikEvtwOvSrG-kCfU6h4tkKoVTdRxn70,2938
+assemblyline_ui/helper/search.py,sha256=iqI_tU1vncw-zvEmpnB2QT3DFckbFcpCfyudvM9un5A,1620
+assemblyline_ui/helper/service.py,sha256=UBytaOh0IFZVH9sYFdvOqAC2W2XOsQcUruhJbpc2vlM,3218
 assemblyline_ui/helper/signature.py,sha256=PUiQk56QoY5Ye2Pg3jRNgOT2i2ZqTWkk_0dv-Bfy9vI,899
-assemblyline_ui/helper/submission.py,sha256=X0W-9kEbiZrAxaP_3M3u6PGE0_rvCACsSl7Q5LbpbBM,6834
-assemblyline_ui/helper/user.py,sha256=ZLvt4WUgfp6yQqdEebAyTgUPnTn8Wc5ZdutZeGV6wW8,6894
+assemblyline_ui/helper/submission.py,sha256=P4Ff9ps_nUzHxBE7486_xbyUNuXTvOYU3aWdK8VyBOY,6835
+assemblyline_ui/helper/user.py,sha256=SG3fXelr-00bOjQFx9VPMlxGwPv-wrc4X5-nG8YEvZA,7568
 assemblyline_ui/security/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 assemblyline_ui/security/apikey_auth.py,sha256=7MnwDlmXxhKGV0LHL8FB9j0aKQBRVBl74Al1gTR1o4I,1337
 assemblyline_ui/security/authenticator.py,sha256=c9ZoT8UhciBiDFQQXBJwi-mNn3AAXcRoWxvjaZZetFo,10096
-assemblyline_ui/security/ldap_auth.py,sha256=O9jx2SRWF910EUD6Q8NmA-EiIHPw0AuSJeHiymWhKVQ,12233
+assemblyline_ui/security/ldap_auth.py,sha256=Af8_5AL0bxHTTBZlqm5oAYmtDh4Jb4Zr-VOUwqxnXKk,12880
 assemblyline_ui/security/oauth_auth.py,sha256=fxmvW2hCZoyh094WVUdews0DiYO9_gJAgrIwQwuspDw,2838
 assemblyline_ui/security/second_factor_auth.py,sha256=CYf_nS9zC6OPI7QuxWGgW6pnx_Vjx5rApbrwK8vb-qk,2913
 assemblyline_ui/security/userpass_auth.py,sha256=2qOQF_ARYfOQ0XtEnQynrUJwAiVHOP0LEYo5FfPl-Fg,675
 assemblyline_ui/sio/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 assemblyline_ui/sio/alert.py,sha256=aTtrkZW21igbP6UcFgo1_fXdF8RpCBlMiKsNdpwItZw,2170
 assemblyline_ui/sio/base.py,sha256=TLSoCLqxvSEFuggmCscnzAY1E60rweIIZLr0ai8jm5M,3529
+assemblyline_ui/sio/file.py,sha256=kvL6gfx7yuFLjJGCe05a3Ff2A7tWwVBrcdKNUuvJQ6M,1174
 assemblyline_ui/sio/live_submission.py,sha256=mS0oGO5rEA8PLa8kjBcodOG-Q0CG4SpYAoi8bz9_PCw,4158
 assemblyline_ui/sio/status.py,sha256=_Bxf1KLPOJEUIk4J9_j9fzvQWUXqSIT9xnJKhT1hhuc,1980
 assemblyline_ui/sio/submission.py,sha256=IYJuGz73HK9HtYfqc-gWW8tc1lt5VZ62Qn64AaGGtm8,2222
-assemblyline_ui-4.4.1.dev9.dist-info/LICENCE.md,sha256=NSkYo9EH8h5oOkzg4VhjAHF4339MqPP2cQ8msTPgl-c,1396
-assemblyline_ui-4.4.1.dev9.dist-info/METADATA,sha256=-CxNWutjONKo5-JAex2e1Nb7FVWuhjYjqfbOHX1Io1g,2839
-assemblyline_ui-4.4.1.dev9.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-assemblyline_ui-4.4.1.dev9.dist-info/top_level.txt,sha256=WLa7-PKLJTbMUbKKU3q3kg5_uAV67hss5kC71PAbIeg,16
-assemblyline_ui-4.4.1.dev9.dist-info/RECORD,,
+assemblyline_ui-4.4.1.dev94.dist-info/LICENCE.md,sha256=NSkYo9EH8h5oOkzg4VhjAHF4339MqPP2cQ8msTPgl-c,1396
+assemblyline_ui-4.4.1.dev94.dist-info/METADATA,sha256=xheLkiItRm78Svy4N643xxQxdx8MUm__4tOnpZu3mck,2861
+assemblyline_ui-4.4.1.dev94.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+assemblyline_ui-4.4.1.dev94.dist-info/top_level.txt,sha256=WLa7-PKLJTbMUbKKU3q3kg5_uAV67hss5kC71PAbIeg,16
+assemblyline_ui-4.4.1.dev94.dist-info/RECORD,,
```

