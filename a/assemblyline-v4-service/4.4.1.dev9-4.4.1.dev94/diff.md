# Comparing `tmp/assemblyline_v4_service-4.4.1.dev9-py3-none-any.whl.zip` & `tmp/assemblyline_v4_service-4.4.1.dev94-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,56 +1,56 @@
-Zip file size: 371693 bytes, number of entries: 54
--rw-r--r--  2.0 unx       11 b- defN 23-Mar-24 16:14 assemblyline_v4_service/VERSION
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-24 16:13 assemblyline_v4_service/__init__.py
--rw-r--r--  2.0 unx     1576 b- defN 23-Mar-24 16:13 assemblyline_v4_service/healthz.py
--rw-r--r--  2.0 unx    14547 b- defN 23-Mar-24 16:13 assemblyline_v4_service/run_privileged_service.py
--rw-r--r--  2.0 unx     5557 b- defN 23-Mar-24 16:13 assemblyline_v4_service/run_service.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/__init__.py
--rw-r--r--  2.0 unx     4453 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/api.py
--rw-r--r--  2.0 unx    12655 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/base.py
--rw-r--r--  2.0 unx   136992 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/dynamic_service_helper.py
--rw-r--r--  2.0 unx     3290 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/helper.py
--rw-r--r--  2.0 unx     5376 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/icap.py
--rw-r--r--  2.0 unx     2219 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/keytool_parse.py
--rw-r--r--  2.0 unx     7768 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/ontology_helper.py
--rw-r--r--  2.0 unx     9226 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/request.py
--rw-r--r--  2.0 unx    28908 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/result.py
--rw-r--r--  2.0 unx     3037 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/safelist_helper.py
--rw-r--r--  2.0 unx     1513 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/section_reducer.py
--rw-r--r--  2.0 unx     4186 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/tag_helper.py
--rw-r--r--  2.0 unx    11102 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/tag_reducer.py
--rw-r--r--  2.0 unx    12480 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/task.py
--rw-r--r--  2.0 unx     2275 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/balbuzard/__init__.py
--rw-r--r--  2.0 unx    25161 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/balbuzard/balbuzard.py
--rw-r--r--  2.0 unx    29180 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/balbuzard/bbcrack.py
--rw-r--r--  2.0 unx    34120 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/balbuzard/patterns.py
--rw-r--r--  2.0 unx        1 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/extractor/__init__.py
--rw-r--r--  2.0 unx     2025 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/extractor/base64.py
--rw-r--r--  2.0 unx     3617 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/extractor/decode_wrapper.py
--rw-r--r--  2.0 unx     4266 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/extractor/ocr.py
--rw-r--r--  2.0 unx      451 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/extractor/pe_file.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/pestudio/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/pestudio/xml/__init__.py
--rw-r--r--  2.0 unx   196476 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/pestudio/xml/features.xml
--rw-r--r--  2.0 unx   350312 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/pestudio/xml/functions.xml
--rw-r--r--  2.0 unx    20008 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/pestudio/xml/languages.xml
--rw-r--r--  2.0 unx    40129 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/pestudio/xml/resources.xml
--rw-r--r--  2.0 unx  1255658 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/pestudio/xml/signatures.xml
--rw-r--r--  2.0 unx   102459 b- defN 23-Mar-24 16:13 assemblyline_v4_service/common/pestudio/xml/strings.xml
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-24 16:13 assemblyline_v4_service/dev/__init__.py
--rw-r--r--  2.0 unx    10592 b- defN 23-Mar-24 16:13 assemblyline_v4_service/dev/run_service_once.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-24 16:13 assemblyline_v4_service/testing/__init__.py
--rw-r--r--  2.0 unx    19711 b- defN 23-Mar-24 16:13 assemblyline_v4_service/testing/helper.py
--rw-r--r--  2.0 unx     1101 b- defN 23-Mar-24 16:13 assemblyline_v4_service/testing/regenerate_results.py
--rw-r--r--  2.0 unx        0 b- defN 23-Mar-24 16:13 assemblyline_v4_service/updater/__init__.py
--rw-r--r--  2.0 unx      133 b- defN 23-Mar-24 16:13 assemblyline_v4_service/updater/__main__.py
--rw-r--r--  2.0 unx     2780 b- defN 23-Mar-24 16:13 assemblyline_v4_service/updater/app.py
--rw-r--r--  2.0 unx     1155 b- defN 23-Mar-24 16:13 assemblyline_v4_service/updater/gunicorn_config.py
--rw-r--r--  2.0 unx     9069 b- defN 23-Mar-24 16:13 assemblyline_v4_service/updater/helper.py
--rw-r--r--  2.0 unx    29655 b- defN 23-Mar-24 16:13 assemblyline_v4_service/updater/updater.py
--rw-r--r--  2.0 unx     1396 b- defN 23-Mar-24 16:14 assemblyline_v4_service-4.4.1.dev9.dist-info/LICENCE.md
--rw-r--r--  2.0 unx     9358 b- defN 23-Mar-24 16:14 assemblyline_v4_service-4.4.1.dev9.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Mar-24 16:14 assemblyline_v4_service-4.4.1.dev9.dist-info/WHEEL
--rw-r--r--  2.0 unx       24 b- defN 23-Mar-24 16:14 assemblyline_v4_service-4.4.1.dev9.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     5551 b- defN 23-Mar-24 16:14 assemblyline_v4_service-4.4.1.dev9.dist-info/RECORD
-54 files, 2421651 bytes uncompressed, 362491 bytes compressed:  85.1%
+Zip file size: 374087 bytes, number of entries: 54
+-rw-r--r--  2.0 unx       12 b- defN 23-May-25 21:44 assemblyline_v4_service/VERSION
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 21:44 assemblyline_v4_service/__init__.py
+-rw-r--r--  2.0 unx     1575 b- defN 23-May-25 21:44 assemblyline_v4_service/healthz.py
+-rw-r--r--  2.0 unx    14547 b- defN 23-May-25 21:44 assemblyline_v4_service/run_privileged_service.py
+-rw-r--r--  2.0 unx     5557 b- defN 23-May-25 21:44 assemblyline_v4_service/run_service.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 21:44 assemblyline_v4_service/common/__init__.py
+-rw-r--r--  2.0 unx     4453 b- defN 23-May-25 21:44 assemblyline_v4_service/common/api.py
+-rw-r--r--  2.0 unx    13039 b- defN 23-May-25 21:44 assemblyline_v4_service/common/base.py
+-rw-r--r--  2.0 unx   147461 b- defN 23-May-25 21:44 assemblyline_v4_service/common/dynamic_service_helper.py
+-rw-r--r--  2.0 unx     3290 b- defN 23-May-25 21:44 assemblyline_v4_service/common/helper.py
+-rw-r--r--  2.0 unx     5376 b- defN 23-May-25 21:44 assemblyline_v4_service/common/icap.py
+-rw-r--r--  2.0 unx     2219 b- defN 23-May-25 21:44 assemblyline_v4_service/common/keytool_parse.py
+-rw-r--r--  2.0 unx     7793 b- defN 23-May-25 21:44 assemblyline_v4_service/common/ontology_helper.py
+-rw-r--r--  2.0 unx     9711 b- defN 23-May-25 21:44 assemblyline_v4_service/common/request.py
+-rw-r--r--  2.0 unx    30349 b- defN 23-May-25 21:44 assemblyline_v4_service/common/result.py
+-rw-r--r--  2.0 unx     3037 b- defN 23-May-25 21:44 assemblyline_v4_service/common/safelist_helper.py
+-rw-r--r--  2.0 unx     1513 b- defN 23-May-25 21:44 assemblyline_v4_service/common/section_reducer.py
+-rw-r--r--  2.0 unx     4186 b- defN 23-May-25 21:44 assemblyline_v4_service/common/tag_helper.py
+-rw-r--r--  2.0 unx    11102 b- defN 23-May-25 21:44 assemblyline_v4_service/common/tag_reducer.py
+-rw-r--r--  2.0 unx    12480 b- defN 23-May-25 21:44 assemblyline_v4_service/common/task.py
+-rw-r--r--  2.0 unx     2338 b- defN 23-May-25 21:44 assemblyline_v4_service/common/utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 21:44 assemblyline_v4_service/common/balbuzard/__init__.py
+-rw-r--r--  2.0 unx    25161 b- defN 23-May-25 21:44 assemblyline_v4_service/common/balbuzard/balbuzard.py
+-rw-r--r--  2.0 unx    29180 b- defN 23-May-25 21:44 assemblyline_v4_service/common/balbuzard/bbcrack.py
+-rw-r--r--  2.0 unx    34120 b- defN 23-May-25 21:44 assemblyline_v4_service/common/balbuzard/patterns.py
+-rw-r--r--  2.0 unx        1 b- defN 23-May-25 21:44 assemblyline_v4_service/common/extractor/__init__.py
+-rw-r--r--  2.0 unx     2025 b- defN 23-May-25 21:44 assemblyline_v4_service/common/extractor/base64.py
+-rw-r--r--  2.0 unx     3617 b- defN 23-May-25 21:44 assemblyline_v4_service/common/extractor/decode_wrapper.py
+-rw-r--r--  2.0 unx     4385 b- defN 23-May-25 21:44 assemblyline_v4_service/common/extractor/ocr.py
+-rw-r--r--  2.0 unx      451 b- defN 23-May-25 21:44 assemblyline_v4_service/common/extractor/pe_file.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 21:44 assemblyline_v4_service/common/pestudio/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 21:44 assemblyline_v4_service/common/pestudio/xml/__init__.py
+-rw-r--r--  2.0 unx   196476 b- defN 23-May-25 21:44 assemblyline_v4_service/common/pestudio/xml/features.xml
+-rw-r--r--  2.0 unx   350312 b- defN 23-May-25 21:44 assemblyline_v4_service/common/pestudio/xml/functions.xml
+-rw-r--r--  2.0 unx    20008 b- defN 23-May-25 21:44 assemblyline_v4_service/common/pestudio/xml/languages.xml
+-rw-r--r--  2.0 unx    40129 b- defN 23-May-25 21:44 assemblyline_v4_service/common/pestudio/xml/resources.xml
+-rw-r--r--  2.0 unx  1255658 b- defN 23-May-25 21:44 assemblyline_v4_service/common/pestudio/xml/signatures.xml
+-rw-r--r--  2.0 unx   102459 b- defN 23-May-25 21:44 assemblyline_v4_service/common/pestudio/xml/strings.xml
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 21:44 assemblyline_v4_service/dev/__init__.py
+-rw-r--r--  2.0 unx    10593 b- defN 23-May-25 21:44 assemblyline_v4_service/dev/run_service_once.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 21:44 assemblyline_v4_service/testing/__init__.py
+-rw-r--r--  2.0 unx    19711 b- defN 23-May-25 21:44 assemblyline_v4_service/testing/helper.py
+-rw-r--r--  2.0 unx     1101 b- defN 23-May-25 21:44 assemblyline_v4_service/testing/regenerate_results.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-25 21:44 assemblyline_v4_service/updater/__init__.py
+-rw-r--r--  2.0 unx      133 b- defN 23-May-25 21:44 assemblyline_v4_service/updater/__main__.py
+-rw-r--r--  2.0 unx     3198 b- defN 23-May-25 21:44 assemblyline_v4_service/updater/app.py
+-rw-r--r--  2.0 unx     1247 b- defN 23-May-25 21:44 assemblyline_v4_service/updater/gunicorn_config.py
+-rw-r--r--  2.0 unx     9069 b- defN 23-May-25 21:44 assemblyline_v4_service/updater/helper.py
+-rw-r--r--  2.0 unx    29322 b- defN 23-May-25 21:44 assemblyline_v4_service/updater/updater.py
+-rw-r--r--  2.0 unx     1396 b- defN 23-May-25 21:44 assemblyline_v4_service-4.4.1.dev94.dist-info/LICENCE.md
+-rw-r--r--  2.0 unx     9359 b- defN 23-May-25 21:44 assemblyline_v4_service-4.4.1.dev94.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-25 21:44 assemblyline_v4_service-4.4.1.dev94.dist-info/WHEEL
+-rw-r--r--  2.0 unx       24 b- defN 23-May-25 21:44 assemblyline_v4_service-4.4.1.dev94.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     5556 b- defN 23-May-25 21:44 assemblyline_v4_service-4.4.1.dev94.dist-info/RECORD
+54 files, 2434821 bytes uncompressed, 364875 bytes compressed:  85.0%
```

## zipnote {}

```diff
@@ -141,23 +141,23 @@
 
 Filename: assemblyline_v4_service/updater/helper.py
 Comment: 
 
 Filename: assemblyline_v4_service/updater/updater.py
 Comment: 
 
-Filename: assemblyline_v4_service-4.4.1.dev9.dist-info/LICENCE.md
+Filename: assemblyline_v4_service-4.4.1.dev94.dist-info/LICENCE.md
 Comment: 
 
-Filename: assemblyline_v4_service-4.4.1.dev9.dist-info/METADATA
+Filename: assemblyline_v4_service-4.4.1.dev94.dist-info/METADATA
 Comment: 
 
-Filename: assemblyline_v4_service-4.4.1.dev9.dist-info/WHEEL
+Filename: assemblyline_v4_service-4.4.1.dev94.dist-info/WHEEL
 Comment: 
 
-Filename: assemblyline_v4_service-4.4.1.dev9.dist-info/top_level.txt
+Filename: assemblyline_v4_service-4.4.1.dev94.dist-info/top_level.txt
 Comment: 
 
-Filename: assemblyline_v4_service-4.4.1.dev9.dist-info/RECORD
+Filename: assemblyline_v4_service-4.4.1.dev94.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## assemblyline_v4_service/VERSION

```diff
@@ -1 +1 @@
-4.4.1.dev9
+4.4.1.dev94
```

## assemblyline_v4_service/healthz.py

 * *Ordering differences only*

```diff
@@ -28,8 +28,8 @@
         if not requests.get(f"{scheme}://{environ['updates_host']}:{environ['updates_port']}/healthz/live",
                             verify=verify).ok:
             raise Exception('Unable to reach local update server')
     exit()
 
 
 if __name__ == '__main__':
-    perform_check()
+    perform_check()
```

## assemblyline_v4_service/common/base.py

```diff
@@ -25,14 +25,15 @@
 # Ignore all other warnings that a service's libraries can generate
 warnings.filterwarnings("ignore")
 
 LOG_LEVEL = logging.getLevelName(os.environ.get("LOG_LEVEL", "INFO"))
 UPDATES_DIR = os.environ.get('UPDATES_DIR', '/updates')
 UPDATES_CA = os.environ.get('UPDATES_CA', '/etc/assemblyline/ssl/al_root-ca.crt')
 PRIVILEGED = os.environ.get('PRIVILEGED', 'false') == 'true'
+MIN_SECONDS_BETWEEN_UPDATES = float(os.environ.get('MIN_SECONDS_BETWEEN_UPDATES', '10.0'))
 
 RECOVERABLE_RE_MSG = [
     "cannot schedule new futures after interpreter shutdown",
     "can't register atexit after shutdown",
     "cannot schedule new futures after shutdown"
 ]
 
@@ -73,14 +74,15 @@
         self.dependencies = self._get_dependencies_info()
         self.ontology = OntologyHelper(self.log, self.service_attributes.name)
 
         # Updater-related
         self.rules_directory: str = None
         self.rules_list: list = []
         self.update_time: int = None
+        self.update_check_time: float = 0.0
         self.rules_hash: str = None
 
     @property
     def api_interface(self):
         return self.get_api_interface()
 
     def _get_dependencies_info(self) -> Dict[str, Dict[str, str]]:
@@ -232,14 +234,20 @@
                     os.makedirs(temp_dir)
                 self._working_directory = tempfile.mkdtemp(dir=temp_dir)
 
         return self._working_directory
 
     # Only relevant for services using updaters (reserving 'updates' as the defacto container name)
     def _download_rules(self):
+        # check if we just tried to download rules to reduce traffic
+        if time.time() - self.update_check_time < MIN_SECONDS_BETWEEN_UPDATES:
+            return
+        self.update_check_time = time.time()
+
+        # Resolve the update target
         scheme, verify = 'http', None
         if os.path.exists(UPDATES_CA):
             scheme, verify = 'https', UPDATES_CA
         url_base = f"{scheme}://{self.dependencies['updates']['host']}:{self.dependencies['updates']['port']}/"
         headers = {
             'X_APIKEY': self.dependencies['updates']['key']
         }
```

## assemblyline_v4_service/common/dynamic_service_helper.py

```diff
@@ -1,51 +1,40 @@
 from datetime import datetime
 from hashlib import sha256
 from json import dumps
 from logging import getLogger
-from re import compile, escape, sub, findall, match as re_match
+from re import compile, escape, findall
+from re import match as re_match
+from re import sub
 from typing import Any, Dict, List, Optional, Union
 from urllib.parse import urlparse
 from uuid import UUID, uuid4
 
 from assemblyline.common import log as al_log
-from assemblyline.common.attack_map import (
-    attack_map,
-    software_map,
-    group_map,
-    revoke_map,
-)
+from assemblyline.common.attack_map import attack_map, group_map, revoke_map, software_map
 from assemblyline.common.digests import get_sha256_for_file
-from assemblyline.common.isotime import (
-    epoch_to_local,
-    LOCAL_FMT,
-    local_to_epoch,
-    MAX_TIME,
-    MIN_TIME,
-    format_time,
-)
+from assemblyline.common.isotime import LOCAL_FMT, MAX_TIME, MIN_TIME, epoch_to_local, format_time, local_to_epoch
 from assemblyline.common.uid import get_random_id
-from assemblyline.odm.base import DOMAIN_REGEX, IP_REGEX, FULL_URI, URI_PATH
-from assemblyline.odm.models.ontology.results import (
-    Process as ProcessModel, Sandbox as SandboxModel,
-    Signature as SignatureModel,
-    NetworkConnection as NetworkConnectionModel
-)
+from assemblyline.odm.base import DOMAIN_REGEX, FULL_URI, IP_REGEX, IPV4_REGEX, URI_PATH
+from assemblyline.odm.models.ontology.results import NetworkConnection as NetworkConnectionModel
+from assemblyline.odm.models.ontology.results import Process as ProcessModel
+from assemblyline.odm.models.ontology.results import Sandbox as SandboxModel
+from assemblyline.odm.models.ontology.results import Signature as SignatureModel
 
 # from assemblyline_v4_service.common.balbuzard.patterns import PatternMatch
 from assemblyline_v4_service.common.base import ServiceBase
 from assemblyline_v4_service.common.request import ServiceRequest
 from assemblyline_v4_service.common.result import (
-    ResultSection,
     ProcessItem,
     ResultProcessTreeSection,
+    ResultSection,
     ResultTableSection,
     TableRow,
 )
-from assemblyline_v4_service.common.safelist_helper import URL_REGEX
+from assemblyline_v4_service.common.safelist_helper import URL_REGEX, is_tag_safelisted
 from assemblyline_v4_service.common.tag_helper import add_tag
 from assemblyline_v4_service.common.task import MaxExtractedExceeded
 
 al_log.init_logging("service.service_base.dynamic_service_helper")
 log = getLogger("assemblyline.service.service_base.dynamic_service_helper")
 
 X86_64 = "x86_64"
@@ -1871,21 +1860,25 @@
             and http.request_headers == request_headers
         ]
         if not network_http_with_details:
             return None
         else:
             return network_http_with_details[0]
 
-    def get_network_connection_by_network_http(self, network_http: NetworkHTTP) -> Optional[NetworkHTTP]:
+    def get_network_connection_by_network_http(self, network_http: NetworkHTTP) -> Optional[NetworkConnection]:
         """
         This method returns the network connection corresponding to the given network http object
         :param network_http: The given network http object
         :return: The corresponding network connection
         """
-        return next((netflow for netflow in self.netflows if netflow.http_details == network_http), None)
+        for netflow in self.netflows:
+            if netflow.http_details == network_http:
+                return netflow
+
+        return None
 
     # Process manipulation methods
     def set_processes(self, processes: List[Process]) -> None:
         """
         This method sets the Process objects.
         :param processes: The Processes to set
         :return: None
@@ -1922,15 +1915,18 @@
     def add_process(self, process: Process) -> None:
         """
         This method adds a validated Process object to the list of processes
         :param process: The Process object to be added
         :return: None
         """
         if self._validate_process(process):
-            self._guid_process_map[process.objectid.guid] = process
+            if isinstance(process.objectid.guid, str):
+                self._guid_process_map[process.objectid.guid.upper()] = process
+            else:
+                self._guid_process_map[process.objectid.guid] = process
             self.set_parent_details(process)
             self.set_child_details(process)
             self.processes.append(process)
         else:
             log.debug("Invalid process, ignoring...")
             return
 
@@ -3254,14 +3250,252 @@
     """
     [service.ontology.add_result_part(ProcessModel, process.as_primitives()) for process in ontres.get_processes()]
     [service.ontology.add_result_part(SandboxModel, sandbox.as_primitives()) for sandbox in ontres.get_sandboxes()]
     [service.ontology.add_result_part(SignatureModel, signature.as_primitives()) for signature in ontres.get_signatures()]
     [service.ontology.add_result_part(NetworkConnectionModel, network_connection.as_primitives()) for network_connection in ontres.get_network_connections()]
 
 
+def convert_sysmon_processes(
+    sysmon: List[Dict[str, Any]],
+    safelist: Dict[str, Dict[str, List[str]]],
+    ontres: OntologyResults,
+):
+    """
+    This method creates the GUID -> Process lookup table
+    :param sysmon: A list of processes observed during the analysis of the task by the Sysmon tool
+    :param safelist: A dictionary containing matches and regexes for use in safelisting values
+    :param ontres: The Ontology Results object instance
+    :return: None
+    """
+    session = ontres.sandboxes[-1].objectid.session
+    for event in sysmon:
+        event_id = int(event["System"]["EventID"])
+        # EventID 10: ProcessAccess causes too many misconfigurations of the process tree
+        if event_id == 10:
+            continue
+        process: Dict[str, str] = {}
+        event_data = event["EventData"]["Data"]
+        for data in event_data:
+            name = data["@Name"].lower()
+            text = data.get("#text")
+
+            # Process Create and Terminate
+            if name == "utctime" and event_id in [1, 5]:
+                if "." in text:
+                    text = text[:text.index(".")]
+                t = str(datetime.strptime(text, LOCAL_FMT))
+                if event_id == 1:
+                    process["start_time"] = t
+                else:
+                    process["start_time"] = MIN_TIME
+                    process["end_time"] = t
+            elif name == "utctime":
+                if "." in text:
+                    text = text[:text.index(".")]
+                t = str(datetime.strptime(text, LOCAL_FMT))
+                process["time_observed"] = t
+            elif name in ["sourceprocessguid", "parentprocessguid"]:
+                process["pguid"] = text
+            elif name in ["processguid", "targetprocessguid"]:
+                process["guid"] = text
+            elif name in ["parentprocessid", "sourceprocessid"]:
+                process["ppid"] = int(text)
+            elif name in ["processid", "targetprocessid"]:
+                process["pid"] = int(text)
+            elif name in ["sourceimage"]:
+                process["pimage"] = text
+            elif name in ["image", "targetimage"]:
+                if not is_tag_safelisted(text, ["dynamic.process.file_name"], safelist):
+                    process["image"] = text
+            elif name in ["parentcommandline"]:
+                if not is_tag_safelisted(
+                    text, ["dynamic.process.command_line"], safelist
+                ):
+                    process["pcommand_line"] = text
+            elif name in ["commandline"]:
+                if not is_tag_safelisted(
+                    text, ["dynamic.process.command_line"], safelist
+                ):
+                    process["command_line"] = text
+            elif name == "originalfilename":
+                process["original_file_name"] = text
+            elif name == "integritylevel":
+                process["integrity_level"] = text
+            elif name == "hashes":
+                split_hash = text.split("=")
+                if len(split_hash) == 2:
+                    _, hash_value = split_hash
+                    process["image_hash"] = hash_value
+
+        if (
+            not process.get("pid")
+            or not process.get("image")
+            or not process.get("start_time")
+        ):
+            continue
+
+        if ontres.is_guid_in_gpm(process["guid"]):
+            ontres.update_process(**process)
+        else:
+            p_oid = ProcessModel.get_oid(
+                {
+                    "pid": process["pid"],
+                    "ppid": process.get("ppid"),
+                    "image": process["image"],
+                    "command_line": process.get("command_line"),
+                }
+            )
+            p = ontres.create_process(
+                objectid=ontres.create_objectid(
+                    tag=Process.create_objectid_tag(process["image"]),
+                    ontology_id=p_oid,
+                    guid=process.get("guid"),
+                    session=session,
+                ),
+                **process,
+            )
+            ontres.add_process(p)
+
+
+def convert_sysmon_network(
+    sysmon: List[Dict[str, Any]],
+    network: Dict[str, Any],
+    safelist: Dict[str, Dict[str, List[str]]],
+    convert_timestamp_to_epoch: bool = False,
+) -> None:
+    """
+    This method converts network connections observed by Sysmon to the format supported by common sandboxes
+    :param sysmon: A list of processes observed during the analysis of the task by the Sysmon tool
+    :param network: The JSON of the network section from the report generated by common sandboxes
+    :param safelist: A dictionary containing matches and regexes for use in safelisting values
+    :param convert_timestamp_to_epoch: A flag indicating if we want timestamps converted to EPOCH
+    :return: None
+    """
+    for event in sysmon:
+        event_id = int(event["System"]["EventID"])
+
+        # There are two main EventIDs that describe network events: 3 (Network connection) and 22 (DNS query)
+        if event_id == 3:
+            protocol = None
+            network_conn = {
+                "src": None,
+                "dst": None,
+                "time": None,
+                "dport": None,
+                "sport": None,
+                "guid": None,
+                "pid": None,
+                "image": None,
+            }
+            for data in event["EventData"]["Data"]:
+                name = data["@Name"]
+                text = data.get("#text")
+                if name == "UtcTime":
+                    if convert_timestamp_to_epoch:
+                        network_conn["time"] = datetime.strptime(text, "%Y-%m-%d %H:%M:%S.%f").timestamp()
+                    else:
+                        if "." in text:
+                            text = text[:text.index(".")]
+                        network_conn["time"] = str(datetime.strptime(text, LOCAL_FMT))
+                elif name == "ProcessGuid":
+                    network_conn["guid"] = text
+                elif name == "ProcessId":
+                    network_conn["pid"] = int(text)
+                elif name == "Image":
+                    network_conn["image"] = text
+                elif name == "Protocol":
+                    protocol = text.lower()
+                elif name == "SourceIp":
+                    if re_match(IPV4_REGEX, text):
+                        network_conn["src"] = text
+                elif name == "SourcePort":
+                    network_conn["sport"] = int(text)
+                elif name == "DestinationIp":
+                    if re_match(IPV4_REGEX, text):
+                        network_conn["dst"] = text
+                elif name == "DestinationPort":
+                    network_conn["dport"] = int(text)
+            if (
+                any(network_conn[key] is None for key in network_conn.keys())
+                or not protocol
+            ):
+                continue
+            elif any(
+                req["dst"] == network_conn["dst"]
+                and req["dport"] == network_conn["dport"]
+                and req["src"] == network_conn["src"]
+                and req["sport"] == network_conn["sport"]
+                for req in network[protocol]
+            ):
+                # Replace record since we have more info from Sysmon
+                for req in network[protocol][:]:
+                    if (
+                        req["dst"] == network_conn["dst"]
+                        and req["dport"] == network_conn["dport"]
+                        and req["src"] == network_conn["src"]
+                        and req["sport"] == network_conn["sport"]
+                    ):
+                        network[protocol].remove(req)
+                        network[protocol].append(network_conn)
+            else:
+                network[protocol].append(network_conn)
+        elif event_id == 22:
+            dns_query = {
+                "type": "A",
+                "request": None,
+                "answers": [],
+                "time": None,
+                "guid": None,
+                "pid": None,
+                "image": None,
+            }
+            for data in event["EventData"]["Data"]:
+                name = data["@Name"]
+                text = data.get("#text")
+                if text is None:
+                    continue
+                if name == "UtcTime":
+                    if convert_timestamp_to_epoch:
+                        dns_query["time"] = datetime.strptime(text, "%Y-%m-%d %H:%M:%S.%f").timestamp()
+                    else:
+                        if "." in text:
+                            text = text[:text.index(".")]
+                        dns_query["time"] = str(datetime.strptime(text, LOCAL_FMT))
+                elif name == "ProcessGuid":
+                    dns_query["guid"] = text
+                elif name == "ProcessId":
+                    dns_query["pid"] = int(text)
+                elif name == "QueryName":
+                    if not is_tag_safelisted(
+                        text, ["network.dynamic.domain"], safelist
+                    ):
+                        dns_query["request"] = text
+                elif name == "QueryResults":
+                    ip = findall(IPV4_REGEX, text)
+                    for item in ip:
+                        dns_query["answers"].append({"data": item, "type": "A"})
+                elif name == "Image":
+                    dns_query["image"] = text
+            if any(dns_query[key] is None for key in dns_query.keys()):
+                continue
+            elif any(
+                query["request"] == dns_query["request"]
+                for query in network.get("dns", [])
+            ):
+                # Replace record since we have more info from Sysmon
+                for query in network["dns"][:]:
+                    if query["request"] == dns_query["request"]:
+                        network["dns"].remove(query)
+                        network["dns"].append(dns_query)
+            else:
+                if "dns" not in network:
+                    network["dns"] = []
+                network["dns"].append(dns_query)
+
+
 def extract_iocs_from_text_blob(
     blob: str,
     result_section: ResultTableSection,
     so_sig: Optional[Signature] = None,
     source: Optional[ObjectID] = None,
     enforce_char_min: bool = False,
     enforce_domain_char_max: bool = False,
@@ -3294,24 +3528,24 @@
     ips = set(findall(IP_REGEX, blob))
     # There is overlap here between regular expressions, so we want to isolate domains that are not ips
     domains = set(findall(DOMAIN_REGEX, blob)) - ips
     # There is overlap here between regular expressions, so we want to isolate uris that are not domains
     # TODO: Are we missing IOCs to the point where we need a different regex?
     # uris = {uri.decode() for uri in set(findall(PatternMatch.PAT_URI_NO_PROTOCOL, blob.encode()))} - domains - ips
     uris = set(findall(URL_REGEX, blob)) - domains - ips
-    for ip in ips:
+    for ip in sorted(ips):
         if add_tag(result_section, f"network.{network_tag_type}.ip", ip, safelist):
             if not result_section.section_body.body:
                 result_section.add_row(TableRow(ioc_type="ip", ioc=ip))
             elif (
                 dumps({"ioc_type": "ip", "ioc": ip})
                 not in result_section.section_body.body
             ):
                 result_section.add_row(TableRow(ioc_type="ip", ioc=ip))
-    for domain in domains:
+    for domain in sorted(domains):
         if enforce_char_min and len(domain) < MIN_DOMAIN_CHARS:
             continue
         if enforce_domain_char_max and len(domain) > MAX_DOMAIN_CHARS:
             continue
 
         # Check if the domain ends with a TLD that is frequently a false positive
         if any(domain.lower().endswith(tld) for tld in COMMON_FP_TLDS):
@@ -3335,15 +3569,15 @@
                 result_section.add_row(TableRow(ioc_type="domain", ioc=domain))
             elif (
                 dumps({"ioc_type": "domain", "ioc": domain})
                 not in result_section.section_body.body
             ):
                 result_section.add_row(TableRow(ioc_type="domain", ioc=domain))
 
-    for uri in uris:
+    for uri in sorted(uris):
         if enforce_char_min and len(uri) < MIN_URI_CHARS:
             continue
         if any(invalid_uri_char in uri for invalid_uri_char in ['"', "'", '<', '>', "(", ")"]):
             for invalid_uri_char in ['"', "'", '<', '>', "(", ")"]:
                 for u in uri.split(invalid_uri_char):
                     if re_match(FULL_URI, u):
                         uri = u
```

## assemblyline_v4_service/common/ontology_helper.py

```diff
@@ -170,15 +170,16 @@
         }
 
         self.attach_parts(ontology)
 
         # Include Ontological data
         ontology_suffix = f"{request.sha256}.ontology"
         ontology_path = os.path.join(working_dir, ontology_suffix)
-        open(ontology_path, 'w').write(json.dumps(ontology))
+        with open(ontology_path, 'w') as f:
+            f.write(json.dumps(ontology))
         attachment_name = f'{request.task.service_name}_{ontology_suffix}'.lower()
         request.add_supplementary(path=ontology_path, name=attachment_name,
                                   description=f"Result Ontology from {request.task.service_name}",
                                   classification=max_result_classification)
 
     def reset(self) -> None:
         self._file_info = {}
```

## assemblyline_v4_service/common/request.py

```diff
@@ -7,14 +7,15 @@
 from assemblyline.common import forge
 from assemblyline.common import log as al_log
 from assemblyline.common.classification import Classification
 from assemblyline_v4_service.common.api import ServiceAPI, PrivilegedServiceAPI
 from assemblyline_v4_service.common.extractor.ocr import ocr_detections
 from assemblyline_v4_service.common.result import Heuristic, Result, ResultKeyValueSection
 from assemblyline_v4_service.common.task import Task, MaxExtractedExceeded
+from assemblyline_v4_service.common.utils import extract_passwords
 
 CLASSIFICATION = forge.get_classification()
 WEBP_MAX_SIZE = 16383
 
 
 class ServiceRequest:
     def __init__(self, task: Task) -> None:
@@ -121,14 +122,20 @@
                     detections = ocr_detections(outtmp.name, ocr_io)
                 except (SystemError, RuntimeError):
                     # If we encountered a system error, then let OCR analysis go
                     # This shouldn't affect service analysis
                     pass
 
             if detections:
+                # If we were able to detect potential passwords, add it to the submission's password list
+                if detections.get('password'):
+                    pw_list = set(self.temp_submission_data.get('passwords', []))
+                    [pw_list.update(extract_passwords(pw_string)) for pw_string in detections['password']]
+                    self.temp_submission_data['passwords'] = list(pw_list)
+
                 heuristic = Heuristic(ocr_heuristic_id, signatures={
                     f'{k}_strings': len(v) for k, v in detections.items()})
                 ocr_section = ResultKeyValueSection(f'Suspicious strings found during OCR analysis on file {name}')
                 ocr_section.set_heuristic(heuristic)
                 for k, v in detections.items():
                     ocr_section.set_item(k, v)
                 data['ocr_section'] = ocr_section
```

## assemblyline_v4_service/common/result.py

```diff
@@ -10,14 +10,17 @@
 from assemblyline.common.dict_utils import unflatten
 from assemblyline.common.str_utils import StringTable, safe_str
 from assemblyline_v4_service.common.helper import get_service_attributes, get_heuristics
 
 if TYPE_CHECKING:  # Avoid circular dependency
     from assemblyline_v4_service.common.request import ServiceRequest
 
+# Type of values in KV sections
+KV_VALUE_TYPE = Union[str, bool, int]
+
 al_log.init_logging('service.result')
 log = logging.getLogger('assemblyline.service.result')
 
 SERVICE_ATTRIBUTES = None
 HEUR_LIST = None
 
 BODY_FORMAT = StringTable('BODY_FORMAT', [
@@ -65,15 +68,15 @@
 
 class Heuristic:
     def __init__(self, heur_id: int,
                  attack_id: Optional[str] = None,
                  signature: Optional[str] = None,
                  attack_ids: Optional[List[str]] = None,
                  signatures: Optional[Dict[str, int]] = None,
-                 frequency: Optional[int] = 1,
+                 frequency: int = 1,
                  score_map: Optional[Dict[str, int]] = None):
 
         # Lazy load heuristics
         global HEUR_LIST
         if not HEUR_LIST:
             HEUR_LIST = get_heuristics()
 
@@ -198,31 +201,36 @@
 
     def increment_frequency(self, frequency: int = 1):
         # Increment the signature less frequency of the heuristic
         self._frequency += frequency
 
 
 class SectionBody:
-    def __init__(self, body_format: BODY_FORMAT, body=None):
+    def __init__(self, body_format, body=None):
         self._format = body_format
         self._data = body
+        self._config = {}
 
     @property
     def format(self):
         return self._format
 
     @property
-    def body(self):
+    def body(self) -> str | None:
         if not self._data:
             return None
         elif not isinstance(self._data, str):
             return json.dumps(self._data)
         else:
             return self._data
 
+    @property
+    def config(self) -> dict:
+        return self._config
+
     def set_body(self, body):
         self._data = body
 
 
 class TextSectionBody(SectionBody):
     def __init__(self, body=None) -> None:
         super().__init__(BODY_FORMAT.TEXT, body=body)
@@ -274,29 +282,31 @@
                     'domain': [cmap_min, cmap_max],
                     'values': values
                 }}
         self._data = cmap
 
 
 class KVSectionBody(SectionBody):
-    def __init__(self, **kwargs) -> None:
+    def __init__(self, **kwargs: KV_VALUE_TYPE) -> None:
+        self._data: dict[str, KV_VALUE_TYPE]
         super().__init__(BODY_FORMAT.KEY_VALUE, body=kwargs)
 
-    def set_item(self, key: str, value: Union[str, bool, int]) -> None:
+    def set_item(self, key: str, value: KV_VALUE_TYPE) -> None:
         self._data[str(key)] = value
 
-    def update_items(self, new_dict: dict):
+    def update_items(self, new_dict: dict[str, KV_VALUE_TYPE]):
         self._data.update({str(k): v for k, v in new_dict.items()})
 
 
 class OrderedKVSectionBody(SectionBody):
-    def __init__(self) -> None:
-        super().__init__(BODY_FORMAT.ORDERED_KEY_VALUE, body=[])
+    def __init__(self, **kwargs: KV_VALUE_TYPE) -> None:
+        self._data: list[tuple[str, KV_VALUE_TYPE]]
+        super().__init__(BODY_FORMAT.ORDERED_KEY_VALUE, body=[(str(key), value) for key, value in kwargs.items()])
 
-    def add_item(self, key: str, value: Union[str, bool, int]) -> None:
+    def add_item(self, key: str, value: KV_VALUE_TYPE) -> None:
         self._data.append((str(key), value))
 
 
 class JSONSectionBody(SectionBody):
     def __init__(self) -> None:
         super().__init__(BODY_FORMAT.JSON, body={})
 
@@ -387,14 +397,19 @@
 
 class TableSectionBody(SectionBody):
     def __init__(self) -> None:
         super().__init__(BODY_FORMAT.TABLE, body=[])
 
     def add_row(self, row: TableRow) -> None:
         self._data.append(row)
+        self.set_column_order(list(row.keys()))
+
+    def set_column_order(self, order: List[str]):
+        self._config = {'column_order': order}
+
 
 
 class ImageSectionBody(SectionBody):
     def __init__(self, request: ServiceRequest) -> None:
         self._request = request
         super().__init__(BODY_FORMAT.IMAGE, body=[])
 
@@ -408,40 +423,40 @@
         return sections
 
 
 class MultiSectionBody(SectionBody):
     def __init__(self) -> None:
         super().__init__(BODY_FORMAT.MULTI, body=[])
 
-    def add_section_body(self, section_body: SectionBody) -> str:
-        self._data.append((section_body.format, section_body._data))
+    def add_section_body(self, section_body: SectionBody) -> None:
+        self._data.append((section_body.format, section_body._data, section_body._config))
 
 
 class DividerSectionBody(SectionBody):
     def __init__(self) -> None:
         super().__init__(BODY_FORMAT.DIVIDER, body=None)
 
 
 class TimelineSectionBody(SectionBody):
     def __init__(self):
-        return super().__init__(BODY_FORMAT.TIMELINE, body=[])
+        super().__init__(BODY_FORMAT.TIMELINE, body=[])
 
     def add_node(self, title: str, content: str, opposite_content: str,
                  icon: str = None, signatures: List[str] = [], score: int = 0) -> None:
         self._data.append(dict(title=title, content=content, opposite_content=opposite_content,
                           icon=icon, signatures=signatures, score=score))
 
 
 class ResultSection:
     def __init__(
             self,
             title_text: Union[str, List],
             body: Optional[Union[str, SectionBody]] = None,
             classification: Optional[Classification] = None,
-            body_format: BODY_FORMAT = BODY_FORMAT.TEXT,
+            body_format=BODY_FORMAT.TEXT,
             heuristic: Optional[Heuristic] = None,
             tags: Optional[Dict[str, List[str]]] = None,
             parent: Optional[Union[ResultSection, Result]] = None,
             zeroize_on_tag_safe: bool = False,
             auto_collapse: bool = False,
             zeroize_on_sig_safe: bool = True,
     ):
@@ -452,18 +467,20 @@
 
         self._finalized: bool = False
         self.parent = parent
         self._section = None
         self._subsections: List[ResultSection] = []
         if isinstance(body, SectionBody):
             self._body_format = body.format
+            self._body_config = body.config
             self._body = body.body
         else:
-            self._body_format: BODY_FORMAT = body_format
-            self._body: str = body
+            self._body_format = body_format
+            self._body = body
+            self._body_config = {}
         self.classification: Classification = classification or SERVICE_ATTRIBUTES.default_result_classification
         self.depth: int = 0
         self._tags = tags or {}
         self._heuristic = None
         self.zeroize_on_tag_safe = zeroize_on_tag_safe
         self.auto_collapse = auto_collapse
         self.zeroize_on_sig_safe = zeroize_on_sig_safe
@@ -489,14 +506,18 @@
         return self._body
 
     @property
     def body_format(self):
         return self._body_format
 
     @property
+    def body_config(self):
+        return self._body_config
+
+    @property
     def heuristic(self):
         return self._heuristic
 
     @property
     def subsections(self):
         return self._subsections
 
@@ -568,18 +589,18 @@
         for subsection in self._subsections:
             if subsection.finalize(depth=depth+1):
                 tmp_subs.append(subsection)
         self._subsections = tmp_subs
 
         return True
 
-    def set_body(self, body: Union[str, SectionBody], body_format: BODY_FORMAT = None) -> None:
+    def set_body(self, body: Union[str, SectionBody], body_format=None) -> None:
         if isinstance(body, SectionBody):
             self._body = body.body
-            self._body_format = body.body_format
+            self._body_format = body._format
         else:
             self._body = body
             if body_format:
                 self._body_format = body_format
 
     def set_heuristic(
             self, heur: Union[int, Heuristic, None],
@@ -620,21 +641,25 @@
         self.section_body = section_body
         super().__init__(title_text, body_format=self.section_body.format, **kwargs)
 
     @property
     def body(self):
         return self.section_body.body
 
+    @property
+    def body_config(self):
+        return self.section_body.config
+
     def add_line(self, text: Union[str, List]) -> None:
         raise InvalidFunctionException("Do not use default add_line method in a type specific section.")
 
     def add_lines(self, line_list: List[str]) -> None:
         raise InvalidFunctionException("Do not use default add_lines method in a type specific section.")
 
-    def set_body(self, body: Union[str, SectionBody], body_format: BODY_FORMAT = BODY_FORMAT.TEXT) -> None:
+    def set_body(self, body: Union[str, SectionBody], body_format=BODY_FORMAT.TEXT) -> None:
         raise InvalidFunctionException("Do not use default set_body method in a type specific section.")
 
 
 class ResultTextSection(ResultSection):
     def __init__(self, title_text: Union[str, List], **kwargs):
         # Not allowed to specified body_format since locked to TEXT
         kwargs.pop('body_format', None)
@@ -646,72 +671,83 @@
         # Not allowed to specified body_format since locked to MEMORY_DUMP
         kwargs.pop('body_format', None)
         super().__init__(title_text, body_format=BODY_FORMAT.MEMORY_DUMP, **kwargs)
 
 
 class ResultGraphSection(TypeSpecificResultSection):
     def __init__(self, title_text: Union[str, List],  **kwargs):
+        self.section_body: GraphSectionBody
         super().__init__(title_text, GraphSectionBody(), **kwargs)
 
     def set_colormap(self, cmap_min: int, cmap_max: int, values: List[int]) -> None:
         self.section_body.set_colormap(cmap_min, cmap_max, values)
 
 
 class ResultURLSection(TypeSpecificResultSection):
     def __init__(self, title_text: Union[str, List], **kwargs):
+        self.section_body: URLSectionBody
         super().__init__(title_text, URLSectionBody(), **kwargs)
 
     def add_url(self, url: str, name: Optional[str] = None) -> None:
         self.section_body.add_url(url, name=name)
 
 
 class ResultKeyValueSection(TypeSpecificResultSection):
-    def __init__(self, title_text: Union[str, List], **kwargs):
-        super().__init__(title_text, KVSectionBody(), **kwargs)
+    def __init__(self, title_text: Union[str, List], body: dict[str, KV_VALUE_TYPE] | None = None, **kwargs):
+        self.section_body: KVSectionBody
+        super().__init__(title_text, KVSectionBody(**(body if body else {})), **kwargs)
 
     def set_item(self, key: str, value: Union[str, bool, int]) -> None:
         self.section_body.set_item(key, value)
 
     def update_items(self, new_dict):
         self.section_body.update_items(new_dict)
 
 
 class ResultOrderedKeyValueSection(TypeSpecificResultSection):
-    def __init__(self, title_text: Union[str, List], **kwargs):
-        super().__init__(title_text, OrderedKVSectionBody(), **kwargs)
+    def __init__(self, title_text: Union[str, List], body: dict[str, KV_VALUE_TYPE] | None = None, **kwargs):
+        self.section_body: OrderedKVSectionBody
+        super().__init__(title_text, OrderedKVSectionBody(**(body if body else {})), **kwargs)
 
     def add_item(self, key: str, value: Union[str, bool, int]) -> None:
         self.section_body.add_item(key, value)
 
 
 class ResultJSONSection(TypeSpecificResultSection):
     def __init__(self, title_text: Union[str, List], **kwargs):
+        self.section_body: JSONSectionBody
         super().__init__(title_text, JSONSectionBody(), **kwargs)
 
     def set_json(self, json_body: dict) -> None:
         self.section_body.set_json(json_body)
 
     def update_json(self, json_body: dict) -> None:
         self.section_body.update_json(json_body)
 
 
 class ResultProcessTreeSection(TypeSpecificResultSection):
     def __init__(self, title_text: Union[str, List], **kwargs):
+        self.section_body: ProcessTreeSectionBody
         super().__init__(title_text, ProcessTreeSectionBody(), **kwargs)
 
     def add_process(self, process: ProcessItem) -> None:
         self.section_body.add_process(process)
 
 
 class ResultTableSection(TypeSpecificResultSection):
     def __init__(self, title_text: Union[str, List], **kwargs):
+        self.section_body: TableSectionBody
         super().__init__(title_text, TableSectionBody(), **kwargs)
 
     def add_row(self, row: TableRow) -> None:
         self.section_body.add_row(row)
+        self.set_column_order(list(row.keys()))
+
+    def set_column_order(self, order: List[str]):
+        self.section_body.set_column_order(order)
 
 
 class ResultImageSection(TypeSpecificResultSection):
     def __init__(self, request: ServiceRequest, title_text: Union[str, List], **kwargs) -> None:
         self.section_body: ImageSectionBody
         super().__init__(title_text, ImageSectionBody(request), **kwargs)
 
@@ -727,41 +763,44 @@
             return None
 
         return ocr_section
 
 
 class ResultTimelineSection(TypeSpecificResultSection):
     def __init__(self, title_text: Union[str, List], **kwargs):
+        self.section_body: TimelineSectionBody
         super().__init__(title_text,  TimelineSectionBody(), **kwargs)
 
     def add_node(self, title: str, content: str, opposite_content: str, icon: str = None, signatures: List[str] = [],
                  score: int = 0) -> None:
         self.section_body.add_node(title=title, content=content, opposite_content=opposite_content,
                                    icon=icon, signatures=signatures, score=score)
 
 
 class ResultMultiSection(TypeSpecificResultSection):
     def __init__(self, title_text: Union[str, List], **kwargs):
+        self.section_body: MultiSectionBody
         super().__init__(title_text,  MultiSectionBody(), **kwargs)
 
-    def add_section_part(self, section_part: SectionBody) -> bool:
+    def add_section_part(self, section_part: SectionBody) -> None:
         self.section_body.add_section_body(section_part)
 
 
 class Result:
     def __init__(self, sections: Optional[List[ResultSection]] = None) -> None:
         self._flattened_sections: List[Dict[str, Any]] = []
         self._score: int = 0
         self.sections: List[ResultSection] = sections or []
 
     def _append_section(self, section: ResultSection) -> None:
         self._flattened_sections.append(dict(
             body=section.body,
             classification=section.classification,
             body_format=section.body_format,
+            body_config=section.body_config,
             depth=section.depth,
             heuristic=get_heuristic_primitives(section.heuristic),
             tags=unflatten(section.tags),
             title_text=section.title_text,
             zeroize_on_tag_safe=section.zeroize_on_tag_safe,
             auto_collapse=section.auto_collapse
         ))
@@ -802,16 +841,16 @@
         for section in to_delete_sections:
             self.sections.remove(section)
 
         # Flatten all the sections into a flat list
         for section in self.sections:
             self._flatten_sections(section)
 
-        for section in self._flattened_sections:
-            heuristic = section.get('heuristic')
+        for flattened_section in self._flattened_sections:
+            heuristic = flattened_section.get('heuristic')
             if heuristic:
                 self._score += heuristic['score']
 
         result = dict(
             score=self._score,
             sections=self._flattened_sections,
         )
```

## assemblyline_v4_service/common/utils.py

```diff
@@ -1,7 +1,9 @@
+from __future__ import annotations
+
 import signal
 import sys
 import ctypes
 import re
 
 libc = ctypes.CDLL("libc.so.6")
 
@@ -60,16 +62,16 @@
         return self
 
     def __exit__(self, exc_type, exc_val, exc_tb):
         signal.alarm(0)
         signal.signal(signal.SIGALRM, self.alarm_default)
 
 
-def extract_passwords(text):
-    passwords = set()
+def extract_passwords(text: str) -> set[str]:
+    passwords: set[str] = set()
     text_split, text_split_n = set(text.split()), set(text.split("\n"))
     passwords.update(text_split)
     passwords.update(re.split(r"\W+", text))
     for i, r in enumerate(PASSWORD_REGEXES):
         for line in text_split:
             if PASSWORD_WORDS[i] in line.lower():
                 passwords.update(re.split(r, line))
```

## assemblyline_v4_service/common/extractor/ocr.py

```diff
@@ -1,14 +1,15 @@
 from __future__ import annotations
 
 from typing import TextIO
 
 import regex
 
 from assemblyline_v4_service.common.helper import get_service_manifest
+from assemblyline_v4_service.common.utils import PASSWORD_WORDS
 
 # TODO: Would prefer this mapping to be dynamic from trusted sources (ie. import from library), but will copy-paste for now
 OCR_INDICATORS_MAPPING: dict[str, list[str]] = {
     'ransomware': [
         # https://github.com/cuckoosandbox/community/blob/master/modules/signatures/windows/ransomware_message.py
         "your files", "your data", "your documents", "restore files",
         "restore data", "restore the files", "restore the data", "recover files",
@@ -26,15 +27,16 @@
     ],
     'macros': [
         # https://github.com/cuckoosandbox/community/blob/17d57d46ccbca0327a8299cb93abba8604b74df7/modules/signatures/windows/office_enablecontent_ocr.py
         "enable macro",
         "enable content",
         "enable editing",
     ],
-    'banned': []
+    'banned': [],
+    'password': PASSWORD_WORDS
 }
 
 
 def ocr_detections(image_path: str, ocr_io: TextIO = None) -> dict[str, list[str]]:
     try:
         import pytesseract
         from PIL import Image
@@ -85,11 +87,11 @@
         if None in indicator_hits:
             indicator_hits.remove(None)
 
         if list_of_strings:
             if len(indicator_hits) >= 2:
                 # We consider the detection to be credible if there's more than a single indicator hit
                 detection_output[indicator] = list_of_strings
-            if indicator == 'banned':
-                # Except if we're dealing with banned, one hit is more than enough
+            if indicator in ['banned', 'password']:
+                # Except if we're dealing with banned/password, one hit is more than enough
                 detection_output[indicator] = list_of_strings
     return detection_output
```

## assemblyline_v4_service/dev/run_service_once.py

```diff
@@ -98,14 +98,15 @@
                 size=file_info['size'],
                 type=file_info['type'],
             ),
             filename=file_name,
             min_classification=forge.get_classification().UNRESTRICTED,
             max_files=501,  # TODO: get the actual value
             ttl=3600
+
         ))
 
         LOG.info(f"Starting task with SID: {service_task.sid}")
 
         # Set the working directory to a directory with same parent as input file
         if os.path.isdir(working_dir):
             shutil.rmtree(working_dir)
```

## assemblyline_v4_service/updater/app.py

```diff
@@ -1,41 +1,68 @@
 import functools
 import os
+import json
+import copy
 
-import requests
 from flask import jsonify, make_response, request, send_from_directory, send_file, Flask
 from werkzeug.exceptions import Unauthorized, ServiceUnavailable
 
-session = requests.session()
+try:
+    from gevent.monkey import patch_all
+    patch_all()
+except ImportError:
+    pass
+
+from .updater import STATUS_FILE
+
+
 app = Flask('service_updater')
 AUTH_KEY = os.environ.get('AL_INSTANCE_KEY', 'ThisIsARandomAuthKey...ChangeMe!')
 AL_ROOT_CA = os.environ.get('AL_ROOT_CA', '/etc/assemblyline/ssl/al_root-ca.crt')
 
 ssl_context = None
 if os.path.exists(AL_ROOT_CA):
     ssl_context = ('/etc/assemblyline/ssl/al_updates/tls.crt', '/etc/assemblyline/ssl/al_updates/tls.key')
 
 
+status_last_read_time = 0
+NO_STATUS = {
+    'local_update_time': 0,
+    'download_available': False,
+    '_directory': None,
+    '_tar': None,
+}
+status_last_read = copy.deepcopy(NO_STATUS)
+
+
+def _get_status():
+    global status_last_read, status_last_read_time
+    try:
+        last_modified = os.path.getmtime(STATUS_FILE)
+    except OSError:
+        return NO_STATUS
+
+    if status_last_read_time < last_modified:
+        with open(STATUS_FILE, 'r') as handle:
+            status_last_read = json.load(handle)
+            status_last_read_time = last_modified
+
+    return status_last_read
+
+
 @app.route('/healthz/live')
 def container_ready():
     """Only meant to convey if the container is running, not if updates are ready."""
     return make_response("OK")
 
 
 @app.route('/status')
 def update_status():
     """A report on readiness for services to run."""
-    request = session.get('http://localhost:9999')
-    request.raise_for_status()
-    response = app.response_class(
-        response=request.text,
-        status=200,
-        mimetype='application/json'
-    )
-    return response
+    return _get_status()
 
 
 def api_login(func):
     @functools.wraps(func)
     def base(*args, **kwargs):
         # Before anything else, check that the API key is set
         apikey = request.environ.get('HTTP_X_APIKEY', None)
@@ -45,18 +72,17 @@
         return func(*args, **kwargs)
 
     return base
 
 
 def get_paths():
     try:
-        request = session.get('http://localhost:9999')
-        request.raise_for_status()
-        path = request.json()['_directory']
-        tar = request.json()['_tar']
+        status = _get_status()
+        path = status['_directory']
+        tar = status['_tar']
         if path is None or not os.path.isdir(path):
             raise ValueError()
         if tar is None or not os.path.isfile(tar):
             raise ValueError()
     except Exception:
         raise ServiceUnavailable("No update ready")
     return path, tar
```

## assemblyline_v4_service/updater/gunicorn_config.py

```diff
@@ -3,27 +3,30 @@
 If these variables are set globally for ui and you don't want it to effect the updaters
 they can be overwritten (for all future systems) by setting them in the service manifest
 entry for the updater container, or (for a running system) in the service configuration
 UI panel for the update container.
 """
 from os import environ as env
 
+# What backend gunicorn should use for workers
+worker_class = env.get('WORKER_CLASS', 'gevent')
+
 # Port to bind to
 bind = f":{int(env.get('PORT', 5003))}"
 
 # Number of processes to launch
 workers = int(env.get('WORKERS', 1))
 
 # Number of concurrent handled connections
 threads = int(env.get('THREADS', 4))
 worker_connections = int(env.get('WORKER_CONNECTIONS', '1000'))
 
 # Recycle the process after X request randomized by the jitter
-max_requests = int(env.get('MAX_REQUESTS', '1000'))
-max_requests_jitter = int(env.get('MAX_REQUESTS_JITTER', '100'))
+max_requests = int(env.get('MAX_REQUESTS', '0'))
+max_requests_jitter = int(env.get('MAX_REQUESTS_JITTER', '0'))
 
 # Connection timeouts
 #  - Defaults to double what the poll length for services should be
 graceful_timeout = int(env.get('GRACEFUL_TIMEOUT', '60'))
 timeout = int(env.get('TIMEOUT', '60'))
 
 # TLS/SSL Configuration
```

## assemblyline_v4_service/updater/updater.py

```diff
@@ -8,15 +8,14 @@
 import json
 import tempfile
 import string
 import random
 import tarfile
 import threading
 import subprocess
-from http.server import BaseHTTPRequestHandler, ThreadingHTTPServer
 from contextlib import contextmanager
 from passlib.hash import bcrypt
 from zipfile import ZipFile, BadZipFile
 
 from assemblyline.common import forge, log as al_log
 from assemblyline.common.isotime import epoch_to_iso, now_as_iso
 from assemblyline.common.identify import zip_ident
@@ -48,15 +47,16 @@
 SOURCE_UPDATE_TIME_KEY = 'update_time'
 LOCAL_UPDATE_TIME_KEY = 'local_update_time'
 SOURCE_EXTRA_KEY = 'source_extra'
 SOURCE_STATUS_KEY = 'status'
 UI_SERVER = os.getenv('UI_SERVER', 'https://nginx')
 UI_SERVER_ROOT_CA = os.environ.get('UI_SERVER_ROOT_CA', '/etc/assemblyline/ssl/al_root-ca.crt')
 UPDATER_DIR = os.getenv('UPDATER_DIR', os.path.join(tempfile.gettempdir(), 'updater'))
-UPDATER_API_ROLES = ['signature_import', 'signature_download', 'signature_view', 'safelist_manage', 'apikey_access']
+UPDATER_API_ROLES = ['signature_import', 'signature_download', 'signature_view', 'safelist_manage', 'apikey_access', 'signature_manage']
+STATUS_FILE = '/tmp/status'
 
 classification = forge.get_classification()
 
 
 @contextmanager
 def temporary_api_key(ds: AssemblylineDatastore, user_name: str, permissions=('R', 'W')):
     """Creates a context where a temporary API key is available."""
@@ -123,19 +123,17 @@
         self.source_update_flag = threading.Event()
         self.local_update_flag = threading.Event()
         self.local_update_start = threading.Event()
 
         self._current_source: str = None
 
         # Load threads
-        self._internal_server = None
         self.expected_threads = {
             'Sync Service Settings': self._sync_settings,
             'Outward HTTP Server': self._run_http,
-            'Internal HTTP Server': self._run_internal_http,
             'Run source updates': self._run_source_updates,
             'Run local updates': self._run_local_updates,
         }
         # Only used by updater with 'generates_signatures: false'
         self.latest_updates_dir = os.path.join(UPDATER_DIR, 'latest_updates')
         if not os.path.exists(self.latest_updates_dir):
             os.makedirs(self.latest_updates_dir)
@@ -193,47 +191,21 @@
         super().stop()
         self.signature_change_watcher.stop()
         self.service_change_watcher.stop()
         self.source_update_watcher.stop()
         self.source_update_flag.set()
         self.local_update_flag.set()
         self.local_update_start.set()
-        if self._internal_server:
-            self._internal_server.shutdown()
 
     def try_run(self):
         self.signature_change_watcher.start()
         self.service_change_watcher.start()
         self.source_update_watcher.start()
         self.maintain_threads(self.expected_threads)
 
-    def _run_internal_http(self):
-        """run backend insecure http server
-
-        A small inprocess server to syncronize info between gunicorn and the updater daemon.
-        This HTTP server is not safe for exposing externally, but fine for IPC.
-        """
-        them = self
-
-        class Handler(BaseHTTPRequestHandler):
-            def do_GET(self):
-                self.send_response(200)
-                self.send_header("Content-type", "application/json")
-                self.end_headers()
-                self.wfile.write(json.dumps(them.status()).encode())
-
-            def log_error(self, format: str, *args: Any):
-                them.log.info(format % args)
-
-            def log_message(self, format: str, *args: Any):
-                them.log.debug(format % args)
-
-        self._internal_server = ThreadingHTTPServer(('0.0.0.0', 9999), Handler)
-        self._internal_server.serve_forever()
-
     def _run_http(self):
         # Start a server for our http interface in a separate process
         my_env = os.environ.copy()
         proc = subprocess.Popen(["gunicorn", "assemblyline_v4_service.updater.app:app",
                                 "--config=python:assemblyline_v4_service.updater.gunicorn_config"], env=my_env)
         while self.sleep(1):
             if proc.poll() is not None:
@@ -246,25 +218,28 @@
 
     @staticmethod
     def config_hash(service: Service) -> int:
         if service is None:
             return 0
         return hash(json.dumps(service.update_config.as_primitives()))
 
-    def _handle_source_update_event(self, data: list[str]):
-        # Received an event regarding a change to source
-        self.log.info(f'Triggered to update the following: {data}')
-        self.do_source_update(self._service, specific_sources=data)
-        self.local_update_flag.set()
+    def _handle_source_update_event(self, data: Optional[list[str]]):
+        if data is not None:
+            # Received an event regarding a change to source
+            self.log.info(f'Triggered to update the following: {data}')
+            self.do_source_update(self._service, specific_sources=data)
+            self.local_update_flag.set()
+        else:
+            self.source_update_flag.set()
 
-    def _handle_signature_change_event(self, data: SignatureChange):
+    def _handle_signature_change_event(self, data: Optional[SignatureChange]):
         self.local_update_flag.set()
 
-    def _handle_service_change_event(self, data: ServiceChange):
-        if data.operation == Operation.Modified:
+    def _handle_service_change_event(self, data: Optional[ServiceChange]):
+        if data is None or data.operation == Operation.Modified:
             self._pull_settings()
 
     def _sync_settings(self):
         # Download the service object from datastore
         self._service = self.datastore.get_service_with_delta(SERVICE_NAME)
 
         while self.sleep(SERVICE_PULL_INTERVAL):
@@ -429,23 +404,29 @@
                     source = source_obj.as_primitives()
                     uri: str = source['uri']
                     default_classification = source.get('default_classification', classification.UNRESTRICTED)
                     try:
                         self.push_status("UPDATING", "Pulling..")
                         output = None
                         if uri in seen_fetches:
+                            if seen_fetches[uri] == 'skipped':
+                                # Skip source if another source says nothing has changed
+                                raise SkipSource
+
                             # We've already fetched something from the same URI, re-use downloaded path
                             self.log.info(f'Already visited {uri} in this run. Using cached download path..')
                             output = seen_fetches[uri]
                         else:
                             # Pull sources from external locations (method depends on the URL)
                             try:
                                 # First we'll attempt by performing a Git clone
                                 # (since not all services hint at being a repository in their URL),
                                 output = git_clone_repo(source, old_update_time, self.log, update_dir)
+                            except SkipSource:
+                                raise
                             except Exception as git_ex:
                                 # Should that fail, we'll attempt a direct-download using Python Requests
                                 if not uri.endswith('.git'):
                                     # Proceed with direct download, raise exception as required if necessary
                                     output = url_download(source, old_update_time, self.log, update_dir)
                                 else:
                                     # Raise Git Exception
@@ -470,14 +451,15 @@
                         self.push_status("DONE", "Signature(s) Imported.")
 
                     except SkipSource:
                         # This source hasn't changed, no need to re-import into Assemblyline
                         self.log.info(f'No new {self.updater_type} rule files to process for {source_name}')
                         if source_name in previous_hashes:
                             files_sha256[source_name] = previous_hashes[source_name]
+                        seen_fetches[uri] = "skipped"
                         self.push_status("DONE", "Skipped.")
                     except Exception as e:
                         # There was an issue with this source, report and continue to the next
                         self.log.error(f"Problem with {source['name']}: {e}")
                         self.push_status("ERROR", str(e))
                         continue
 
@@ -556,14 +538,20 @@
             tar_handle.add(new_directory, '/')
             tar_handle.close()
 
             # swap update directory with old one
             self._update_dir, new_directory = new_directory, self._update_dir
             self._update_tar, new_tar = new_tar, self._update_tar
             self._time_keeper, new_time = new_time, self._time_keeper
+
+            # Write the new status file
+            temp_status = tempfile.NamedTemporaryFile('w+', delete=False, dir='/tmp')
+            json.dump(self.status(), temp_status.file)
+            os.rename(temp_status.name, STATUS_FILE)
+
             self.log.info(f"Now serving: {self._update_dir} and {self._update_tar} ({self.get_local_update_time()})")
         finally:
             if new_tar and os.path.exists(new_tar):
                 self.log.info(f"Remove old tar file: {new_tar}")
                 time.sleep(3)
                 os.unlink(new_tar)
             if new_directory and os.path.exists(new_directory):
@@ -612,16 +600,16 @@
                 continue
 
     def ensure_service_account(self):
         """Check that the update service account exists, if it doesn't, create it."""
         uname = 'update_service_account'
         user_data = self.datastore.user.get_if_exists(uname)
         if user_data:
-            if user_data.roles:
-                # User exists and has roles, we're good to go
+            if user_data.roles and user_data.roles == UPDATER_API_ROLES:
+                # User exists and has the expected roles, we're good to go
                 return uname
 
             # User exist but has no roles, let's update the user's roles
             user_data.type = ["custom"]
             user_data.roles = UPDATER_API_ROLES
         else:
             # User does not exist, let's create the user
```

## Comparing `assemblyline_v4_service-4.4.1.dev9.dist-info/LICENCE.md` & `assemblyline_v4_service-4.4.1.dev94.dist-info/LICENCE.md`

 * *Files identical despite different names*

## Comparing `assemblyline_v4_service-4.4.1.dev9.dist-info/METADATA` & `assemblyline_v4_service-4.4.1.dev94.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: assemblyline-v4-service
-Version: 4.4.1.dev9
+Version: 4.4.1.dev94
 Summary: Assemblyline 4 - Service base
 Home-page: https://github.com/CybercentreCanada/assemblyline-v4-service/
 Author: CCCS Assemblyline development team
 Author-email: assemblyline@cyber.gc.ca
 License: MIT
 Keywords: assemblyline automated malware analysis gc canada cse-cst cse cst cyber cccs
 Platform: UNKNOWN
```

## Comparing `assemblyline_v4_service-4.4.1.dev9.dist-info/RECORD` & `assemblyline_v4_service-4.4.1.dev94.dist-info/RECORD`

 * *Files 8% similar despite different names*

```diff
@@ -1,54 +1,54 @@
-assemblyline_v4_service/VERSION,sha256=1UhXp18ZRh5JSiN7TVBqo6jxxtexk5UMttX1_Gg3vUY,11
+assemblyline_v4_service/VERSION,sha256=7tRb9rStMAW8ZkRmU6rM5MLIq9c0Eny9iFmIk9A0S0M,12
 assemblyline_v4_service/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-assemblyline_v4_service/healthz.py,sha256=3QGBg0EZuXC6UN411HFwpLNEop9UvS9feFhvBUTP-k4,1576
+assemblyline_v4_service/healthz.py,sha256=sS1cFkDLw8hUPMpj7tbHXFv8ZmHcazrwZ0l6oQDwwkQ,1575
 assemblyline_v4_service/run_privileged_service.py,sha256=9uTfHetXR5G-EDKMDrgfWUOw34yr64-cj6Cm9eZaCbQ,14547
 assemblyline_v4_service/run_service.py,sha256=RCqxdm-OAwJhl15BnKFkuavpQ5k6eTX3ZGeSna5JJBw,5557
 assemblyline_v4_service/common/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 assemblyline_v4_service/common/api.py,sha256=U908p3wlW9fEydx77GgI2E-6wW6T8Nc3R91nNOKU0H0,4453
-assemblyline_v4_service/common/base.py,sha256=3wjhmd-NltaRpMMF9Sh3BWJJCfPsw-JK-34Fc1Vn-5k,12655
-assemblyline_v4_service/common/dynamic_service_helper.py,sha256=ak3ehxGqejnaZQ67P6Nd4L2o2Fp9B9B3SYxHK8cEqf0,136992
+assemblyline_v4_service/common/base.py,sha256=STzfZ9dwqvbgbKiFs-aLk05pdhyK6Psz4hZ3_fOmQYM,13039
+assemblyline_v4_service/common/dynamic_service_helper.py,sha256=OhxSnSOjUB_iSkMahHbPQEll9sl5wLuCFwwykvV-Kno,147461
 assemblyline_v4_service/common/helper.py,sha256=Fgimk8DhnS23aijTGewA1HwvPoAM61UUbHlrGBnSzL0,3290
 assemblyline_v4_service/common/icap.py,sha256=phT3CT5uII3Qm90Nzi4O-eDkQ2jmr3zHcVVra4sqYSc,5376
 assemblyline_v4_service/common/keytool_parse.py,sha256=e829hrNNG5LFw1kjLsYVZsafCm2S3NpgM6jBc6JKawY,2219
-assemblyline_v4_service/common/ontology_helper.py,sha256=HJdFvZCP6OPNGySjjmXa-fLqTwaa9V-lnhCSv-isztQ,7768
-assemblyline_v4_service/common/request.py,sha256=JB3BfXYtgAPRlA-9O_YuQw2PCj_jEZuCyweY4RZrlqU,9226
-assemblyline_v4_service/common/result.py,sha256=TivKKDgh-6xhGbyBTAcjU8HFVRyXzTI19vFMa9PA3AQ,28908
+assemblyline_v4_service/common/ontology_helper.py,sha256=uiwc5cfPDAesEDYKk7etzCMTGQNVwhNrO3mWLdB2520,7793
+assemblyline_v4_service/common/request.py,sha256=p8A9boDZ6KuVxl3EdhvaU1D_5K6_gAVoIbJYDz8TzjA,9711
+assemblyline_v4_service/common/result.py,sha256=9OGfWTCnBtow31Ft03us9Ew_2pXyDydUTP4iio9Qg8Q,30349
 assemblyline_v4_service/common/safelist_helper.py,sha256=QHTuG8q52o3U307AADPgrIgug7aYFK2uQE4-EtWG3yQ,3037
 assemblyline_v4_service/common/section_reducer.py,sha256=JJOT7eFfBn4hFJKHY9UeVEbHS-E8FpmQ_dPZC-dWla0,1513
 assemblyline_v4_service/common/tag_helper.py,sha256=om3TVPY_XDeFDqVW2iUA349xbljSAy5tv667jCiA7JI,4186
 assemblyline_v4_service/common/tag_reducer.py,sha256=T6_l6T7EQKX1pYvTZ7swO90SifUPwwEfPWNUO-IZjjk,11102
 assemblyline_v4_service/common/task.py,sha256=PiYJdL2Qd2dKzwJ_FzWv6PBMvq-gHiVZq05ZQCjtREA,12480
-assemblyline_v4_service/common/utils.py,sha256=oB2Pg8n1DQXWn391TeLXokFKQ8sr-b5Fm2uXSav6bAU,2275
+assemblyline_v4_service/common/utils.py,sha256=K0UNJ3cugDHoqAgt6zvJ3JYEAiyT1XM2efd7XTNRPK8,2338
 assemblyline_v4_service/common/balbuzard/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 assemblyline_v4_service/common/balbuzard/balbuzard.py,sha256=JnIs3vkfp6uQGtxGL9mklM0TG4kP3jaRw2RE5pgrBzo,25161
 assemblyline_v4_service/common/balbuzard/bbcrack.py,sha256=6v2xe_VI5C3E9Ga8rD-FAxMKok7T-UZkjuxYfo9KQHw,29180
 assemblyline_v4_service/common/balbuzard/patterns.py,sha256=NYi38A_EADKA3fRFkx1u8K5WqPoW709d2LvomHJerkg,34120
 assemblyline_v4_service/common/extractor/__init__.py,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
 assemblyline_v4_service/common/extractor/base64.py,sha256=02e8r1jFDw_S1lCCdopUVEMbwGdxS-y9eHQNYmDkP9E,2025
 assemblyline_v4_service/common/extractor/decode_wrapper.py,sha256=eZSM2zBSzbGotuM04tKtV-R7oY5xuUTZ-rTfL6ktmns,3617
-assemblyline_v4_service/common/extractor/ocr.py,sha256=LuUu960yj4IUNClr1bbsEWvvfataSBbWuWL5NgTvmRs,4266
+assemblyline_v4_service/common/extractor/ocr.py,sha256=Pm47dRlMu66kwuPd6WQO5UPziMusJt8pPSq8Sj4YxiA,4385
 assemblyline_v4_service/common/extractor/pe_file.py,sha256=_SB3yoSuRwt-u5tz2E1GcbghknuNSJ-EkdVjlO8RXfA,451
 assemblyline_v4_service/common/pestudio/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 assemblyline_v4_service/common/pestudio/xml/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 assemblyline_v4_service/common/pestudio/xml/features.xml,sha256=q883UJxIq20mk88pxYnv2nKeG5dFiq-mhYH7D45i9lE,196476
 assemblyline_v4_service/common/pestudio/xml/functions.xml,sha256=QnbWwvvKeugnIU4XFYh8jeuP-eGl_h4z5KKihvpnCNU,350312
 assemblyline_v4_service/common/pestudio/xml/languages.xml,sha256=NLWwcGIVTWOQh7vvzP5yYPAstJJMsRXzNAv54Kly42M,20008
 assemblyline_v4_service/common/pestudio/xml/resources.xml,sha256=bYP-AVbq_Dlhgj_gNC2o0LSqc0AdlJHxJ8-G8Ih0MIc,40129
 assemblyline_v4_service/common/pestudio/xml/signatures.xml,sha256=r5FLFgmWejRdqPdoPQCFTt31Tllc64o81geaN1SbwS4,1255658
 assemblyline_v4_service/common/pestudio/xml/strings.xml,sha256=kRU8WbCcU1RckM6oCFeUVMdpOxZjJDDTMIIor8k2ru0,102459
 assemblyline_v4_service/dev/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-assemblyline_v4_service/dev/run_service_once.py,sha256=4gnb09WeKXlyWQKCQdH4SoL4xtfIRWq_9nyIiECrJ7g,10592
+assemblyline_v4_service/dev/run_service_once.py,sha256=D-QpwRox1dy9H6EPoR6nY1o3XiD3JRjC7xrEkPn952I,10593
 assemblyline_v4_service/testing/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 assemblyline_v4_service/testing/helper.py,sha256=f0-qBtgR0vWZBpEV9sPfcworLtdh4h_CcoAofHlOtZE,19711
 assemblyline_v4_service/testing/regenerate_results.py,sha256=Cbp2CMAxbF3kz5vxEPPCxrgUp1Vl3Tz6e46aUhg_I4U,1101
 assemblyline_v4_service/updater/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 assemblyline_v4_service/updater/__main__.py,sha256=9Os-u8Tf7MD73JSrUSPmOaErTgfvesNLiEeszU4ujXA,133
-assemblyline_v4_service/updater/app.py,sha256=IB9UrfUesu88ixC_VKk8IbEVvhYFI7c7gla_IfS_g2g,2780
-assemblyline_v4_service/updater/gunicorn_config.py,sha256=8Qulsnw9pcsol4x_3oeyRkvovFEe0nEJQnPPemuOl-I,1155
+assemblyline_v4_service/updater/app.py,sha256=Ass5DZtOCr0tdoRbLo7Qn8Ujlw8T8mUDroAaHxx2oMo,3198
+assemblyline_v4_service/updater/gunicorn_config.py,sha256=p3j2KPBeD5jvMw9O5i7vAtlRgPSVVxIG9AO0DfN82J8,1247
 assemblyline_v4_service/updater/helper.py,sha256=JD0gX3KHY-wvsFjTbWkT83F0d5Up3OfubMPinuNzbTQ,9069
-assemblyline_v4_service/updater/updater.py,sha256=9etDHj72mCZ8X1OLq8TP6rht24AVF9Z2-kDC0HVjo7E,29655
-assemblyline_v4_service-4.4.1.dev9.dist-info/LICENCE.md,sha256=NSkYo9EH8h5oOkzg4VhjAHF4339MqPP2cQ8msTPgl-c,1396
-assemblyline_v4_service-4.4.1.dev9.dist-info/METADATA,sha256=sySSC5StKrWr8dzUh9pSORGY5O_i3EnsHXenLEN2LaQ,9358
-assemblyline_v4_service-4.4.1.dev9.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-assemblyline_v4_service-4.4.1.dev9.dist-info/top_level.txt,sha256=Ut5IqePObcxlJ8rv2--dOAzYbxzqlllfiV_51cbqjbA,24
-assemblyline_v4_service-4.4.1.dev9.dist-info/RECORD,,
+assemblyline_v4_service/updater/updater.py,sha256=AQ3aTm5nhb-RXWjm5w1RIZM3j3UQJ4Vr4bVJ6Z2rX8A,29322
+assemblyline_v4_service-4.4.1.dev94.dist-info/LICENCE.md,sha256=NSkYo9EH8h5oOkzg4VhjAHF4339MqPP2cQ8msTPgl-c,1396
+assemblyline_v4_service-4.4.1.dev94.dist-info/METADATA,sha256=E2nt_9-pxjNJqgBPDOI_nAJrKK8dk-6yKJaLwgOmDh0,9359
+assemblyline_v4_service-4.4.1.dev94.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+assemblyline_v4_service-4.4.1.dev94.dist-info/top_level.txt,sha256=Ut5IqePObcxlJ8rv2--dOAzYbxzqlllfiV_51cbqjbA,24
+assemblyline_v4_service-4.4.1.dev94.dist-info/RECORD,,
```

