# Comparing `tmp/orquestra_sdk-0.48.0-py3-none-any.whl.zip` & `tmp/orquestra_sdk-0.49.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,113 +1,115 @@
-Zip file size: 207202 bytes, number of entries: 111
--rw-r--r--  2.0 unx     1494 b- defN 23-May-15 18:03 orquestra/sdk/__init__.py
--rw-r--r--  2.0 unx     6076 b- defN 23-May-15 18:03 orquestra/sdk/exceptions.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-15 18:03 orquestra/sdk/py.typed
--rw-r--r--  2.0 unx      204 b- defN 23-May-15 18:03 orquestra/sdk/_base/__init__.py
--rw-r--r--  2.0 unx     8563 b- defN 23-May-15 18:03 orquestra/sdk/_base/_ast.py
--rw-r--r--  2.0 unx    24929 b- defN 23-May-15 18:03 orquestra/sdk/_base/_config.py
--rw-r--r--  2.0 unx    36433 b- defN 23-May-15 18:03 orquestra/sdk/_base/_dsl.py
--rw-r--r--  2.0 unx     1999 b- defN 23-May-15 18:03 orquestra/sdk/_base/_env.py
--rw-r--r--  2.0 unx     2338 b- defN 23-May-15 18:03 orquestra/sdk/_base/_exec_ctx.py
--rw-r--r--  2.0 unx     1776 b- defN 23-May-15 18:03 orquestra/sdk/_base/_factory.py
--rw-r--r--  2.0 unx     3638 b- defN 23-May-15 18:03 orquestra/sdk/_base/_git_url_utils.py
--rw-r--r--  2.0 unx     3021 b- defN 23-May-15 18:03 orquestra/sdk/_base/_graphs.py
--rw-r--r--  2.0 unx    11135 b- defN 23-May-15 18:03 orquestra/sdk/_base/_in_process_runtime.py
--rw-r--r--  2.0 unx     6476 b- defN 23-May-15 18:03 orquestra/sdk/_base/_log_adapter.py
--rw-r--r--  2.0 unx     1407 b- defN 23-May-15 18:03 orquestra/sdk/_base/_retry.py
--rw-r--r--  2.0 unx     4331 b- defN 23-May-15 18:03 orquestra/sdk/_base/_services.py
--rw-r--r--  2.0 unx    32145 b- defN 23-May-15 18:03 orquestra/sdk/_base/_traversal.py
--rw-r--r--  2.0 unx     4629 b- defN 23-May-15 18:03 orquestra/sdk/_base/_viz.py
--rw-r--r--  2.0 unx    26166 b- defN 23-May-15 18:03 orquestra/sdk/_base/_workflow.py
--rw-r--r--  2.0 unx     8817 b- defN 23-May-15 18:03 orquestra/sdk/_base/abc.py
--rw-r--r--  2.0 unx    11810 b- defN 23-May-15 18:03 orquestra/sdk/_base/dispatch.py
--rw-r--r--  2.0 unx     6001 b- defN 23-May-15 18:03 orquestra/sdk/_base/loader.py
--rw-r--r--  2.0 unx     7004 b- defN 23-May-15 18:03 orquestra/sdk/_base/serde.py
--rw-r--r--  2.0 unx      624 b- defN 23-May-15 18:03 orquestra/sdk/_base/_api/__init__.py
--rw-r--r--  2.0 unx    18506 b- defN 23-May-15 18:03 orquestra/sdk/_base/_api/_config.py
--rw-r--r--  2.0 unx     9505 b- defN 23-May-15 18:03 orquestra/sdk/_base/_api/_task_run.py
--rw-r--r--  2.0 unx    21243 b- defN 23-May-15 18:03 orquestra/sdk/_base/_api/_wf_run.py
--rw-r--r--  2.0 unx      204 b- defN 23-May-15 18:03 orquestra/sdk/_base/_conversions/__init__.py
--rw-r--r--  2.0 unx     3509 b- defN 23-May-15 18:03 orquestra/sdk/_base/_conversions/_ids.py
--rw-r--r--  2.0 unx     7074 b- defN 23-May-15 18:03 orquestra/sdk/_base/_conversions/_imports.py
--rw-r--r--  2.0 unx    12943 b- defN 23-May-15 18:03 orquestra/sdk/_base/_conversions/_invocations.py
--rw-r--r--  2.0 unx     3905 b- defN 23-May-15 18:03 orquestra/sdk/_base/_conversions/_yaml_exporter.py
--rw-r--r--  2.0 unx      360 b- defN 23-May-15 18:03 orquestra/sdk/_base/_db/__init__.py
--rw-r--r--  2.0 unx     5107 b- defN 23-May-15 18:03 orquestra/sdk/_base/_db/_db.py
--rw-r--r--  2.0 unx      894 b- defN 23-May-15 18:03 orquestra/sdk/_base/_db/_migration.py
--rw-r--r--  2.0 unx      204 b- defN 23-May-15 18:03 orquestra/sdk/_base/_driver/__init__.py
--rw-r--r--  2.0 unx    19734 b- defN 23-May-15 18:03 orquestra/sdk/_base/_driver/_ce_runtime.py
--rw-r--r--  2.0 unx    24868 b- defN 23-May-15 18:03 orquestra/sdk/_base/_driver/_client.py
--rw-r--r--  2.0 unx     4748 b- defN 23-May-15 18:03 orquestra/sdk/_base/_driver/_exceptions.py
--rw-r--r--  2.0 unx     9208 b- defN 23-May-15 18:03 orquestra/sdk/_base/_driver/_models.py
--rw-r--r--  2.0 unx      204 b- defN 23-May-15 18:03 orquestra/sdk/_base/_qe/__init__.py
--rw-r--r--  2.0 unx     7212 b- defN 23-May-15 18:03 orquestra/sdk/_base/_qe/_client.py
--rw-r--r--  2.0 unx    34116 b- defN 23-May-15 18:03 orquestra/sdk/_base/_qe/_qe_runtime.py
--rw-r--r--  2.0 unx      204 b- defN 23-May-15 18:03 orquestra/sdk/_base/_spaces/__init__.py
--rw-r--r--  2.0 unx     1734 b- defN 23-May-15 18:03 orquestra/sdk/_base/_spaces/_api.py
--rw-r--r--  2.0 unx      704 b- defN 23-May-15 18:03 orquestra/sdk/_base/_spaces/_structs.py
--rw-r--r--  2.0 unx      204 b- defN 23-May-15 18:03 orquestra/sdk/_base/_testing/__init__.py
--rw-r--r--  2.0 unx     4031 b- defN 23-May-15 18:03 orquestra/sdk/_base/_testing/_connections.py
--rw-r--r--  2.0 unx     6800 b- defN 23-May-15 18:03 orquestra/sdk/_base/_testing/_example_wfs.py
--rw-r--r--  2.0 unx     1754 b- defN 23-May-15 18:03 orquestra/sdk/_base/_testing/_ipc.py
--rw-r--r--  2.0 unx      261 b- defN 23-May-15 18:03 orquestra/sdk/_base/_testing/_long_import.py
--rw-r--r--  2.0 unx    12293 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_arg_resolvers.py
--rw-r--r--  2.0 unx      698 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_cli_logs.py
--rw-r--r--  2.0 unx     3032 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_dumpers.py
--rw-r--r--  2.0 unx    10432 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_entry.py
--rw-r--r--  2.0 unx    21884 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_repos.py
--rw-r--r--  2.0 unx     3043 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_login/_login.py
--rw-r--r--  2.0 unx     1694 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_login/_login_server.py
--rw-r--r--  2.0 unx     1621 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_services/_down.py
--rw-r--r--  2.0 unx     1327 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_services/_status.py
--rw-r--r--  2.0 unx     2135 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_services/_up.py
--rw-r--r--  2.0 unx     3106 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_task/_logs.py
--rw-r--r--  2.0 unx     3626 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_task/_results.py
--rw-r--r--  2.0 unx      367 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_ui/__init__.py
--rw-r--r--  2.0 unx     4107 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_ui/_errors.py
--rw-r--r--  2.0 unx     1648 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_ui/_models.py
--rw-r--r--  2.0 unx    10300 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_ui/_presenters.py
--rw-r--r--  2.0 unx     9394 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_ui/_prompts.py
--rw-r--r--  2.0 unx      624 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/color.py
--rw-r--r--  2.0 unx     7794 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/per_command.py
--rw-r--r--  2.0 unx     3463 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_workflow/_list.py
--rw-r--r--  2.0 unx     2739 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_workflow/_logs.py
--rw-r--r--  2.0 unx     3140 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_workflow/_results.py
--rw-r--r--  2.0 unx     2507 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_workflow/_stop.py
--rw-r--r--  2.0 unx     4406 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_workflow/_submit.py
--rw-r--r--  2.0 unx     2138 b- defN 23-May-15 18:03 orquestra/sdk/_base/cli/_dorq/_workflow/_view.py
--rw-r--r--  2.0 unx      204 b- defN 23-May-15 18:03 orquestra/sdk/_ray/__init__.py
--rw-r--r--  2.0 unx    16431 b- defN 23-May-15 18:03 orquestra/sdk/_ray/_build_workflow.py
--rw-r--r--  2.0 unx     6612 b- defN 23-May-15 18:03 orquestra/sdk/_ray/_client.py
--rw-r--r--  2.0 unx    20571 b- defN 23-May-15 18:03 orquestra/sdk/_ray/_dag.py
--rw-r--r--  2.0 unx      867 b- defN 23-May-15 18:03 orquestra/sdk/_ray/_id_gen.py
--rw-r--r--  2.0 unx     4387 b- defN 23-May-15 18:03 orquestra/sdk/_ray/_ray_logs.py
--rw-r--r--  2.0 unx     1278 b- defN 23-May-15 18:03 orquestra/sdk/_ray/_wf_metadata.py
--rw-r--r--  2.0 unx      204 b- defN 23-May-15 18:03 orquestra/sdk/examples/__init__.py
--rw-r--r--  2.0 unx     1558 b- defN 23-May-15 18:03 orquestra/sdk/examples/exportable_wf.py
--rw-r--r--  2.0 unx     1116 b- defN 23-May-15 18:03 orquestra/sdk/examples/workflow_defs.py
--rw-r--r--  2.0 unx      318 b- defN 23-May-15 18:03 orquestra/sdk/kubernetes/__init__.py
--rw-r--r--  2.0 unx     2420 b- defN 23-May-15 18:03 orquestra/sdk/kubernetes/quantity.py
--rw-r--r--  2.0 unx      427 b- defN 23-May-15 18:03 orquestra/sdk/packaging/__init__.py
--rw-r--r--  2.0 unx     4144 b- defN 23-May-15 18:03 orquestra/sdk/packaging/_versions.py
--rw-r--r--  2.0 unx      204 b- defN 23-May-15 18:03 orquestra/sdk/schema/__init__.py
--rw-r--r--  2.0 unx     1874 b- defN 23-May-15 18:03 orquestra/sdk/schema/_compat.py
--rw-r--r--  2.0 unx     1474 b- defN 23-May-15 18:03 orquestra/sdk/schema/configs.py
--rw-r--r--  2.0 unx    14987 b- defN 23-May-15 18:03 orquestra/sdk/schema/ir.py
--rw-r--r--  2.0 unx      832 b- defN 23-May-15 18:03 orquestra/sdk/schema/local_database.py
--rw-r--r--  2.0 unx     4745 b- defN 23-May-15 18:03 orquestra/sdk/schema/responses.py
--rw-r--r--  2.0 unx     1478 b- defN 23-May-15 18:03 orquestra/sdk/schema/workflow_run.py
--rw-r--r--  2.0 unx     4114 b- defN 23-May-15 18:03 orquestra/sdk/schema/yaml_model.py
--rw-r--r--  2.0 unx     1104 b- defN 23-May-15 18:03 orquestra/sdk/secrets/__init__.py
--rw-r--r--  2.0 unx     5356 b- defN 23-May-15 18:03 orquestra/sdk/secrets/_api.py
--rw-r--r--  2.0 unx     2090 b- defN 23-May-15 18:03 orquestra/sdk/secrets/_auth.py
--rw-r--r--  2.0 unx     5243 b- defN 23-May-15 18:03 orquestra/sdk/secrets/_client.py
--rw-r--r--  2.0 unx     1222 b- defN 23-May-15 18:03 orquestra/sdk/secrets/_exceptions.py
--rw-r--r--  2.0 unx     1319 b- defN 23-May-15 18:03 orquestra/sdk/secrets/_models.py
--rw-r--r--  2.0 unx     1072 b- defN 23-May-15 18:03 orquestra/sdk/v2/__init__.py
--rw-r--r--  2.0 unx    11357 b- defN 23-May-15 18:03 orquestra_sdk-0.48.0.dist-info/LICENSE
--rw-r--r--  2.0 unx     3089 b- defN 23-May-15 18:03 orquestra_sdk-0.48.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-May-15 18:03 orquestra_sdk-0.48.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       67 b- defN 23-May-15 18:03 orquestra_sdk-0.48.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       10 b- defN 23-May-15 18:03 orquestra_sdk-0.48.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    10421 b- defN 23-May-15 18:03 orquestra_sdk-0.48.0.dist-info/RECORD
-111 files, 660457 bytes uncompressed, 190428 bytes compressed:  71.2%
+Zip file size: 215166 bytes, number of entries: 113
+-rw-r--r--  2.0 unx     1538 b- defN 23-May-26 11:55 orquestra/sdk/__init__.py
+-rw-r--r--  2.0 unx     7183 b- defN 23-May-26 11:55 orquestra/sdk/exceptions.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 11:55 orquestra/sdk/py.typed
+-rw-r--r--  2.0 unx      204 b- defN 23-May-26 11:55 orquestra/sdk/_base/__init__.py
+-rw-r--r--  2.0 unx     8563 b- defN 23-May-26 11:55 orquestra/sdk/_base/_ast.py
+-rw-r--r--  2.0 unx    24929 b- defN 23-May-26 11:55 orquestra/sdk/_base/_config.py
+-rw-r--r--  2.0 unx    36681 b- defN 23-May-26 11:55 orquestra/sdk/_base/_dsl.py
+-rw-r--r--  2.0 unx     2461 b- defN 23-May-26 11:55 orquestra/sdk/_base/_env.py
+-rw-r--r--  2.0 unx     2465 b- defN 23-May-26 11:55 orquestra/sdk/_base/_exec_ctx.py
+-rw-r--r--  2.0 unx     1776 b- defN 23-May-26 11:55 orquestra/sdk/_base/_factory.py
+-rw-r--r--  2.0 unx     3638 b- defN 23-May-26 11:55 orquestra/sdk/_base/_git_url_utils.py
+-rw-r--r--  2.0 unx     3021 b- defN 23-May-26 11:55 orquestra/sdk/_base/_graphs.py
+-rw-r--r--  2.0 unx    12934 b- defN 23-May-26 11:55 orquestra/sdk/_base/_in_process_runtime.py
+-rw-r--r--  2.0 unx     1104 b- defN 23-May-26 11:55 orquestra/sdk/_base/_jwt.py
+-rw-r--r--  2.0 unx     5245 b- defN 23-May-26 11:55 orquestra/sdk/_base/_log_adapter.py
+-rw-r--r--  2.0 unx     1407 b- defN 23-May-26 11:55 orquestra/sdk/_base/_retry.py
+-rw-r--r--  2.0 unx     4180 b- defN 23-May-26 11:55 orquestra/sdk/_base/_services.py
+-rw-r--r--  2.0 unx    32145 b- defN 23-May-26 11:55 orquestra/sdk/_base/_traversal.py
+-rw-r--r--  2.0 unx     4629 b- defN 23-May-26 11:55 orquestra/sdk/_base/_viz.py
+-rw-r--r--  2.0 unx    24415 b- defN 23-May-26 11:55 orquestra/sdk/_base/_workflow.py
+-rw-r--r--  2.0 unx     9135 b- defN 23-May-26 11:55 orquestra/sdk/_base/abc.py
+-rw-r--r--  2.0 unx    11844 b- defN 23-May-26 11:55 orquestra/sdk/_base/dispatch.py
+-rw-r--r--  2.0 unx     6001 b- defN 23-May-26 11:55 orquestra/sdk/_base/loader.py
+-rw-r--r--  2.0 unx     7004 b- defN 23-May-26 11:55 orquestra/sdk/_base/serde.py
+-rw-r--r--  2.0 unx      664 b- defN 23-May-26 11:55 orquestra/sdk/_base/_api/__init__.py
+-rw-r--r--  2.0 unx    18506 b- defN 23-May-26 11:55 orquestra/sdk/_base/_api/_config.py
+-rw-r--r--  2.0 unx    13764 b- defN 23-May-26 11:55 orquestra/sdk/_base/_api/_task_run.py
+-rw-r--r--  2.0 unx    18923 b- defN 23-May-26 11:55 orquestra/sdk/_base/_api/_wf_run.py
+-rw-r--r--  2.0 unx      204 b- defN 23-May-26 11:55 orquestra/sdk/_base/_conversions/__init__.py
+-rw-r--r--  2.0 unx     3509 b- defN 23-May-26 11:55 orquestra/sdk/_base/_conversions/_ids.py
+-rw-r--r--  2.0 unx     7074 b- defN 23-May-26 11:55 orquestra/sdk/_base/_conversions/_imports.py
+-rw-r--r--  2.0 unx    12943 b- defN 23-May-26 11:55 orquestra/sdk/_base/_conversions/_invocations.py
+-rw-r--r--  2.0 unx     3905 b- defN 23-May-26 11:55 orquestra/sdk/_base/_conversions/_yaml_exporter.py
+-rw-r--r--  2.0 unx      360 b- defN 23-May-26 11:55 orquestra/sdk/_base/_db/__init__.py
+-rw-r--r--  2.0 unx     5107 b- defN 23-May-26 11:55 orquestra/sdk/_base/_db/_db.py
+-rw-r--r--  2.0 unx      894 b- defN 23-May-26 11:55 orquestra/sdk/_base/_db/_migration.py
+-rw-r--r--  2.0 unx      204 b- defN 23-May-26 11:55 orquestra/sdk/_base/_driver/__init__.py
+-rw-r--r--  2.0 unx    20258 b- defN 23-May-26 11:55 orquestra/sdk/_base/_driver/_ce_runtime.py
+-rw-r--r--  2.0 unx    25247 b- defN 23-May-26 11:55 orquestra/sdk/_base/_driver/_client.py
+-rw-r--r--  2.0 unx     4748 b- defN 23-May-26 11:55 orquestra/sdk/_base/_driver/_exceptions.py
+-rw-r--r--  2.0 unx     9314 b- defN 23-May-26 11:55 orquestra/sdk/_base/_driver/_models.py
+-rw-r--r--  2.0 unx      204 b- defN 23-May-26 11:55 orquestra/sdk/_base/_qe/__init__.py
+-rw-r--r--  2.0 unx     7212 b- defN 23-May-26 11:55 orquestra/sdk/_base/_qe/_client.py
+-rw-r--r--  2.0 unx    34726 b- defN 23-May-26 11:55 orquestra/sdk/_base/_qe/_qe_runtime.py
+-rw-r--r--  2.0 unx      204 b- defN 23-May-26 11:55 orquestra/sdk/_base/_spaces/__init__.py
+-rw-r--r--  2.0 unx     1734 b- defN 23-May-26 11:55 orquestra/sdk/_base/_spaces/_api.py
+-rw-r--r--  2.0 unx     1555 b- defN 23-May-26 11:55 orquestra/sdk/_base/_spaces/_resolver.py
+-rw-r--r--  2.0 unx      704 b- defN 23-May-26 11:55 orquestra/sdk/_base/_spaces/_structs.py
+-rw-r--r--  2.0 unx      204 b- defN 23-May-26 11:55 orquestra/sdk/_base/_testing/__init__.py
+-rw-r--r--  2.0 unx     4031 b- defN 23-May-26 11:55 orquestra/sdk/_base/_testing/_connections.py
+-rw-r--r--  2.0 unx     7793 b- defN 23-May-26 11:55 orquestra/sdk/_base/_testing/_example_wfs.py
+-rw-r--r--  2.0 unx     1754 b- defN 23-May-26 11:55 orquestra/sdk/_base/_testing/_ipc.py
+-rw-r--r--  2.0 unx      261 b- defN 23-May-26 11:55 orquestra/sdk/_base/_testing/_long_import.py
+-rw-r--r--  2.0 unx    16844 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_arg_resolvers.py
+-rw-r--r--  2.0 unx      698 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_cli_logs.py
+-rw-r--r--  2.0 unx     3032 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_dumpers.py
+-rw-r--r--  2.0 unx    10859 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_entry.py
+-rw-r--r--  2.0 unx    23124 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_repos.py
+-rw-r--r--  2.0 unx     5360 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_login/_login.py
+-rw-r--r--  2.0 unx     1694 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_login/_login_server.py
+-rw-r--r--  2.0 unx     1621 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_services/_down.py
+-rw-r--r--  2.0 unx     1327 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_services/_status.py
+-rw-r--r--  2.0 unx     2656 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_services/_up.py
+-rw-r--r--  2.0 unx     3106 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_task/_logs.py
+-rw-r--r--  2.0 unx     3626 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_task/_results.py
+-rw-r--r--  2.0 unx      367 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_ui/__init__.py
+-rw-r--r--  2.0 unx     5520 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_ui/_errors.py
+-rw-r--r--  2.0 unx     1648 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_ui/_models.py
+-rw-r--r--  2.0 unx    11287 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_ui/_presenters.py
+-rw-r--r--  2.0 unx    10249 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_ui/_prompts.py
+-rw-r--r--  2.0 unx      624 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/color.py
+-rw-r--r--  2.0 unx     7794 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/per_command.py
+-rw-r--r--  2.0 unx     5180 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_workflow/_list.py
+-rw-r--r--  2.0 unx     2739 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_workflow/_logs.py
+-rw-r--r--  2.0 unx     3140 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_workflow/_results.py
+-rw-r--r--  2.0 unx     2507 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_workflow/_stop.py
+-rw-r--r--  2.0 unx     4406 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_workflow/_submit.py
+-rw-r--r--  2.0 unx     2138 b- defN 23-May-26 11:55 orquestra/sdk/_base/cli/_dorq/_workflow/_view.py
+-rw-r--r--  2.0 unx      204 b- defN 23-May-26 11:55 orquestra/sdk/_ray/__init__.py
+-rw-r--r--  2.0 unx    18315 b- defN 23-May-26 11:55 orquestra/sdk/_ray/_build_workflow.py
+-rw-r--r--  2.0 unx     6808 b- defN 23-May-26 11:55 orquestra/sdk/_ray/_client.py
+-rw-r--r--  2.0 unx    21176 b- defN 23-May-26 11:55 orquestra/sdk/_ray/_dag.py
+-rw-r--r--  2.0 unx      867 b- defN 23-May-26 11:55 orquestra/sdk/_ray/_id_gen.py
+-rw-r--r--  2.0 unx     4387 b- defN 23-May-26 11:55 orquestra/sdk/_ray/_ray_logs.py
+-rw-r--r--  2.0 unx     1278 b- defN 23-May-26 11:55 orquestra/sdk/_ray/_wf_metadata.py
+-rw-r--r--  2.0 unx      204 b- defN 23-May-26 11:55 orquestra/sdk/examples/__init__.py
+-rw-r--r--  2.0 unx     1558 b- defN 23-May-26 11:55 orquestra/sdk/examples/exportable_wf.py
+-rw-r--r--  2.0 unx     1116 b- defN 23-May-26 11:55 orquestra/sdk/examples/workflow_defs.py
+-rw-r--r--  2.0 unx      318 b- defN 23-May-26 11:55 orquestra/sdk/kubernetes/__init__.py
+-rw-r--r--  2.0 unx     2420 b- defN 23-May-26 11:55 orquestra/sdk/kubernetes/quantity.py
+-rw-r--r--  2.0 unx      427 b- defN 23-May-26 11:55 orquestra/sdk/packaging/__init__.py
+-rw-r--r--  2.0 unx     4144 b- defN 23-May-26 11:55 orquestra/sdk/packaging/_versions.py
+-rw-r--r--  2.0 unx      204 b- defN 23-May-26 11:55 orquestra/sdk/schema/__init__.py
+-rw-r--r--  2.0 unx     1874 b- defN 23-May-26 11:55 orquestra/sdk/schema/_compat.py
+-rw-r--r--  2.0 unx     1474 b- defN 23-May-26 11:55 orquestra/sdk/schema/configs.py
+-rw-r--r--  2.0 unx    14987 b- defN 23-May-26 11:55 orquestra/sdk/schema/ir.py
+-rw-r--r--  2.0 unx      832 b- defN 23-May-26 11:55 orquestra/sdk/schema/local_database.py
+-rw-r--r--  2.0 unx     4745 b- defN 23-May-26 11:55 orquestra/sdk/schema/responses.py
+-rw-r--r--  2.0 unx     1478 b- defN 23-May-26 11:55 orquestra/sdk/schema/workflow_run.py
+-rw-r--r--  2.0 unx     4114 b- defN 23-May-26 11:55 orquestra/sdk/schema/yaml_model.py
+-rw-r--r--  2.0 unx     1104 b- defN 23-May-26 11:55 orquestra/sdk/secrets/__init__.py
+-rw-r--r--  2.0 unx     6596 b- defN 23-May-26 11:55 orquestra/sdk/secrets/_api.py
+-rw-r--r--  2.0 unx     2090 b- defN 23-May-26 11:55 orquestra/sdk/secrets/_auth.py
+-rw-r--r--  2.0 unx     5600 b- defN 23-May-26 11:55 orquestra/sdk/secrets/_client.py
+-rw-r--r--  2.0 unx     1222 b- defN 23-May-26 11:55 orquestra/sdk/secrets/_exceptions.py
+-rw-r--r--  2.0 unx     1679 b- defN 23-May-26 11:55 orquestra/sdk/secrets/_models.py
+-rw-r--r--  2.0 unx     1072 b- defN 23-May-26 11:55 orquestra/sdk/v2/__init__.py
+-rw-r--r--  2.0 unx    11357 b- defN 23-May-26 11:55 orquestra_sdk-0.49.1.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3127 b- defN 23-May-26 11:55 orquestra_sdk-0.49.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-26 11:55 orquestra_sdk-0.49.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       67 b- defN 23-May-26 11:55 orquestra_sdk-0.49.1.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       10 b- defN 23-May-26 11:55 orquestra_sdk-0.49.1.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    10604 b- defN 23-May-26 11:55 orquestra_sdk-0.49.1.dist-info/RECORD
+113 files, 687604 bytes uncompressed, 198106 bytes compressed:  71.2%
```

## zipnote {}

```diff
@@ -33,14 +33,17 @@
 
 Filename: orquestra/sdk/_base/_graphs.py
 Comment: 
 
 Filename: orquestra/sdk/_base/_in_process_runtime.py
 Comment: 
 
+Filename: orquestra/sdk/_base/_jwt.py
+Comment: 
+
 Filename: orquestra/sdk/_base/_log_adapter.py
 Comment: 
 
 Filename: orquestra/sdk/_base/_retry.py
 Comment: 
 
 Filename: orquestra/sdk/_base/_services.py
@@ -129,14 +132,17 @@
 
 Filename: orquestra/sdk/_base/_spaces/__init__.py
 Comment: 
 
 Filename: orquestra/sdk/_base/_spaces/_api.py
 Comment: 
 
+Filename: orquestra/sdk/_base/_spaces/_resolver.py
+Comment: 
+
 Filename: orquestra/sdk/_base/_spaces/_structs.py
 Comment: 
 
 Filename: orquestra/sdk/_base/_testing/__init__.py
 Comment: 
 
 Filename: orquestra/sdk/_base/_testing/_connections.py
@@ -309,26 +315,26 @@
 
 Filename: orquestra/sdk/secrets/_models.py
 Comment: 
 
 Filename: orquestra/sdk/v2/__init__.py
 Comment: 
 
-Filename: orquestra_sdk-0.48.0.dist-info/LICENSE
+Filename: orquestra_sdk-0.49.1.dist-info/LICENSE
 Comment: 
 
-Filename: orquestra_sdk-0.48.0.dist-info/METADATA
+Filename: orquestra_sdk-0.49.1.dist-info/METADATA
 Comment: 
 
-Filename: orquestra_sdk-0.48.0.dist-info/WHEEL
+Filename: orquestra_sdk-0.49.1.dist-info/WHEEL
 Comment: 
 
-Filename: orquestra_sdk-0.48.0.dist-info/entry_points.txt
+Filename: orquestra_sdk-0.49.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: orquestra_sdk-0.48.0.dist-info/top_level.txt
+Filename: orquestra_sdk-0.49.1.dist-info/top_level.txt
 Comment: 
 
-Filename: orquestra_sdk-0.48.0.dist-info/RECORD
+Filename: orquestra_sdk-0.49.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## orquestra/sdk/__init__.py

```diff
@@ -4,14 +4,15 @@
 """Orquestra SDK allows to define computational workflows using Python DSL."""
 
 from . import secrets
 from ._base._api import (
     RuntimeConfig,
     TaskRun,
     WorkflowRun,
+    current_run_ids,
     list_workflow_runs,
     migrate_config_file,
 )
 from ._base._dsl import (
     ArtifactFuture,
     DataAggregation,
     GithubImport,
@@ -29,14 +30,15 @@
 from ._base._spaces._api import list_projects, list_workspaces
 from ._base._spaces._structs import Project, ProjectRef, Workspace
 from ._base._workflow import NotATaskWarning, WorkflowDef, WorkflowTemplate, workflow
 
 __all__ = [
     "ArtifactFuture",
     "DataAggregation",
+    "current_run_ids",
     "GithubImport",
     "GitImport",
     "Import",
     "InlineImport",
     "LocalImport",
     "NotATaskWarning",
     "PythonImports",
```

## orquestra/sdk/exceptions.py

```diff
@@ -69,14 +69,20 @@
 
 class UnsavedConfigChangesError(BaseRuntimeError):
     """Raised when there are unsaved clashing changes to the token."""
 
     pass
 
 
+class LocalConfigLoginError(BaseRuntimeError):
+    """Raised when trying to log in using a config that relates to local execution."""
+
+    pass
+
+
 # Workflow Definition Errors
 class WorkflowDefinitionModuleNotFound(NotFoundError):
     """
     Raised when loading workflow definitions module failed.
     """
 
     def __init__(self, module_name: str, sys_path: t.Sequence[str]):
@@ -200,42 +206,74 @@
 
 class WorkflowResultsNotReadyError(NotFoundError):
     """
     Raised when a workflow has succeeded, but the results are not ready yet
     """
 
 
+class WorkflowRunIDNotFoundError(NotFoundError):
+    """Raised when we can't recover the ID for this Workflow Run."""
+
+    # Note that this is different to the WorkflowRunNotFoundError.
+    # We have an ID but can't find the workflow: WorkflowRunNotFoundError
+    # We have a workflow but can't recover the ID: WorkflowRunIDNotFoundError
+
+
 # Auth Errors
 class UnauthorizedError(BaseRuntimeError):
     """Raised when the remote cluster rejects the auth token."""
 
     pass
 
 
+class ExpiredTokenError(BaseRuntimeError):
+    """Raised when the auth token is expired"""
+
+    pass
+
+
+class InvalidTokenError(BaseRuntimeError):
+    """Raised when an auth token is not a JWT"""
+
+    pass
+
+
 # Ray Errors
 class RayActorNameClashError(BaseRuntimeError):
     """Raised when multiple Ray actors exist with the same name."""
 
     pass
 
 
+class RayNotRunningError(ConnectionError):
+    """Raised when there isn't a running ray instance."""
+
+    pass
+
+
 # CLI Exceptions
 class UserCancelledPrompt(BaseRuntimeError):
     """Raised when the user cancels a CLI prompt."""
 
     pass
 
 
 class LoginURLUnavailableError(BaseRuntimeError):
     """Raised when the login URL for is unavailable."""
 
     def __init__(self, base_uri: str):
         self.base_uri = base_uri
 
 
+class NoOptionsAvailableError(NotFoundError):
+    """Raised when the user would choose options, but no options are available"""
+
+    pass
+
+
 class InProcessFromCLIError(NotFoundError):
     """Raised when the user requests the in-process runtime when using the CLI"""
 
 
 # Unsupported features
 class UnsupportedRuntimeFeature(Warning):
     """Raised when a requested feature is not supported on the selected runtime."""
@@ -243,7 +281,12 @@
     pass
 
 
 class ProjectInvalidError(BaseRuntimeError):
     """When there is insufficient information provided to identify a unique project."""
 
     pass
+
+
+class WorkspacesNotSupportedError(BaseRuntimeError):
+    """When requested for a workspaces-related method in a runtime that doesn't
+    support workspaces"""
```

## orquestra/sdk/_base/_dsl.py

```diff
@@ -984,34 +984,39 @@
     source_import: Optional[Import] = None,
     dependency_imports: Union[Iterable[Import], Import, None] = None,
     resources: Resources = Resources(),
     n_outputs: Optional[int] = None,
     custom_image: Optional[str] = None,
     custom_name: Optional[str] = None,
 ) -> Union[TaskDef[_P, _R], Callable[[Callable[_P, _R]], TaskDef[_P, _R]]]:
-    """Wraps a function into an SDK Task.
+    """
+    Wraps a function into an Orquestra Task.
+
+    The result is something you can use inside your `@sdk.workflow` function. If you
+    need to call the task's underlying function directly, see
+    ``orquestra.sdk.packaging.execute_task()``.
 
     Args:
         fn: A function definition to expose to Orquestra.
-        source_import: Tells Orquestra what git repo to clone to run this task
-            Only matters when running workflows remotely (on Quantum Engine).
-        dependency_imports: Tells Orquestra what other git repos need to be
-            cloned and installed before running this task. Use it only when
-            your dependencies aren't installable from PyPI. Only matters when
-            running workflows remotely (on Quantum Engine).
+        source_import: Tells Orquestra what "import" needs to be installed to access
+            this task's code. For more information see the ``Import``'s union definition
+            and the guide:
+            https://docs.orquestra.io/docs/core/sdk/guides/dependency-installation.html
+        dependency_imports: Tells Orquestra what other "imports" need to be
+            installed before running this task. For more information see:
+            https://docs.orquestra.io/docs/core/sdk/guides/dependency-installation.html
         resources: hints Orquestra what computational resources are required to
-            run this task. Only matters when running workflows remotely (on Quantum
-            Engine).
+            run this task. For more information see:
+            https://docs.orquestra.io/docs/core/sdk/guides/resource-management.html
         n_outputs: tells Orquestra how many outputs this task produces. If omitted,
             the SDK magically infers this information from the task function's source
             code by analyzing the Abstract Syntax Tree (AST).
         custom_image: tell the runtime to run this task in a docker container
-            preloaded with a custom docker image. If the runtime doesn't support
-            it, this field is ignored. Currently, this field only has effect
-            when running the workflow using QERuntime.
+            preloaded with a custom docker image. Only supported with remote workflows
+            sent to Quantum Engine and Compute Engine.
         custom_name: changes name for invocation of this task. Supports python
             formatting in brackets {} using task parameters. Currently, supports only
             values known at submit time. If parameter is unknown at submit time (e.g.
             result of other task) - it will be placeholded. Due to the QE limitations
             every char that is non-alphanumeric will be changed to dash ("-").
             Also only first 128 characters of the name will be used
     """
```

## orquestra/sdk/_base/_env.py

```diff
@@ -16,20 +16,34 @@
 DB_PATH_ENV = "ORQ_DB_PATH"
 """
 Used to configure the location of the `workflows.db`
 Example:
     ORQ_DB_PATH=/tmp/workflows.db
 """
 
-
 PASSPORT_FILE_ENV = "ORQUESTRA_PASSPORT_FILE"
 """
 Consumed by the Workflow SDK to set auth in remote contexts
 """
 
+CURRENT_CLUSTER_ENV = "ORQ_CURRENT_CLUSTER"
+"""
+Set by Studio to share cluster's URL
+"""
+
+CURRENT_WORKSPACE_ENV = "ORQ_CURRENT_WORKSPACE"
+"""
+Set by Studio to share current workspace ID
+"""
+
+CURRENT_PROJECT_ENV = "ORQ_CURRENT_PROJECT"
+"""
+Set by Studio to share current project ID
+"""
+
 ORQ_VERBOSE = "ORQ_VERBOSE"
 """
 If set to a truthy value, enables printing debug information when running the ``orq``
 CLI commands.
 """
 
 # --------------------------------- Ray --------------------------------------
@@ -63,14 +77,21 @@
 """
 
 RAY_GLOBAL_WF_RUN_ID_ENV = "GLOBAL_WF_RUN_ID"
 """
 Used to set the workflow run ID in a Ray workflow
 """
 
+RAY_SET_CUSTOM_IMAGE_RESOURCES_ENV = "ORQ_RAY_SET_CUSTOM_IMAGE_RESOURCES"
+"""
+Used to configure if Ray uses custom images
+Example:
+    ORQ_RAY_SET_CUSTOM_IMAGE_RESOURCES=1
+"""
+
 
 # ------------------------------- utilities ----------------------------------
 
 
 def _is_truthy(env_var_value: t.Optional[str]):
     if env_var_value is None:
         return False
```

## orquestra/sdk/_base/_exec_ctx.py

```diff
@@ -75,7 +75,12 @@
 @contextmanager
 def platform_qe():
     """
     Helper. Sets the context for running code in a remote, QE-based task.
     """
     with _set_context(ExecContext.PLATFORM_QE):
         yield
+
+
+def get_current_exec_context() -> ExecContext:
+    """Getter for the current execution context."""
+    return global_context
```

## orquestra/sdk/_base/_in_process_runtime.py

```diff
@@ -1,29 +1,78 @@
 ################################################################################
 # Â© Copyright 2022-2023 Zapata Computing Inc.
 ################################################################################
+"""
+In-process implementation of the runtime interface.
+"""
+
 import typing as t
 import warnings
+from contextlib import contextmanager
 from datetime import datetime, timedelta, timezone
 
 from orquestra.sdk import ProjectRef, exceptions
 from orquestra.sdk._base import abc
 from orquestra.sdk.schema import ir
 from orquestra.sdk.schema.responses import WorkflowResult
-from orquestra.sdk.schema.workflow_run import RunStatus, State, TaskRun, WorkflowRun
+from orquestra.sdk.schema.workflow_run import (
+    ProjectId,
+    RunStatus,
+    State,
+    TaskRun,
+    TaskRunId,
+    WorkflowRun,
+    WorkflowRunId,
+    WorkspaceId,
+)
 
 from .. import secrets
 from . import serde
 from ._graphs import iter_invocations_topologically
 from .dispatch import locate_fn_ref
 
 WfRunId = str
 ArtifactValue = t.Any
 TaskOutputs = t.Tuple[ArtifactValue, ...]
 
+global_current_run_ids: t.Optional[
+    t.Tuple[WorkflowRunId, ir.TaskInvocationId, TaskRunId]
+] = None
+"""
+Global variable to store the current workflow, task inv, and task run IDs.
+
+This should _only_ be used in the context of the set_ids context manager or the
+`get_current_in_process_ids` function, and should be None at all other times.
+"""
+
+
+@contextmanager
+def set_ids(ids: t.Tuple[WorkflowRunId, ir.TaskInvocationId, TaskRunId]):
+    """
+    Temporarily set the global_current_run_ids global variable.
+
+    global_current_run_ids will be set to a tuple of the current WorkflowRunID,
+    TaskInvocationID, and TaskRunID.
+    """
+
+    global global_current_run_ids
+    old_ids = global_current_run_ids
+    global_current_run_ids = ids
+    yield
+    global_current_run_ids = old_ids
+
+
+def get_current_in_process_ids() -> (
+    t.Optional[t.Tuple[WorkflowRunId, ir.TaskInvocationId, TaskRunId]]
+):
+    """
+    Getter for the current In process run IDs.
+    """
+    return global_current_run_ids
+
 
 def _make_completed_task_run(workflow_run_id, start_time, end_time, task_inv):
     return TaskRun(
         id=f"{workflow_run_id}-{task_inv}",
         invocation_id=task_inv,
         status=RunStatus(
             state=State.SUCCEEDED,
@@ -118,20 +167,22 @@
             )
 
             # Next, the task is executed with the args/kwargs
             try:
                 fn = task_fn._TaskDef__sdk_task_body
             except AttributeError:
                 fn = task_fn
-            fn_output = fn(*args, **kwargs)
+
+            with set_ids((run_id, task_inv.id, task_inv.task_id)):
+                fn_output = fn(*args, **kwargs)
 
             # Finally, we need to dereference the output IDs
             for artifact_id in task_inv.output_ids:
                 artifact = workflow_def.artifact_nodes[artifact_id]
-                if artifact.artifact_index is None:
+                if artifact.artifact_index is None or not isinstance(fn_output, tuple):
                     self._artifact_store[run_id][artifact_id] = fn_output
                 else:
                     self._artifact_store[run_id][artifact_id] = fn_output[
                         artifact.artifact_index
                     ]
 
         # Ordinary functions return `obj` or `tuple(obj, obj)`
@@ -164,17 +215,18 @@
             # Assumption there's always a non-unpacked artifact. We want to return
             # whatever shape was returned from the task function so we can use the
             # "packed" artifact. For more info on artifact unpacking, see
             # "orquestra.sdk._base._traversal".
 
             artifact_nodes = [wf_def.artifact_nodes[id] for id in inv.output_ids]
             packed_nodes = [n for n in artifact_nodes if n.artifact_index is None]
-            assert (
-                len(packed_nodes) == 1
-            ), f"Task invocation should have exactly 1 packed output. {inv.id} has {len(packed_nodes)}: {packed_nodes}"  # noqa: E501
+            assert len(packed_nodes) == 1, (
+                "Task invocation should have exactly 1 packed output. "
+                f"{inv.id} has {len(packed_nodes)}: {packed_nodes}"
+            )
             packed_artifact = packed_nodes[0]
 
             task_result = self._artifact_store[workflow_run_id][packed_artifact.id]
 
             inv_outputs[inv.id] = serde.result_from_artifact(
                 task_result, ir.ArtifactFormat.AUTO
             )
@@ -221,26 +273,35 @@
 
     def list_workflow_runs(
         self,
         *,
         limit: t.Optional[int] = None,
         max_age: t.Optional[timedelta] = None,
         state: t.Union[State, t.List[State], None] = None,
+        workspace: t.Optional[WorkspaceId] = None,
+        project: t.Optional[ProjectId] = None,
     ) -> t.List[WorkflowRun]:
         """
         List the workflow runs, with some filters
 
         Args:
             limit: Restrict the number of runs to return, prioritising the most recent.
             max_age: Only return runs younger than the specified maximum age.
             status: Only return runs of runs with the specified status.
-
+            workspace: Only return runs from the specified workspace. Not supported
+                on this runtime.
         Returns:
                 A list of the workflow runs
+        Raises:
+            WorkspacesNotSupportedError: when a workspace or project is specified.
         """
+        if workspace or project:
+            raise exceptions.WorkspacesNotSupportedError(
+                "Filtering by workspace is not supported on In Process runtimes."
+            )
         now = datetime.now(timezone.utc)
 
         if state is not None:
             if not isinstance(state, list):
                 state_list = [state]
             else:
                 state_list = state
```

## orquestra/sdk/_base/_log_adapter.py

```diff
@@ -3,18 +3,18 @@
 ################################################################################
 """
 Log adapter adds a workflow context to logs, Workflow ID and Task ID.
 """
 
 import json
 import logging
-import os
 import typing as t
 from datetime import datetime, timezone
 
+from orquestra.sdk._base._api._task_run import current_run_ids
 from orquestra.sdk.schema.ir import TaskInvocationId
 from orquestra.sdk.schema.workflow_run import TaskRunId, WorkflowRunId
 
 # NOTE: the `message`, `wf_run_id`, and `task_run_id` value placeholders don't come with
 # "" quotes. We already add them when we json.dumps() the value. This ensure proper JSON
 # escaping and handling null values.
 FORMAT = '{"timestamp": "%(asctime)s", "level": "%(levelname)s", "filename": "%(filename)s:%(lineno)s", "message": %(message)s, "wf_run_id": %(wf_run_id)s, "task_inv_id": %(task_inv_id)s, "task_run_id": %(task_run_id)s}'  # noqa
@@ -48,54 +48,14 @@
 
         # Mimic default behavior of logging.LoggerAdapter. Note we keep run IDs as
         # extras.
         new_kwargs = {**kwargs, "extra": new_extra}
         return new_msg, new_kwargs
 
 
-def is_argo_backend():
-    """
-    Quantum Engine backend test.
-    Argo Workflows are executed in pods, where ARGO_NODE_ID corresponds
-    to the workflow step ID.
-    """
-    return "ARGO_NODE_ID" in os.environ
-
-
-def get_argo_backend_ids() -> t.Tuple[WorkflowRunId, TaskInvocationId, TaskRunId]:
-    node_id = os.environ["ARGO_NODE_ID"]
-    # Argo Workflow ID is the left part of the step ID
-    # [wf-id]-[retry-number]-[step-number]
-    wf_run_id = "-".join(node_id.split("-")[:-2])
-    task_run_id = node_id
-
-    argo_template = json.loads(os.environ["ARGO_TEMPLATE"])
-    # Looks like the template name on Argo matches our task invocation ID. Not sure how
-    # good this assumption is.
-    task_inv_id = argo_template["name"]
-
-    return wf_run_id, task_inv_id, task_run_id
-
-
-def get_ray_backend_ids() -> (
-    t.Tuple[
-        t.Optional[WorkflowRunId], t.Optional[TaskInvocationId], t.Optional[TaskRunId]
-    ]
-):
-    try:
-        # Deferred import because Ray isn't installed when running on QE.
-        import orquestra.sdk._ray._dag
-
-    except ModuleNotFoundError:
-        # Ray is not installed
-        return None, None, None
-
-    return orquestra.sdk._ray._dag.get_current_ids()
-
-
 class ISOFormatter(logging.Formatter):
     """
     Overrides the default date formatting to produce ISO 8601 strings.
     """
 
     def formatTime(self, record, datefmt=None) -> str:
         """
@@ -160,20 +120,19 @@
 
     Each call of this function creates a new object. It shouldn't be retained across
     task runs.
     """
     wf_run_id: t.Optional[WorkflowRunId]
     task_inv_id: t.Optional[TaskInvocationId]
     task_run_id: t.Optional[TaskRunId]
-    if is_argo_backend():
-        # Workflow is running in the Orquestra QE environment
-        wf_run_id, task_inv_id, task_run_id = get_argo_backend_ids()
-    else:
-        # We assume the workflow is running on Ray
-        wf_run_id, task_inv_id, task_run_id = get_ray_backend_ids()
+    try:
+        wf_run_id, task_inv_id, task_run_id = current_run_ids()
+    except ModuleNotFoundError:
+        # Ray is not installed
+        wf_run_id, task_inv_id, task_run_id = None, None, None
 
     logger = _make_logger(
         wf_run_id=wf_run_id, task_inv_id=task_inv_id, task_run_id=task_run_id
     )
 
     return logger
```

## orquestra/sdk/_base/_services.py

```diff
@@ -76,47 +76,45 @@
         return "Ray"
 
     def up(self):
         """
         Starts a Ray cluster. If a Ray is already running, this does nothing.
 
         Raises:
-            RuntimeError: if we ask Ray to start and it fails
-            subprocess.CalledProcessError: if calling the `ray` CLI failed. This
-                shouldn't happen in regular conditions.
+            subprocess.CalledProcessError: if calling the `ray` CLI failed.
         """
         ray_temp = ray_temp_path()
         ray_storage = ray_storage_path()
         ray_plasma = ray_plasma_path()
 
         for path in (ray_temp, ray_storage, ray_plasma):
             path.mkdir(exist_ok=True, parents=True)
 
         # 'ray start' fails if the cluster can't be started, or another problem
         # occurred. I don't know a good way to differentiate between these
         # scenarios, so the strategy is:
         # 1. Attempt to start the Ray cluster. Ignore errors.
         # 2. Check if the cluster is running to confirm that either the cluster was
         #    started, or it had been already running prior to this command.
-        _ = subprocess.run(
+        proc = subprocess.run(
             [
                 "ray",
                 "start",
                 "--head",
                 f"--temp-dir={ray_temp}",
                 f"--storage={ray_storage}",
                 f"--plasma-directory={ray_plasma}",
             ],
             check=False,
             timeout=IPC_TIMEOUT,
-            stdout=subprocess.DEVNULL,
-            stderr=subprocess.DEVNULL,
+            stdout=subprocess.PIPE,
+            stderr=subprocess.PIPE,
         )
         if not self.is_running():
-            raise RuntimeError("Couldn't start Ray cluster")
+            proc.check_returncode()
 
     def down(self):
         """
         Shuts down the managed Ray cluster. If Ray isn't running, this does nothing.
 
         Raises:
             subprocess.CalledProcessError: if calling the `ray` CLI failed. This
```

## orquestra/sdk/_base/_workflow.py

```diff
@@ -22,19 +22,15 @@
     Union,
     overload,
 )
 
 from typing_extensions import ParamSpec
 
 import orquestra.sdk.schema.ir as ir
-from orquestra.sdk.exceptions import (
-    ConfigNameNotFoundError,
-    ProjectInvalidError,
-    WorkflowSyntaxError,
-)
+from orquestra.sdk.exceptions import ConfigNameNotFoundError, WorkflowSyntaxError
 from orquestra.sdk.schema.workflow_run import ProjectId, WorkspaceId
 
 from .. import secrets
 from . import _api, _dsl, loader
 from ._ast import CallVisitor, NodeReference, NodeReferenceType, normalize_indents
 from ._dsl import (
     DataAggregation,
@@ -44,14 +40,15 @@
     Secret,
     TaskDef,
     UnknownPlaceholderInCustomNameWarning,
     get_fn_ref,
     parse_custom_name,
 )
 from ._in_process_runtime import InProcessRuntime
+from ._spaces._resolver import resolve_studio_project_ref
 from ._spaces._structs import ProjectRef
 from .abc import RuntimeInterface
 
 
 # ----- Workflow exceptions  -----
 class NotATaskWarning(Warning):
     pass
@@ -157,128 +154,87 @@
     def local_run(self) -> _R:
         """Executes workflow as a script in a local environment."""
         _dsl.DIRECT_EXECUTION = True
         result = self._fn(*self._workflow_args, **self._workflow_kwargs)
         _dsl.DIRECT_EXECUTION = False
         return result
 
-    def prepare(
+    def run(
         self,
-        config: Union[_api.RuntimeConfig, str],
+        config: Optional[Union[_api.RuntimeConfig, str]] = None,
         project_dir: Optional[Union[str, Path]] = None,
         workspace_id: Optional[WorkspaceId] = None,
         project_id: Optional[ProjectId] = None,
     ) -> _api.WorkflowRun:
         """
-        "Prepares" workflow for running. Call ".start()" on the result to
-        schedule the workflow for execution.
+        Schedules workflow for execution.
 
         Args:
             config: SDK needs to know where to execute the workflow. The config
                 contains the required details. This can be a RuntimeConfig object, or
                 the name of a saved configuration.
             project_dir: the path to the project directory. If omitted, the current
                 working directory is used.
             workspace_id: ID of the workspace for workflow - supported only on CE
             project_id: ID of the project for workflow - supported only on CE
 
         Raises:
-            ConfigNameNotFoundError: when the configuration has not been saved prior to
-                this point.
             orquestra.sdk.exceptions.DirtyGitRepo: (warning) when a task def used by
                 this workflow def has a "GitImport" and the git repo that contains it
                 has uncommitted changes.
             ProjectInvalidError: when only 1 out of project and workspace is passed
+
         """
+        # This exists for users who have gotten used to doing `run()`. Once this has
+        # been released, the following release should make config a required argument
+        # and remove this check.
+        if config is None:
+            raise FutureWarning(
+                "Please specify the runtime configuration for this run. "
+                "The built in `local` and `in_process` configurations can be used by "
+                'calling `run("local")` and `run("in_process")` respectively. '
+                "User defined configurations can be specified by providing the name "
+                "under which they are saved, or passing in the RuntimeConfig object "
+                "directly. "
+            )
+
         _config: _api.RuntimeConfig
         if isinstance(config, _api.RuntimeConfig):
             _config = config
         elif isinstance(config, str):
             _config = _api.RuntimeConfig.load(config)
         else:
             raise TypeError(
-                f"'config' argument to `prepare()` has unsupported type {type(config)}."
+                f"'config' argument to `run()` has unsupported type {type(config)}."
             )
         runtime: RuntimeInterface
         if _config._runtime_name == "IN_PROCESS":
             runtime = InProcessRuntime()
         else:
             runtime = _config._get_runtime(project_dir=project_dir)
 
         # In close future there will be multiple ways of figuring out the
         # appropriate runtime to use, based on `config`. Regardless of this
         # logic, the runtime should always be resolved.
         assert runtime is not None
 
-        _project: Optional[ProjectRef]
-        if project_id is not None and workspace_id is not None:
-            _project = ProjectRef(project_id=project_id, workspace_id=workspace_id)
-        elif project_id is None and workspace_id is None:
-            _project = None
-        else:
-            raise ProjectInvalidError(
-                "Invalid project ID. Either explicitly pass workspace_id "
-                "and project_id, or omit both"
-            )
+        _project: Optional[ProjectRef] = resolve_studio_project_ref(
+            workspace_id, project_id, _config.name
+        )
 
         # The DirtyGitRepo warning can be raised here.
         wf_def_model = self.model
 
-        return _api.WorkflowRun(
-            run_id=None,
+        wf_run = _api.WorkflowRun._start(
             wf_def=wf_def_model,
             runtime=runtime,
             config=_config,
             project=_project,
         )
-
-    def run(
-        self,
-        config: Optional[Union[_api.RuntimeConfig, str]] = None,
-        project_dir: Optional[Union[str, Path]] = None,
-        workspace_id: Optional[WorkspaceId] = None,
-        project_id: Optional[ProjectId] = None,
-    ) -> _api.WorkflowRun:
-        """
-        Schedules workflow for execution. Shorthand for
-        `workflow.prepare().start()`.
-
-        Args:
-            config: SDK needs to know where to execute the workflow. This
-                objects contains the required details.
-            project_dir: the path to the project directory. If omitted, the current
-                working directory is used.
-            workspace_id: ID of the workspace for workflow - supported only on CE
-            project_id: ID of the project for workflow - supported only on CE
-
-        Raises:
-            orquestra.sdk.exceptions.DirtyGitRepo: (warning) when a task def used by
-                this workflow def has a "GitImport" and the git repo that contains it
-                has uncommitted changes.
-        """
-        # This exists for users who have gotten used to doing `run()`. Once this has
-        # been released, the following release should make config a required argument
-        # and remove this check.
-        if config is None:
-            raise FutureWarning(
-                "Please specify the runtime configuration for this run. "
-                "The built in `local` and `in_process` configurations can be used by "
-                'calling `run.("local")` and `run("in_process")` respectively. '
-                "User defined configurations can be specified by providing the name "
-                "under which they are saved, or passing in the RuntimeConfig object "
-                "directly. "
-            )
-        run = self.prepare(
-            config,
-            project_dir=project_dir,
-            workspace_id=workspace_id,
-            project_id=project_id,
-        )
-        run.start()
-        return run
+        return wf_run
 
     def with_resources(
         self,
         *,
         cpu: Optional[Union[str, _dsl.Sentinel]] = _dsl.Sentinel.NO_UPDATE,
         memory: Optional[Union[str, _dsl.Sentinel]] = _dsl.Sentinel.NO_UPDATE,
         disk: Optional[Union[str, _dsl.Sentinel]] = _dsl.Sentinel.NO_UPDATE,
```

## orquestra/sdk/_base/abc.py

```diff
@@ -12,23 +12,26 @@
 
 import typing as t
 from abc import ABC, abstractmethod
 from datetime import timedelta
 from pathlib import Path
 
 from orquestra.sdk._base._spaces._structs import Project, ProjectRef, Workspace
+from orquestra.sdk.exceptions import WorkspacesNotSupportedError
 from orquestra.sdk.schema.configs import RuntimeConfiguration
 from orquestra.sdk.schema.ir import TaskInvocationId, WorkflowDef
 from orquestra.sdk.schema.local_database import StoredWorkflowRun
 from orquestra.sdk.schema.responses import WorkflowResult
 from orquestra.sdk.schema.workflow_run import (
+    ProjectId,
     State,
     WorkflowRun,
     WorkflowRunId,
     WorkflowRunMinimal,
+    WorkspaceId,
 )
 
 
 class LogReader(t.Protocol):
     """
     A component that reads logs produced by tasks and workflows.
     """
@@ -154,22 +157,26 @@
     @abstractmethod
     def list_workflow_runs(
         self,
         *,
         limit: t.Optional[int] = None,
         max_age: t.Optional[timedelta] = None,
         state: t.Optional[t.Union[State, t.List[State]]] = None,
+        workspace: t.Optional[WorkspaceId] = None,
+        project: t.Optional[ProjectId] = None
     ) -> t.Sequence[WorkflowRunMinimal]:
         """
         List the workflow runs, with some filters
 
         Args:
             limit: Restrict the number of runs to return, prioritising the most recent.
             max_age: Only return runs younger than the specified maximum age.
             state: Only return runs of runs with the specified status.
+            workspace: Only return runs from the specified workspace. Supported only
+                on CE.
         Returns:
                 A list of the workflow runs
         """
         raise NotImplementedError()
 
     def get_task_logs(
         self, wf_run_id: WorkflowRunId, task_inv_id: TaskInvocationId
@@ -187,21 +194,21 @@
         """
         raise NotImplementedError()
 
     def list_workspaces(self) -> t.Sequence[Workspace]:
         """
         List workspaces available to a user. Works only on CE
         """
-        raise NotImplementedError()
+        raise WorkspacesNotSupportedError()
 
     def list_projects(self, workspace_id: str) -> t.Sequence[Project]:
         """
         List workspaces available to a user. Works only on CE
         """
-        raise NotImplementedError()
+        raise WorkspacesNotSupportedError()
 
 
 class WorkflowRepo(ABC):
     """
     This is the interface for accessing workflow runs that have been submitted
 
     The results and status is still delegated to the Runtime
```

## orquestra/sdk/_base/dispatch.py

```diff
@@ -274,15 +274,15 @@
 
     # --- Phase 4: save the outputs ---
     ret_nodes = [
         ir.ArtifactNode.parse_obj(node_dict) for node_dict in __sdk_output_node_dicts
     ]
 
     for ret_node in ret_nodes:
-        if ret_node.artifact_index is None:
+        if ret_node.artifact_index is None or not isinstance(ret_obj, tuple):
             ret_val = ret_obj
         else:
             ret_val = ret_obj[ret_node.artifact_index]
         result = serde.result_from_artifact(
             artifact_value=ret_val, artifact_format=ret_node.serialization_format
         )
         with open(_make_path(ret_node, __sdk_artifacts_dir), "w") as f:
```

## orquestra/sdk/_base/_api/__init__.py

```diff
@@ -5,17 +5,18 @@
 User-facing API for controlling workflows.
 
 We re-export symbols here for grouping concepts under the "api" umbrella, e.g.
 "_api.WorkflowRun".
 """
 
 from ._config import RuntimeConfig, migrate_config_file
-from ._task_run import TaskRun
+from ._task_run import TaskRun, current_run_ids
 from ._wf_run import WorkflowRun, list_workflow_runs
 
 __all__ = [
     "RuntimeConfig",
     "TaskRun",
+    "current_run_ids",
     "WorkflowRun",
     "list_workflow_runs",
     "migrate_config_file",
 ]
```

## orquestra/sdk/_base/_api/_task_run.py

```diff
@@ -1,23 +1,26 @@
 ################################################################################
 # Â© Copyright 2022-2023 Zapata Computing Inc.
 ################################################################################
 
+import json
+import os
 import typing as t
 from collections import namedtuple
 from itertools import chain
 
 from orquestra.sdk._base import serde
 from orquestra.sdk.schema import ir
 from orquestra.sdk.schema.responses import WorkflowResult
 from orquestra.sdk.schema.workflow_run import State, TaskInvocationId
 from orquestra.sdk.schema.workflow_run import TaskRun as TaskRunModel
 from orquestra.sdk.schema.workflow_run import TaskRunId, WorkflowRunId
 
-from ...exceptions import TaskRunNotFound
+from ..._base import _exec_ctx
+from ...exceptions import TaskRunNotFound, WorkflowRunIDNotFoundError
 from ..abc import ArtifactValue, RuntimeInterface
 from ..serde import deserialize_constant
 
 
 class TaskRun:
     """
     Represents execution of a single task.
@@ -253,7 +256,129 @@
                 runtime=self._runtime,
                 wf_def=self._wf_def,
             )
             for model in parent_run_models
         ]
 
         return set(parents)
+
+
+def _get_argo_backend_ids() -> (
+    t.Tuple[WorkflowRunId, t.Optional[TaskInvocationId], t.Optional[TaskRunId]]
+):
+    """
+    Get the workflow run, task invocation, and task run IDs from Argo.
+
+    Raises:
+        WorkflowRunIDNotFoundError: When the workflow run ID can't be recovered.
+    """
+
+    assert (
+        "ARGO_NODE_ID" in os.environ
+    ), "The ARGO_NODE_ID environment variable is absent."
+
+    node_id = os.environ["ARGO_NODE_ID"]
+    # Argo Workflow ID is the left part of the step ID
+    # [wf-id]-[retry-number]-[step-number]
+    wf_run_id = "-".join(node_id.split("-")[:-2])
+    task_run_id = node_id
+
+    argo_template = json.loads(os.environ["ARGO_TEMPLATE"])
+    # Looks like the template name on Argo matches our task invocation ID. Not sure how
+    # good this assumption is.
+    task_inv_id = argo_template["name"]
+
+    if len(wf_run_id) == 0:
+        raise WorkflowRunIDNotFoundError("Could not recover Workflow Run ID")
+
+    return wf_run_id, task_inv_id, task_run_id
+
+
+def _get_ray_backend_ids() -> (
+    t.Tuple[WorkflowRunId, t.Optional[TaskInvocationId], t.Optional[TaskRunId]]
+):
+    """
+    Get the workflow run, task invocation, and task run IDs from Ray.
+
+    Raises:
+        ModuleNotFoundError: when Ray isn't installed.
+        WorkflowRunIDNotFoundError: When the workflow run ID can't be recovered.
+    """
+    # Deferred import because Ray isn't installed when running on QE.
+    import orquestra.sdk._ray._dag
+
+    wf_run_id, task_inv_id, task_run_id = orquestra.sdk._ray._dag.get_current_ids()
+
+    if wf_run_id is None:
+        raise WorkflowRunIDNotFoundError("Could not recover Workflow Run ID")
+
+    return wf_run_id, task_inv_id, task_run_id
+
+
+def _get_in_process_backend_ids() -> (
+    t.Tuple[WorkflowRunId, t.Optional[TaskInvocationId], t.Optional[TaskRunId]]
+):
+    """
+    Get the workflow run, task invocation, and task run IDs from the In-process runtime.
+
+    Raises:
+        WorkflowRunIDNotFoundError: When the workflow run ID can't be recovered.
+    """
+    from ..._base._in_process_runtime import get_current_in_process_ids
+
+    ids = get_current_in_process_ids()
+
+    if ids is None:
+        raise WorkflowRunIDNotFoundError(
+            "current_run_ids global was imported with value None."
+        )
+    if ids[0] is None:
+        raise WorkflowRunIDNotFoundError("Could not recover Workflow Run ID")
+
+    return ids
+
+
+def current_run_ids() -> (
+    t.Tuple[WorkflowRunId, t.Optional[TaskInvocationId], t.Optional[TaskRunId]]
+):
+    """
+    Get the workflow run, task invocation, and task run IDs related to current
+    execution context.
+
+    Workflow run ID is a globally unique identifier generated whenever a workflow is
+    submitted for running. Single workflow definition can be run multiple times
+    resulting in multiple workflow run IDs. Analog of PID for a standard program.
+
+    Task invocation ID is related to using a task in your workflow definition,
+    analogous to a function invocation in a standard program. Scoped to a workflow
+    definition. Isn't globally unique. If you run the same workflow definition multiple
+    times, you'll end up with the same task invocation IDs across runs.
+
+    Task run ID is a globally unique identifier of executing an invocation exactly once.
+
+    This function is intended to be used within the task code in the following way:
+    ```
+    @sdk.task
+    def t():
+        wf_run_id, task_inv_id, task_run_id =  sdk.current_run_ids()
+        ...
+    ```
+
+    Returns:
+        WorkflowRunId, TaskInvocationId, TaskRunId
+
+    Raises:
+        WorkflowRunIDNotFoundError: When the workflow run ID cannot be recovered.
+        NotImplementedError: When the execution context is not one of the covered cases.
+    """
+    context = _exec_ctx.get_current_exec_context()
+
+    if context == _exec_ctx.ExecContext.PLATFORM_QE:
+        return _get_argo_backend_ids()
+    elif context == _exec_ctx.ExecContext.RAY:
+        return _get_ray_backend_ids()
+    elif context == _exec_ctx.ExecContext.DIRECT:
+        return _get_in_process_backend_ids()
+
+    raise NotImplementedError(
+        f"Got unexpected global context {context}. Please report this as a bug."
+    )
```

## orquestra/sdk/_base/_api/_wf_run.py

```diff
@@ -9,29 +9,29 @@
 import warnings
 from datetime import timedelta
 from pathlib import Path
 
 from ...exceptions import (
     ConfigFileNotFoundError,
     ConfigNameNotFoundError,
+    ProjectInvalidError,
     UnauthorizedError,
     WorkflowRunCanNotBeTerminated,
     WorkflowRunNotFinished,
     WorkflowRunNotFoundError,
-    WorkflowRunNotStarted,
     WorkflowRunNotSucceeded,
 )
 from ...schema import ir
 from ...schema.configs import ConfigName
 from ...schema.local_database import StoredWorkflowRun
-from ...schema.workflow_run import State, TaskInvocationId
+from ...schema.workflow_run import ProjectId, State, TaskInvocationId
 from ...schema.workflow_run import WorkflowRun as WorkflowRunModel
-from ...schema.workflow_run import WorkflowRunId, WorkflowRunMinimal
+from ...schema.workflow_run import WorkflowRunId, WorkflowRunMinimal, WorkspaceId
 from .. import serde
-from .._spaces._structs import ProjectRef
+from .._spaces._resolver import resolve_studio_project_ref
 from ..abc import RuntimeInterface
 from ._config import RuntimeConfig, _resolve_config
 from ._task_run import TaskRun
 
 COMPLETED_STATES = [State.FAILED, State.TERMINATED, State.SUCCEEDED]
 
 
@@ -121,46 +121,58 @@
             wf_def=wf_run_model.workflow_def,
             runtime=runtime,
             config=resolved_config,
         )
 
         return workflow_run
 
+    @classmethod
+    def _start(cls, wf_def: ir.WorkflowDef, runtime, config, project):
+        """
+        Schedule workflow for execution and return WorkflowRun.
+        """
+        run_id = runtime.create_workflow_run(wf_def, project)
+
+        workflow_run = WorkflowRun(
+            run_id=run_id,
+            wf_def=wf_def,
+            runtime=runtime,
+            config=config,
+        )
+
+        return workflow_run
+
     def __init__(
         self,
-        run_id: t.Optional[WorkflowRunId],
+        run_id: WorkflowRunId,
         wf_def: ir.WorkflowDef,
         runtime: RuntimeInterface,
         config: t.Optional["RuntimeConfig"] = None,
-        project: t.Optional[ProjectRef] = None,
     ):
         """
         Users aren't expected to use __init__() directly. Please use
-        `WorkflowRun.by_id`, `WorkflowDef.prepare()`, or `WorkflowDef.run()`.
+        `WorkflowRun.by_id` or `WorkflowDef.run()`.
 
         Args:
             wf_def: the workflow being run. Workflow definition in the model
                 (serializable) form.
             runtime: the adapter object used to interact with the runtime to
                 submit workflow, get results, etc. Different "runtimes" like
                 Ray or Quantum Engine have corresponding classes.
         """
 
         self._run_id = run_id
         self._wf_def = wf_def
         self._runtime = runtime
         self._config = config
-        self._project = project
 
     def __str__(self) -> str:
         outstr: str = ""
-        if self._run_id is None:
-            outstr += "Unstarted WorkflowRun with parameters:"
-        else:
-            outstr += f"WorkflowRun '{self._run_id}' with parameters:"
+
+        outstr += f"WorkflowRun '{self._run_id}' with parameters:"
         if self._config is None:
             outstr += "\n- Runtime: In-process runtime."
         else:
             outstr += f"\n- Config name: {self._config.name}"
             outstr += f"\n- Runtime name: {self._config._runtime_name}"
         return outstr
 
@@ -169,77 +181,44 @@
         """
         The configuration for this workflow run.
         """
         if self._config is None:
             no_config_message = (
                 "This workflow run was created without a runtime configuration. "
             )
-            if self._run_id is None:
-                no_config_message += (
-                    "The default in-process runtime will be used at execution."
-                )
-            else:
-                no_config_message += "The default in-process runtime was used."
+            no_config_message += "The default in-process runtime was used."
             warnings.warn(no_config_message)
 
         return self._config
 
     @property
     def run_id(self):
         """
         The run_id for this workflow run.
-
-        Raises:
-            WorkflowRunNotStarted: when the workflow run has not started
         """
-        workflow_not_started_message = (
-            "Cannot get the run id of workflow run that hasn't started yet. "
-            "You will need to call the `.start()` method prior accessing this property."
-        )
-        if self._run_id is None:
-            raise WorkflowRunNotStarted(workflow_not_started_message)
         return self._run_id
 
-    def start(self):
-        """
-        Schedule workflow for execution.
-        """
-        run_id = self._runtime.create_workflow_run(self._wf_def, self._project)
-        self._run_id = run_id
-
     def wait_until_finished(self, frequency: float = 0.25, verbose=True) -> State:
         """Block until the workflow run finishes.
 
         This method draws no distinctions between whether the workflow run completes
         successfully, fails, or is terminated for any other reason.
 
         Args:
             frequency: The frequency in Hz at which the status should be checked.
             verbose: If ``True``, each iteration of the polling loop will print to
                 stderr.
 
-        Raises:
-            WorkflowRunNotStarted: when the workflow run has not started
-
         Returns:
             State: The state of the finished workflow.
         """
 
         assert frequency > 0.0, "Frequency must be a positive non-zero value"
 
-        try:
-            status = self.get_status()
-        except WorkflowRunNotStarted as e:
-            message = (
-                "Cannot wait for the completion of workflow run that hasn't started "
-                "yet. "
-                "You will need to call the `.start()` method prior to calling this "
-                "method."
-            )
-            raise WorkflowRunNotStarted(message) from e
+        status = self.get_status()
 
         while status == State.RUNNING or status == State.WAITING:
             sleep_time = 1.0 / frequency
 
             if verbose:
                 print(
                     f"{self.run_id} is {status.name}. Sleeping for {sleep_time}s...",
@@ -264,57 +243,35 @@
         return status
 
     def stop(self):
         """
         Asks the runtime to stop the workflow run.
 
         Raises:
-            orquestra.sdk.exceptions.WorkflowRunNotStarted: when the workflow run was
-                not started yet
             orquestra.sdk.exceptions.UnauthorizedError: when communication with runtime
                 failed because of an auth error
             orquestra.sdk.exceptions.WorkflowRunCanNotBeTerminated if the termination
                 attempt failed
         """
         try:
-            run_id = self.run_id
-        except WorkflowRunNotStarted:
-            raise
-
-        try:
-            self._runtime.stop_workflow_run(run_id)
+            self._runtime.stop_workflow_run(self.run_id)
         except (UnauthorizedError, WorkflowRunCanNotBeTerminated):
             raise
 
     def get_status(self) -> State:
         """
         Return the current status of the workflow.
-
-        Raises:
-            WorkflowRunNotStarted: when the workflow run has not started
         """
         return self.get_status_model().status.state
 
     def get_status_model(self) -> WorkflowRunModel:
         """
         Serializable representation of the workflow run state at a given point in time.
-
-        Raises:
-            WorkflowRunNotStarted: if the workflow wasn't started yet.
         """
-        try:
-            run_id = self.run_id
-        except WorkflowRunNotStarted as e:
-            message = (
-                "Cannot get the status of a workflow run that hasn't started yet. "
-                "You will need to call the `.start()` method prior to calling this "
-                "method."
-            )
-            raise WorkflowRunNotStarted(message) from e
-        return self._runtime.get_workflow_run_status(run_id)
+        return self._runtime.get_workflow_run_status(self.run_id)
 
     def get_results(self, wait: bool = False) -> t.Sequence[t.Any]:
         """
         Retrieves workflow results, as returned by the workflow function.
 
         A workflow function is expected to return task outputs
         (ArtifactFutures) or constants (10, "hello", etc.). This method returns values
@@ -325,44 +282,35 @@
 
         Args:
             wait:  whether or not to wait for workflow run completion.
                    Uses the default options for waiting, use `wait_until_finished()` for
                    more control.
 
         Raises:
-            WorkflowRunNotStarted: when the workflow run has not started
             WorkflowRunNotFinished: when the workflow run has not finished and `wait` is
                                    False
             WorkflowRunNotSucceeded: when the workflow is no longer executing, but it did not
                 succeed.
         """  # noqa 501
-        try:
-            run_id = self.run_id
-        except WorkflowRunNotStarted as e:
-            message = (
-                "Cannot get the results of a workflow run that hasn't started yet. "
-                "You will need to call the `.start()` method prior to calling this "
-                "method."
-            )
-            raise WorkflowRunNotStarted(message) from e
-
         if wait:
             self.wait_until_finished()
 
         if (state := self.get_status()) not in COMPLETED_STATES:
             raise WorkflowRunNotFinished(
-                f"Workflow run with id {run_id} has not finished. "
+                f"Workflow run with id {self.run_id} has not finished. "
                 f"Current state: {state}",
                 state,
             )
         try:
             results = (
                 *(
                     serde.deserialize(o)
-                    for o in self._runtime.get_workflow_run_outputs_non_blocking(run_id)
+                    for o in self._runtime.get_workflow_run_outputs_non_blocking(
+                        self.run_id
+                    )
                 ),
             )
         except WorkflowRunNotSucceeded:
             raise
 
         # If we only get one result back, return it directly rather than as a sequence
         if len(results) == 1:
@@ -373,37 +321,23 @@
     def get_artifacts(self) -> t.Mapping[ir.TaskInvocationId, t.Any]:
         """
         Unstable: this API will change.
 
         Returns values calculated by this workflow's tasks. If a given task hasn't
         succeeded yet, the mapping won't contain the corresponding entry.
 
-        Raises:
-            WorkflowRunNotStarted: when the workflow has not started
-
         Returns:
             A dictionary with an entry for each task run in the workflow. The key is the
                 task's invocation ID. The value is whatever the task returned. If the
                 task has 1 output, it's the dict entry's value. If the tasks has n
                 outputs, the dict entry's value is a n-tuple.
         """
-
-        try:
-            run_id = self.run_id
-        except WorkflowRunNotStarted as e:
-            message = (
-                "Cannot get the values of a workflow run that hasn't started yet. "
-                "You will need to call the `.start()` method prior to calling this "
-                "method."
-            )
-            raise WorkflowRunNotStarted(message) from e
-
         # NOTE: this is a possible place for improvement. If future runtime APIs support
         # getting a subset of artifacts, we should use them here.
-        inv_outputs = self._runtime.get_available_outputs(run_id)
+        inv_outputs = self._runtime.get_available_outputs(self.run_id)
 
         # The output shape differs across runtimes when the workflow functions returns a
         # single, packed future. See more in:
         # https://zapatacomputing.atlassian.net/browse/ORQSDK-801
         return {
             inv_id: serde.deserialize(inv_output)
             for inv_id, inv_output in inv_outputs.items()
@@ -413,99 +347,103 @@
         """
         Unstable: this API will change.
 
         Returns logs produced by all task runs in this workflow. If you're interested in
         only subset of tasks, consider using ``WorkflowRun.get_tasks()`` and
         ``TaskRun.get_logs()``.
 
-        Raises:
-            WorkflowRunNotStarted: when the workflow has not started
-
         Returns:
             A dictionary where each key-value entry corresponds to a single task run.
             The key identifies a task invocation, a single node in the workflow graph.
             The value is a list of log lines produced by the corresponding task
             invocation while running this workflow.
         """
-        try:
-            wf_run_id = self.run_id
-        except WorkflowRunNotStarted as e:
-            message = (
-                "Cannot get the logs of a workflow run that hasn't started yet. "
-                "You will need to call the `.start()` method prior to calling this "
-                "method."
-            )
-            raise WorkflowRunNotStarted(message) from e
-
-        return self._runtime.get_workflow_logs(wf_run_id=wf_run_id)
+        return self._runtime.get_workflow_logs(wf_run_id=self.run_id)
 
     # TODO: ORQSDK-617 add filtering ability for the users
     def get_tasks(self) -> t.Set[TaskRun]:
-        try:
-            wf_run_id = self.run_id
-        except WorkflowRunNotStarted as e:
-            message = (
-                "Cannot get tasks of a workflow run that hasn't started yet. "
-                "You will need to call the `.start()` method prior to calling this "
-                "method."
-            )
-            raise WorkflowRunNotStarted(message) from e
-
         wf_run_model = self.get_status_model()
 
         return {
             TaskRun(
                 task_run_id=task_run_model.id,
                 task_invocation_id=task_run_model.invocation_id,
-                workflow_run_id=wf_run_id,
+                workflow_run_id=self.run_id,
                 runtime=self._runtime,
                 wf_def=self._wf_def,
             )
             for task_run_model in wf_run_model.task_runs
         }
 
 
 def list_workflow_runs(
     config: t.Union[ConfigName, "RuntimeConfig"],
     *,
     limit: t.Optional[int] = None,
     max_age: t.Optional[str] = None,
     state: t.Optional[t.Union[State, t.List[State]]] = None,
     project_dir: t.Optional[t.Union[Path, str]] = None,
+    workspace: t.Optional[WorkspaceId] = None,
+    project: t.Optional[ProjectId] = None,
 ) -> t.List[WorkflowRun]:
-    """Get the WorkflowRun corresponding to a previous workflow run.
+    """
+    List the workflow runs, with some filters.
 
     Args:
         config: The name of the configuration to use.
         limit: Restrict the number of runs to return, prioritising the most recent.
-        prefix: Only return runs that start with the specified string.
         max_age: Only return runs younger than the specified maximum age.
         state: Only return runs of runs with the specified status.
         project_dir: The location of the project directory. This directory must
             contain the workflows database to which this run was saved. If omitted,
             the current working directory is assumed to be the project directory.
+        workspace: Only return runs from the specified workspace when using CE.
+        project: will be used to list workflows from specific workspace and project
+            when using CE.
 
     Raises:
         ConfigNameNotFoundError: when the named config is not found in the file.
+        NotImplementedError: when a filter is specified for a runtime that does not
+            support it.
 
     Returns:
         a list of WorkflowRuns
     """
+    # TODO: update docstring when platform workspace/project filtering is merged [ORQP-1479](https://zapatacomputing.atlassian.net/browse/ORQP-1479?atlOrigin=eyJpIjoiZWExMWI4MDUzYTI0NDQ0ZDg2ZTBlNzgyNjE3Njc4MDgiLCJwIjoiaiJ9) # noqa: E501
+
+    if project and not workspace:
+        raise ProjectInvalidError(
+            f"The project `{project}` cannot be uniquely identified "
+            "without a workspace parameter."
+        )
+
     _project_dir = Path(project_dir or Path.cwd())
 
     # Resolve config
-    resolved_config = _resolve_config(config)
+    resolved_config: RuntimeConfig = _resolve_config(config)
+    # If user wasn't specific with workspace and project, we might want to resolve it
+    if workspace is None and project is None:
+        if _project := resolve_studio_project_ref(
+            workspace, project, resolved_config.name
+        ):
+            workspace = _project.workspace_id
+            project = _project.project_id
 
+    # resolve runtime
     runtime = resolved_config._get_runtime(_project_dir)
 
     # Grab the "workflow runs" from the runtime.
     # Note: WorkflowRun means something else in runtime land. To avoid overloading, this
     #       import is aliased to WorkflowRunStatus in here.
     run_statuses: t.Sequence[WorkflowRunMinimal] = runtime.list_workflow_runs(
-        limit=limit, max_age=_parse_max_age(max_age), state=state
+        limit=limit,
+        max_age=_parse_max_age(max_age),
+        state=state,
+        workspace=workspace,
+        project=project,
     )
 
     # We need to convert to the public API notion of a WorkflowRun
     runs = []
     for run_status in run_statuses:
         assert run_status.workflow_def is not None
         workflow_run = WorkflowRun(
```

## orquestra/sdk/_base/_driver/_ce_runtime.py

```diff
@@ -1,10 +1,13 @@
 ################################################################################
 # Â© Copyright 2022-2023 Zapata Computing Inc.
 ################################################################################
+"""
+RuntimeInterface implementation that uses Compute Engine.
+"""
 import warnings
 from datetime import timedelta
 from pathlib import Path
 from typing import Dict, List, Optional, Sequence, Union
 
 from orquestra.sdk import Project, ProjectRef, Workspace, exceptions
 from orquestra.sdk._base import _retry, serde
@@ -12,19 +15,21 @@
 from orquestra.sdk._base.abc import RuntimeInterface
 from orquestra.sdk.kubernetes.quantity import parse_quantity
 from orquestra.sdk.schema.configs import RuntimeConfiguration
 from orquestra.sdk.schema.ir import ArtifactFormat, TaskInvocationId, WorkflowDef
 from orquestra.sdk.schema.local_database import StoredWorkflowRun
 from orquestra.sdk.schema.responses import ComputeEngineWorkflowResult, WorkflowResult
 from orquestra.sdk.schema.workflow_run import (
+    ProjectId,
     State,
     TaskRunId,
     WorkflowRun,
     WorkflowRunId,
     WorkflowRunMinimal,
+    WorkspaceId,
 )
 
 from . import _client, _exceptions, _models
 
 
 def _get_max_resources(workflow_def: WorkflowDef) -> _models.Resources:
     max_gpu = None
@@ -217,15 +222,15 @@
                 "- the authorization token was rejected by the remote cluster."
             ) from e
 
         if len(result_ids) == 0:
             wf_run = self.get_workflow_run_status(workflow_run_id)
             if wf_run.status.state == State.SUCCEEDED:
                 raise exceptions.WorkflowResultsNotReadyError(
-                    f"Workflow run `{workflow_run_id}` has succeded, but the results "
+                    f"Workflow run `{workflow_run_id}` has succeeded, but the results "
                     "are not ready yet.\n"
                     "After a workflow completes, there may be a short delay before the "
                     "results are ready to download. Please try again!"
                 )
             else:
                 raise exceptions.WorkflowRunNotSucceeded(
                     f"Workflow run `{workflow_run_id}` is in state "
@@ -343,22 +348,25 @@
 
     def list_workflow_runs(
         self,
         *,
         limit: Optional[int] = None,
         max_age: Optional[timedelta] = None,
         state: Optional[Union[State, List[State]]] = None,
+        workspace: Optional[WorkspaceId] = None,
+        project: Optional[ProjectId] = None,
     ) -> List[WorkflowRunMinimal]:
         """
         List the workflow runs, with some filters
 
         Args:
             limit: Restrict the number of runs to return, prioritising the most recent.
             max_age: Only return runs younger than the specified maximum age.
             status: Only return runs of runs with the specified status.
+            workspace: Only return runs from the specified workspace.
 
         Raises:
             UnauthorizedError: if the remote cluster rejects the token
 
         Returns:
                 A list of the workflow runs
         """
@@ -383,16 +391,20 @@
 
         page_token: Optional[str] = None
         runs: List[WorkflowRunMinimal] = []
 
         for page_size in page_sizes:
             try:
                 # TODO(ORQSDK-684): driver client cannot do filtering via API yet
+                # https://zapatacomputing.atlassian.net/browse/ORQSDK-684?atlOrigin=eyJpIjoiYmNiZjUyMjZiNzg5NDI2YWJmNGU5NzAxZDI1MmJlNzEiLCJwIjoiaiJ9 # noqa: E501
                 paginated_runs = self._client.list_workflow_runs(
-                    page_size=page_size, page_token=page_token
+                    page_size=page_size,
+                    page_token=page_token,
+                    workspace=workspace,
+                    project=project,
                 )
             except (_exceptions.InvalidTokenError, _exceptions.ForbiddenError) as e:
                 raise exceptions.UnauthorizedError(
                     "Could not get list of workflow runs "
                     "- the authorization token was rejected by the remote cluster."
                 ) from e
             page_token = paginated_runs.next_page_token
```

## orquestra/sdk/_base/_driver/_client.py

```diff
@@ -8,26 +8,31 @@
     https://github.com/zapatacomputing/workflow-driver/tree/2b3534/openapi
 """
 
 import io
 import json
 import zlib
 from tarfile import TarFile
-from typing import Generic, List, Mapping, Optional, Tuple, TypeVar, Union
+from typing import Generic, List, Mapping, Optional, TypeVar, Union
 from urllib.parse import urljoin
 
 import pydantic
 import requests
 from requests import codes
 
 from orquestra.sdk import ProjectRef
 from orquestra.sdk._ray._ray_logs import WFLog
 from orquestra.sdk.schema.ir import WorkflowDef
 from orquestra.sdk.schema.responses import ComputeEngineWorkflowResult, WorkflowResult
-from orquestra.sdk.schema.workflow_run import WorkflowRun, WorkflowRunMinimal
+from orquestra.sdk.schema.workflow_run import (
+    ProjectId,
+    WorkflowRun,
+    WorkflowRunMinimal,
+    WorkspaceId,
+)
 
 from . import _exceptions, _models
 
 API_ACTIONS = {
     # Workflow Definitions
     "create_workflow_def": "/api/workflow-definitions",
     "list_workflow_defs": "/api/workflow-definitions",
@@ -356,29 +361,34 @@
         )
 
     def list_workflow_runs(
         self,
         workflow_def_id: Optional[_models.WorkflowDefID] = None,
         page_size: Optional[int] = None,
         page_token: Optional[str] = None,
+        workspace: Optional[WorkspaceId] = None,
+        project: Optional[ProjectId] = None,
     ) -> Paginated[WorkflowRunMinimal]:
         """
         List workflow runs with a specified workflow def ID from the workflow driver
 
         Raises:
             InvalidTokenError: see the exception's docstring
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
         """
+        # Schema: https://github.com/zapatacomputing/workflow-driver/blob/fa3eb17f1132d9c7f4960331ffe7ddbd31e02f8c/openapi/src/resources/workflow-runs.yaml#L10 # noqa: E501
         resp = self._get(
             API_ACTIONS["list_workflow_runs"],
             query_params=_models.ListWorkflowRunsRequest(
                 workflowDefinitionID=workflow_def_id,
                 pageSize=page_size,
                 pageToken=page_token,
+                workspaceId=workspace,
+                projectId=project,
             ).dict(),
         )
 
         _handle_common_errors(resp)
 
         parsed_response = _models.Response[
             _models.ListWorkflowRunsResponse, _models.Pagination
```

## orquestra/sdk/_base/_driver/_models.py

```diff
@@ -9,19 +9,21 @@
 from typing import Generic, List, Mapping, Optional, TypeVar
 
 import pydantic
 from pydantic.generics import GenericModel
 
 from orquestra.sdk.schema.ir import WorkflowDef
 from orquestra.sdk.schema.workflow_run import (
+    ProjectId,
     RunStatus,
     State,
     TaskRun,
     WorkflowRun,
     WorkflowRunMinimal,
+    WorkspaceId,
 )
 
 WorkflowDefID = str
 WorkflowRunID = str
 TaskRunID = str
 TaskInvocationID = str
 WorkflowRunArtifactID = str
@@ -251,14 +253,16 @@
     Implements:
         https://github.com/zapatacomputing/workflow-driver/blob/34eba4253b56266772795a8a59d6ec7edf88c65a/openapi/src/resources/workflow-runs.yaml#L9
     """
 
     workflowDefinitionID: Optional[WorkflowDefID]
     pageSize: Optional[int]
     pageToken: Optional[str]
+    workspaceId: Optional[WorkspaceId]
+    projectId: Optional[ProjectId]
 
 
 ListWorkflowRunsResponse = List[MinimalWorkflowRunResponse]
 
 
 class GetWorkflowRunResponse(pydantic.BaseModel):
     """
```

## orquestra/sdk/_base/_qe/_qe_runtime.py

```diff
@@ -1,10 +1,13 @@
 ################################################################################
 # Â© Copyright 2022-2023 Zapata Computing Inc.
 ################################################################################
+"""
+RuntimeInterface implementation that uses QE.
+"""
 import base64
 import gzip
 import io
 import json
 import re
 import sqlite3
 import sys
@@ -34,20 +37,22 @@
     TaskInvocation,
     TaskInvocationId,
     WorkflowDef,
 )
 from orquestra.sdk.schema.local_database import StoredWorkflowRun
 from orquestra.sdk.schema.responses import WorkflowResult
 from orquestra.sdk.schema.workflow_run import (
+    ProjectId,
     RunStatus,
     State,
     TaskRun,
     TaskRunId,
     WorkflowRun,
     WorkflowRunId,
+    WorkspaceId,
 )
 
 from . import _client
 
 # From: https://pkg.go.dev/github.com/argoproj/argo/pkg/apis/workflow/v1alpha1#NodePhase
 QE_PHASE_ORQ_STATUS = {
     "Pending": State.WAITING,
@@ -831,29 +836,40 @@
 
     def list_workflow_runs(
         self,
         *,
         limit: Optional[int] = None,
         max_age: Optional[timedelta] = None,
         state: Optional[Union[State, List[State]]] = None,
+        workspace: Optional[WorkspaceId] = None,
+        project: Optional[ProjectId] = None,
     ) -> List[WorkflowRun]:
         """
         List the workflow runs, with some filters
 
         Args:
             limit: Restrict the number of runs to return, prioritising the most recent.
             max_age: Only return runs younger than the specified maximum age.
             status: Only return runs of runs with the specified status.
+            workspace: Only return runs from the specified workspace. Not supported
+                on this runtime.
 
         Raises:
             orquestra.sdk.exceptions.UnauthorizedError: if QE returns 401
+            orquestra.sdk.exceptions.WorkspacesNotSupportedError: if a workspace or
+                project is specified.
 
         Returns:
             A list of the workflow runs
         """
+        if workspace or project:
+            raise exceptions.WorkspacesNotSupportedError(
+                "Filtering by workspace or project is not supported on QE runtimes."
+            )
+
         now = datetime.now(timezone.utc)
 
         # Grab the workflows we know about from the DB
         with WorkflowDB.open_project_db(self._project_dir) as db:
             stored_runs = db.get_workflow_runs_list(
                 config_name=self._config.config_name
             )
```

## orquestra/sdk/_base/_testing/_example_wfs.py

```diff
@@ -1,12 +1,11 @@
 ################################################################################
 # Â© Copyright 2022-2023 Zapata Computing Inc.
 ################################################################################
 import time
-from pathlib import Path
 from typing import Optional, Sequence
 
 import orquestra.sdk as sdk
 import orquestra.sdk._base._testing._ipc as ipc
 
 
 @sdk.task
@@ -190,14 +189,33 @@
     in given socket appears
     """
     ipc.TriggerClient(port).wait_on_trigger(timeout)
 
     return a + b
 
 
+@sdk.task
+def long_task(*_):
+    import time
+
+    # sleep for an hour - just in case someone forgets to terminate this buddy
+    time.sleep(60 * 60)
+
+
+@sdk.workflow
+def infinite_workflow():
+    """
+    Allows reproducing scenario where tasks take some time to run.
+    This workflow is used to test termination as it will never complete
+    This workflow isn't actually infinite - it just takes an hour of sleep time to
+    complete
+    """
+    return long_task()
+
+
 @sdk.workflow
 def serial_wf_with_file_triggers(ports: Sequence[int], task_timeout: float):
     """
     Allows reproducing scenario where tasks take some time to run. Uses
     socket-based coordination.
 
     There are as many workflow graph nodes as there are `ports`. Each
@@ -278,20 +296,43 @@
 @sdk.workflow
 def wf_with_secrets():
     secret = sdk.secrets.get("some-secret", config_name="test_config_default")
     return capitalize_inline(secret)
 
 
 @sdk.workflow
-def workflow_parametrised_with_resources(cpu=None, memory=None, gpu=None):
-    return add(1, 1).with_invocation_meta(cpu=cpu, memory=memory, gpu=gpu)
+def workflow_parametrised_with_resources(
+    cpu=None, memory=None, gpu=None, custom_image=None
+):
+    future = add(1, 1)
+
+    if cpu is not None:
+        future = future.with_invocation_meta(cpu=cpu)
+    if memory is not None:
+        future = future.with_invocation_meta(memory=memory)
+    if gpu is not None:
+        future = future.with_invocation_meta(gpu=gpu)
+    if custom_image is not None:
+        future = future.with_invocation_meta(custom_image=custom_image)
+
+    return future
 
 
 @sdk.workflow
 def workflow_with_different_resources():
     cpu = add(1, 1).with_invocation_meta(cpu="5000m")
     small_cpu = add(1, 1).with_invocation_meta(cpu="1000m")
     memory = add(1, 1).with_invocation_meta(memory="3G")
     small_memory = add(1, 1).with_invocation_meta(memory="512Mi")
     gpu = add(1, 1).with_invocation_meta(gpu="1")
     all_resources = add(1, 1).with_invocation_meta(cpu="2000m", memory="2Gi", gpu="0")
     return cpu, small_cpu, memory, small_memory, gpu, all_resources
+
+
+@sdk.task(source_import=sdk.InlineImport(), n_outputs=1)
+def task_with_single_output_explicit():
+    return True
+
+
+@sdk.workflow
+def wf_with_explicit_n_outputs():
+    return task_with_single_output_explicit()
```

## orquestra/sdk/_base/cli/_dorq/_arg_resolvers.py

```diff
@@ -7,21 +7,24 @@
 resolution logic extracted as components reusable across similar CLI commands.
 """
 import typing as t
 
 from orquestra.sdk import exceptions
 from orquestra.sdk._base import _services
 from orquestra.sdk._base._config import IN_PROCESS_CONFIG_NAME
+from orquestra.sdk._base._spaces._structs import ProjectRef
 from orquestra.sdk.schema.configs import ConfigName
 from orquestra.sdk.schema.ir import TaskInvocationId
 from orquestra.sdk.schema.workflow_run import (
+    ProjectId,
     State,
     TaskRunId,
     WorkflowRun,
     WorkflowRunId,
+    WorkspaceId,
 )
 
 from . import _repos
 from ._ui import _presenters, _prompts
 
 
 def _check_for_in_process(config_names: t.Sequence[ConfigName]):
@@ -48,14 +51,46 @@
             return config
 
         # 1.2. Prompt the user.
         config_names = self._config_repo.list_config_names()
         selected_config = self._prompter.choice(config_names, message="Runtime config")
         return selected_config
 
+    def resolve_stored_config_for_login(
+        self, config: t.Optional[ConfigName]
+    ) -> ConfigName:
+        """
+        Resolve the name of a config for logging in.
+
+        This functions similarly to `resolve`, however we enforce two conditions:
+        1. The resolved config name must correspond to a stored config
+        2. The stored config must specify a URL
+        """
+        config_names = self._config_repo.list_config_names()
+        valid_configs = [
+            name
+            for name in config_names
+            if "uri" in self._config_repo.read_config(name).runtime_options.keys()
+        ]
+
+        if config is not None and config in valid_configs:
+            return config
+
+        message = "Please select a valid config"
+
+        # The user specified a config, but it doesn't exist
+        if config is not None and config not in config_names:
+            message = f"No config '{config}' found in file. " + message
+        elif config is not None and config in config_names:
+            message = (
+                f"Cannot log in with '{config}' as it relates to local runs. " + message
+            )
+
+        return self._prompter.choice(valid_configs, message=message)
+
     def resolve_multiple(
         self, configs: t.Optional[t.Sequence[str]]
     ) -> t.Sequence[ConfigName]:
         if configs is not None and len(configs) > 0:
             _check_for_in_process(configs)
             return configs
 
@@ -107,50 +142,144 @@
                 # need to ask the user for the config.
                 pass
 
         # 1.2. Prompt the user
         return ConfigResolver(self._config_repo, self._prompter).resolve(config)
 
 
+class SpacesResolver:
+    """
+    Resolve values related to the workspace / project paradigm.
+    """
+
+    def __init__(
+        self,
+        spaces=_repos.SpacesRepo(),
+        prompter=_prompts.Prompter(),
+        presenter=_presenters.PromptPresenter(),
+    ):
+        self._spaces_repo = spaces
+        self._prompter = prompter
+        self._presenter = presenter
+
+    def resolve_workspace_id(
+        self,
+        config: ConfigName,
+        workspace_id: t.Optional[WorkspaceId] = None,
+    ) -> WorkspaceId:
+        """
+        Resolve the value of the workspace ID.
+
+        If the ID hasn't been specified, prompts the user to pick from the available
+        workspaces.
+        """
+        if workspace_id is not None:
+            return workspace_id
+
+        workspaces = self._spaces_repo.list_workspaces(config)
+        labels = self._presenter.workspaces_list_to_prompt(workspaces)
+        prompt_choices = [(label, ws) for label, ws in zip(labels, workspaces)]
+        selected_id = self._prompter.choice(prompt_choices, message="Workspace")
+
+        return selected_id.workspace_id
+
+    def resolve_project_id(
+        self,
+        config: ConfigName,
+        workspace_id: WorkspaceId,
+        project_id: t.Optional[ProjectId] = None,
+        optional: bool = False,
+    ) -> t.Optional[ProjectId]:
+        """
+        Resolve the value of the Project ID.
+
+        If the ID hasn't been specified, prompts the user to pick from the available
+        projects.
+
+        If `optional` is set to True, adds an `All` option that returns `None` for the
+        ID.
+        """
+
+        if project_id is not None:
+            return project_id
+
+        projects = self._spaces_repo.list_projects(config, workspace_id)
+        labels = self._presenter.project_list_to_prompt(projects)
+        if optional:
+            projects.append(None)
+            labels.append("All")
+        prompt_choices = [(label, project) for label, project in zip(labels, projects)]
+
+        selected_id = self._prompter.choice(prompt_choices, message="Projects")
+        if selected_id is not None:
+            return selected_id.project_id
+        return None
+
+
 class WFRunResolver:
     """
     Resolves value of `wf_run_id` based on `config`.
     """
 
     def __init__(
         self,
         wf_run_repo=_repos.WorkflowRunRepo(),
         prompter=_prompts.Prompter(),
         presenter=_presenters.PromptPresenter(),
+        spaces_resolver=SpacesResolver(),
     ):
         self._wf_run_repo = wf_run_repo
         self._prompter = prompter
         self._presenter = presenter
+        self._spaces_resolver = spaces_resolver
 
     def resolve_id(
         self, wf_run_id: t.Optional[WorkflowRunId], config: ConfigName
     ) -> WorkflowRunId:
         if wf_run_id is not None:
             return wf_run_id
 
-        wfs = self._wf_run_repo.list_wf_runs(config)
+        try:
+            resolved_workspace_id = self._spaces_resolver.resolve_workspace_id(config)
+            resolved_project_id = self._spaces_resolver.resolve_project_id(
+                config, workspace_id=resolved_workspace_id
+            )
+        except exceptions.WorkspacesNotSupportedError:
+            # if run on runtime that doesn't support workspaces
+            resolved_workspace_id = None
+            resolved_project_id = None
+
+        wfs = self._wf_run_repo.list_wf_runs(
+            config, workspace=resolved_workspace_id, project=resolved_project_id
+        )
 
         wfs, tabulated_labels = self._presenter.wf_list_for_prompt(wfs)
         prompt_choices = [(label, wf.id) for label, wf in zip(tabulated_labels, wfs)]
         selected_id = self._prompter.choice(prompt_choices, message="Workflow run ID")
 
         return selected_id
 
     def resolve_run(
         self, wf_run_id: t.Optional[WorkflowRunId], config: ConfigName
     ) -> WorkflowRun:
         if wf_run_id is not None:
             return self._wf_run_repo.get_wf_by_run_id(wf_run_id, config)
 
-        runs = self._wf_run_repo.list_wf_runs(config)
+        try:
+            resolved_workspace_id = self._spaces_resolver.resolve_workspace_id(config)
+            resolved_project_id = self._spaces_resolver.resolve_project_id(
+                config, workspace_id=resolved_workspace_id
+            )
+        except exceptions.WorkspacesNotSupportedError:
+            resolved_workspace_id = None
+            resolved_project_id = None
+
+        runs = self._wf_run_repo.list_wf_runs(
+            config, workspace=resolved_workspace_id, project=resolved_project_id
+        )
 
         runs, tabulated_labels = self._presenter.wf_list_for_prompt(runs)
         prompt_choices = [(label, wf) for label, wf in zip(tabulated_labels, runs)]
 
         selected_run = self._prompter.choice(prompt_choices, message="Workflow run ID")
 
         return selected_run
```

## orquestra/sdk/_base/cli/_dorq/_entry.py

```diff
@@ -230,31 +230,37 @@
     "-l", "--limit", type=int, help="Maximum number of runs to display for each config."
 )
 @cloup.option("-t", "--max-age", help="Maximum age of runs to display.")
 @cloup.option(
     "-s",
     "--state",
     multiple=True,
-    help="State of workflow runs to display. Max be specified multiple times.",
+    help="State of workflow runs to display. May be specified multiple times.",
 )
+@WORKSPACE_OPTION
+@PROJECT_OPTION
 def list(
     config: t.Optional[str],
     interactive: t.Optional[bool] = False,
     limit: t.Optional[int] = None,
     max_age: t.Optional[str] = None,
     state: t.Optional[t.List[str]] = None,
+    workspace_id: t.Optional[str] = None,
+    project_id: t.Optional[str] = None,
 ):
     """
     Lists the available workflows
     """
 
     from ._workflow._list import Action
 
     action = Action()
-    action.on_cmd_call(config, limit, max_age, state, interactive)
+    action.on_cmd_call(
+        config, limit, max_age, state, workspace_id, project_id, interactive
+    )
 
 
 # ----------- 'orq task' commands ----------
 
 
 @dorq.group()
 def task():
@@ -376,40 +382,47 @@
 dorq.section(
     "Service Management",
     up,
     down,
     status,
 )
 
+server_config_group = cloup.OptionGroup(
+    "Server configuration", constraint=cloup.constraints.RequireExactly(1)
+)
+
 
 @dorq.command()
-@cloup.option(
-    "-s", "--server", required=True, help="server URI that you want to log into"
+@server_config_group.option(
+    "-c", "--config", required=False, help="The name of an existing configureation."
+)
+@server_config_group.option(
+    "-s", "--server", required=False, help="server URI that you want to log into"
 )
 @cloup.option(
     "-t",
     "--token",
     required=False,
     help="User Token to given server. To generate token, use this command without -t"
     "option first",
 )
 @cloup.option(
     "--ce",
     is_flag=True,
     default=False,
     help="Log in to Compute Engine. If not passed, will log in to Quantum Engine",
 )
-def login(server: str, token: t.Optional[str], ce: bool):
+def login(config: str, server: str, token: t.Optional[str], ce: bool):
     """
     Login in to remote cluster
     """
     from ._login._login import Action
 
     action = Action()
-    action.on_cmd_call(server, token, ce)
+    action.on_cmd_call(config, server, token, ce)
 
 
 def main():
     dorq()
 
 
 if __name__ == "__main__":
```

## orquestra/sdk/_base/cli/_dorq/_repos.py

```diff
@@ -17,18 +17,20 @@
 
 import requests
 
 from orquestra import sdk
 from orquestra.sdk import exceptions
 from orquestra.sdk._base import _config, _db, loader
 from orquestra.sdk._base._driver._client import DriverClient
+from orquestra.sdk._base._jwt import check_jwt_without_signature_verification
 from orquestra.sdk._base._qe import _client
+from orquestra.sdk._base._spaces._structs import ProjectRef
 from orquestra.sdk._base.abc import ArtifactValue
 from orquestra.sdk.schema import _compat
-from orquestra.sdk.schema.configs import ConfigName, RuntimeName
+from orquestra.sdk.schema.configs import ConfigName, RuntimeConfiguration, RuntimeName
 from orquestra.sdk.schema.ir import TaskInvocationId, WorkflowDef
 from orquestra.sdk.schema.workflow_run import (
     ProjectId,
     State,
     TaskRun,
     TaskRunId,
     WorkflowRun,
@@ -50,38 +52,49 @@
             orquestra.sdk.exceptions.WorkflowRunNotFoundError: when couldn't find
                 a matching record.
         """
         with _db.WorkflowDB.open_db() as db:
             stored_run = db.get_workflow_run(workflow_run_id=wf_run_id)
             return stored_run.config_name
 
-    def list_wf_run_ids(self, config: ConfigName) -> t.Sequence[WorkflowRunId]:
-        return [run.id for run in self.list_wf_runs(config)]
+    def list_wf_run_ids(
+        self, config: ConfigName, project: ProjectRef
+    ) -> t.Sequence[WorkflowRunId]:
+        return [
+            run.id
+            for run in self.list_wf_runs(
+                config, project.workspace_id, project.project_id
+            )
+        ]
 
     def list_wf_runs(
         self,
         config: ConfigName,
+        workspace: t.Optional[WorkspaceId] = None,
+        project: t.Optional[ProjectId] = None,
         limit: t.Optional[int] = None,
         max_age: t.Optional[str] = None,
         state: t.Optional[t.Union[State, t.List[State]]] = None,
     ) -> t.List[WorkflowRun]:
         """
-        Asks the runtime for all workflow runs.
+        Asks the runtime for all workflow runs that match the filters.
 
         Raises:
             ConnectionError: when connection with Ray failed.
             orquestra.sdk.exceptions.UnauthorizedError: when connection with runtime
                 failed because of an auth error.
         """
         try:
             wf_runs = sdk.list_workflow_runs(
                 config,
                 limit=limit,
                 max_age=max_age,
                 state=state,
+                workspace=workspace,
+                project=project,
             )
         except (ConnectionError, exceptions.UnauthorizedError):
             raise
 
         return [run.get_status_model() for run in wf_runs]
 
     def get_wf_by_run_id(
@@ -489,28 +502,58 @@
         return [
             config
             for config in sdk.RuntimeConfig.list_configs()
             if config not in _config.CLI_IGNORED_CONFIGS
         ]
 
     def store_token_in_config(self, uri, token, ce):
+        """
+        Saves the token in the config file
+
+        Raises:
+            ExpiredTokenError: if the token is expired
+            InvalidTokenError: if the token is not a valid format
+        """
+        check_jwt_without_signature_verification(token)
+
         runtime_name = RuntimeName.CE_REMOTE if ce else RuntimeName.QE_REMOTE
         config_name = _config.generate_config_name(runtime_name, uri)
 
         config = sdk.RuntimeConfig(
             runtime_name,
             name=config_name,
             bypass_factory_methods=True,
         )
         setattr(config, "uri", uri)
         setattr(config, "token", token)
         _config.save_or_update(config_name, runtime_name, config._get_runtime_options())
 
         return config_name
 
+    def read_config(self, config: ConfigName) -> RuntimeConfiguration:
+        """
+        Read a stored config.
+        """
+        return _config.read_config(config)
+
+
+class SpacesRepo:
+    """
+    Wraps access to workspaces and projects
+    """
+
+    def list_workspaces(
+        self,
+        config: ConfigName,
+    ):
+        return sdk.list_workspaces(config)
+
+    def list_projects(self, config: ConfigName, workspace_id):
+        return sdk.list_projects(config, workspace_id)
+
 
 class RuntimeRepo:
     """
     Wraps access to QE/CE clients
     """
 
     def get_login_url(self, uri: str, ce: bool, redirect_port: int):
```

## orquestra/sdk/_base/cli/_dorq/_login/_login.py

```diff
@@ -5,16 +5,19 @@
 Code for 'orq login'.
 """
 import asyncio
 import typing as t
 
 from aiohttp import web
 
-from .. import _repos
-from .._ui import _presenters
+from orquestra.sdk.exceptions import LocalConfigLoginError, UserCancelledPrompt
+from orquestra.sdk.schema.configs import RuntimeName
+
+from .. import _arg_resolvers, _repos
+from .._ui import _presenters, _prompts
 from ._login_server import LoginServer
 
 
 class Action:
     """
     Encapsulates app-related logic for handling `orq login`.
     """
@@ -22,45 +25,96 @@
     def __init__(
         self,
         exception_presenter=_presenters.WrappedCorqOutputPresenter(),
         login_presenter=_presenters.LoginPresenter(),
         config_repo=_repos.ConfigRepo(),
         runtime_repo=_repos.RuntimeRepo(),
         login_server=LoginServer(),
+        config_resolver=_arg_resolvers.ConfigResolver(),
+        prompter=_prompts.Prompter(),
     ):
         # presenters
         self._exception_presenter: _presenters.WrappedCorqOutputPresenter = (
             exception_presenter
         )
         self._login_presenter: _presenters.LoginPresenter = login_presenter
+        self._prompter: _prompts.Prompter = prompter
 
         # data sources
         self._config_repo: _repos.ConfigRepo = config_repo
         self._runtime_repo: _repos.RuntimeRepo = runtime_repo
         self._login_server: LoginServer = login_server
+        self._config_resolver: _arg_resolvers.ConfigResolver = config_resolver
 
-    def on_cmd_call(self, url: str, token: t.Optional[str], ce: bool):
+    def on_cmd_call(
+        self,
+        config: t.Optional[str],
+        url: t.Optional[str],
+        token: t.Optional[str],
+        ce: bool,
+    ):
+        """
+        Call the login command action, catching any exceptions that arise.
+        """
         try:
-            self._on_cmd_call_with_exceptions(url, token, ce)
+            self._on_cmd_call_with_exceptions(config, url, token, ce)
         except Exception as e:
             self._exception_presenter.show_error(e)
 
     def _on_cmd_call_with_exceptions(
         self,
-        url: str,
+        config: t.Optional[str],
+        url: t.Optional[str],
         token: t.Optional[str],
         ce: bool,
     ):
         """
         Implementation of the command action. Doesn't catch exceptions.
         """
+        assert bool(config) ^ bool(url), (
+            "orq login action was called with arguments "
+            f"'config = {config}, url = {url}'. "
+            "Exactly one of these arguments must be provided, but this constraint "
+            "should have been handled at CLI entry."
+        )
+
+        _url: str
+        if config:
+            loaded_config = self._config_repo.read_config(
+                self._config_resolver.resolve_stored_config_for_login(config)
+            )
+            try:
+                _url = loaded_config.runtime_options["uri"]
+            except KeyError as e:
+                raise LocalConfigLoginError(
+                    f"Cannot log in with '{loaded_config.config_name}' "
+                    "as this config does not include a server URL. "
+                    "It is likely that this config is for local execution, "
+                    "and therefore can be used without logging in."
+                ) from e
+
+            # If the CLI disagrees with the stored config about which runtime to use,
+            # prompt the user to agree to changing the config to match the cli args.
+            # TODO: This can be reworked once we have a --qe flag.
+            if ce != (loaded_config.runtime_name == RuntimeName.CE_REMOTE):
+                if not self._prompter.confirm(
+                    f"Config '{loaded_config.config_name}' will be changed from "
+                    f"{loaded_config.runtime_name} to "
+                    f"{RuntimeName.CE_REMOTE if ce else RuntimeName.QE_REMOTE}. "
+                    "Continue?",
+                    True,
+                ):
+                    raise UserCancelledPrompt()
+
+        _url = url or _url
+
         if token is None:
-            self._prompt_for_login(url, ce)
+            self._prompt_for_login(_url, ce)
         else:
-            self._save_token(url, token, ce)
+            self._save_token(_url, token, ce)
 
     def _prompt_for_login(self, url: str, ce: bool):
         try:
             asyncio.run(self._get_token_from_server(url, ce, 60))
         except (web.GracefulExit, KeyboardInterrupt):
             pass
         if self._login_server.token is None:
```

## orquestra/sdk/_base/cli/_dorq/_services/_up.py

```diff
@@ -1,10 +1,11 @@
 ################################################################################
 # Â© Copyright 2023 Zapata Computing Inc.
 ################################################################################
+import subprocess
 import sys
 from typing import Optional
 
 from orquestra.sdk.schema.responses import ResponseStatusCode, ServiceResponse
 
 from .. import _arg_resolvers
 from .._ui import _presenters
@@ -36,33 +37,45 @@
         manage_ray: Optional[bool],
         manage_all: Optional[bool],
     ):
         resolved_services = self._service_resolver.resolve(
             manage_ray=manage_ray, manage_all=manage_all
         )
 
-        services = []
+        responses = []
         success = True
 
         with self._presenter.show_progress(
             resolved_services, label="Starting"
         ) as progress:
             for service in progress:
                 try:
                     service.up()
-                    services.append(
+
+                    responses.append(
                         ServiceResponse(
                             name=service.name, is_running=True, info="Started!"
                         )
                     )
-                except RuntimeError as e:
+                except subprocess.CalledProcessError as e:
                     success = False
-                    services.append(
+                    responses.append(
                         ServiceResponse(
-                            name=service.name, is_running=False, info=str(e)
+                            name=service.name,
+                            is_running=False,
+                            info="\n".join(
+                                [
+                                    "command:",
+                                    str(e.cmd),
+                                    "stdout:",
+                                    *e.stdout.decode().splitlines(),
+                                    "stderr:",
+                                    *e.stderr.decode().splitlines(),
+                                ]
+                            ),
                         )
                     )
 
-        self._presenter.show_services(services=services)
-
-        if not success:
-            sys.exit(ResponseStatusCode.SERVICES_ERROR.value)
+        if success:
+            self._presenter.show_services(responses)
+        else:
+            self._presenter.show_failure(responses)
```

## orquestra/sdk/_base/cli/_dorq/_ui/_errors.py

```diff
@@ -84,14 +84,24 @@
         "This action only works with finished workflows. However, the selected run "
         f"is {e.state.name}."
     )
     return ResponseStatusCode.INVALID_WORKFLOW_RUN
 
 
 @pretty_print_exception.register
+def _(e: exceptions.RayNotRunningError) -> ResponseStatusCode:
+    click.echo(
+        "Could not find any running Ray instance. "
+        "You can use 'orq status' to check the status of the ray service. "
+        "If it is not running, it can be started with the `orq up` command."
+    )
+    return ResponseStatusCode.CONNECTION_ERROR
+
+
+@pretty_print_exception.register
 def _(e: ConnectionError) -> ResponseStatusCode:
     _print_traceback(e)
     click.echo(f"{e}")
     return ResponseStatusCode.CONNECTION_ERROR
 
 
 @pretty_print_exception.register
@@ -118,7 +128,39 @@
             "persisted.\n\nYou may want to:\n"
             ' - Use the Python API to debug workflows with the "{0}" runtime.\n'
             ' - Try the "{1}" runtime if you want to run a workflow locally via'
             " the CLI."
         ).format(IN_PROCESS_CONFIG_NAME, RAY_CONFIG_NAME_ALIAS),
     )
     return ResponseStatusCode.USER_CANCELLED
+
+
+@pretty_print_exception.register
+def _(e: exceptions.ConfigNameNotFoundError) -> ResponseStatusCode:
+    _print_traceback(e)
+    click.echo(e.message)
+    return ResponseStatusCode.NOT_FOUND
+
+
+@pretty_print_exception.register
+def _(e: exceptions.NoOptionsAvailableError) -> ResponseStatusCode:
+    _print_traceback(e)
+    click.echo(f"{e.message}:\nNo options are available.")
+    return ResponseStatusCode.NOT_FOUND
+
+
+@pretty_print_exception.register
+def _(e: exceptions.LocalConfigLoginError) -> ResponseStatusCode:
+    click.echo(e.message)
+    return ResponseStatusCode.INVALID_CLI_COMMAND_ERROR
+
+
+@pretty_print_exception.register
+def _(e: exceptions.InvalidTokenError) -> ResponseStatusCode:
+    click.echo("The auth token is not valid.\n" "Please try logging in again.")
+    return ResponseStatusCode.UNAUTHORIZED
+
+
+@pretty_print_exception.register
+def _(e: exceptions.ExpiredTokenError) -> ResponseStatusCode:
+    click.echo("The auth token has expired.\n" "Please try logging in again.")
+    return ResponseStatusCode.UNAUTHORIZED
```

## orquestra/sdk/_base/cli/_dorq/_ui/_presenters.py

```diff
@@ -8,15 +8,15 @@
 import pprint
 import sys
 import typing as t
 import webbrowser
 from contextlib import contextmanager
 from datetime import datetime, timezone
 from pathlib import Path
-from typing import Iterable, Iterator, List
+from typing import Iterable, Iterator, List, Sequence
 
 import click
 from tabulate import tabulate
 
 from orquestra.sdk._base import _services, serde
 from orquestra.sdk.schema import responses
 from orquestra.sdk.schema.ir import ArtifactFormat
@@ -150,15 +150,15 @@
 
         click.echo(f"Artifact saved at {dump_details.file_path} " f"as {format_name}.")
 
 
 class ServicePresenter:
     @contextmanager
     def show_progress(
-        self, services: List[_services.Service], *, label: str
+        self, services: Sequence[_services.Service], *, label: str
     ) -> Iterator[Iterable[_services.Service]]:
         """
         Starts a progress bar on the context enter.
 
         Yields an iterable of services; when you iterate over it, the progress bar is
         advanced.
         """
@@ -167,15 +167,15 @@
             show_eta=False,
             item_show_func=lambda svc: f"{label} {svc.name}"
             if svc is not None
             else None,
         ) as bar:
             yield bar
 
-    def show_services(self, services: List[responses.ServiceResponse]):
+    def show_services(self, services: Sequence[responses.ServiceResponse]):
         click.echo(
             tabulate(
                 [
                     [
                         click.style(svc.name, bold=True),
                         click.style("Running", fg="green")
                         if svc.is_running
@@ -185,14 +185,19 @@
                     for svc in services
                 ],
                 colalign=("right",),
                 tablefmt="plain",
             ),
         )
 
+    def show_failure(self, service_responses: Sequence[responses.ServiceResponse]):
+        self.show_services(service_responses)
+
+        sys.exit(responses.ResponseStatusCode.SERVICES_ERROR.value)
+
 
 class LoginPresenter:
     def prompt_for_login(self, login_url, url, ce):
         click.echo("We were unable to automatically log you in.")
         click.echo("Please login to your Orquestra account using the following URL.")
         click.echo(login_url)
         click.echo(
@@ -292,7 +297,25 @@
             reverse=True,
         )
 
         labels = [[wf.id, _format_datetime(wf.status.start_time)] for wf in wfs]
         tabulated_labels = tabulate(labels, tablefmt="plain").split("\n")
 
         return wfs, tabulated_labels
+
+    def workspaces_list_to_prompt(self, workspaces):
+        # Create labels of workspaces that are printed by prompter
+        # Label is <display_name> <id> tabulated nicely to create good-looking
+        # table
+        labels = [[ws.name, ws.workspace_id] for ws in workspaces]
+        tabulated_labels = tabulate(labels, tablefmt="plain").split("\n")
+
+        return tabulated_labels
+
+    def project_list_to_prompt(self, projects):
+        # Create labels of projects that are printed by prompter
+        # Label is <display_name> <id> tabulated nicely to create good-looking
+        # table
+        labels = [[ws.name, ws.project_id] for ws in projects]
+        tabulated_labels = tabulate(labels, tablefmt="plain").split("\n")
+
+        return tabulated_labels
```

## orquestra/sdk/_base/cli/_dorq/_ui/_prompts.py

```diff
@@ -73,36 +73,22 @@
         Returns:
             The item the user chose, either a ChoiceID or an object if ``choices`` was
             a tuple.
 
         Raises:
             UserCancelledPrompt if the user cancels the prompt
         """
+        # If there are no choices, report it to the user and exit.
+        if len(choices) == 0:
+            raise exceptions.NoOptionsAvailableError(message)
 
         # If there's only one choice, select it automatically and confirm with the user
         # that that's what they want to do.
         if len(choices) == 1:
-            name: ChoiceID
-            value: t.Union[ChoiceID, T]
-            # When the choice is a tuple, we unpack the display
-            # name and the returned value.
-            # Otherwise, the choice is a ChoiceID and should be
-            # used as both the display name and the returned
-            # value.
-            if isinstance(choices[0], tuple):
-                name, value = choices[0]
-            else:
-                name, value = choices[0], choices[0]
-
-            if not self.confirm(
-                f"{message} - only one option is available. Proceed with {name}?",
-                default=True,
-            ):
-                raise exceptions.UserCancelledPrompt(f"User cancelled {message} prompt")
-            return value
+            return self._handle_single_option(message, choices[0])
 
         question = inquirer.List(
             SINGLE_INPUT,
             message=message,
             choices=choices,
             default=default,
             carousel=True,
@@ -178,14 +164,25 @@
         Returns:
             The list of items the user chose, either ChoiceIDs or objects if
             ``choices`` was a tuple.
 
         Raises:
             UserCancelledPrompt if the user cancels the prompt
         """
+        # If there are no choices, report it to the user and exit.
+        if len(choices) == 0:
+            raise exceptions.NoOptionsAvailableError(message)
+
+        # If there's only one choice, select it automatically and confirm with the user
+        # that that's what they want to do.
+        if len(choices) == 1:
+            return t.cast(
+                t.Union[t.List[ChoiceID], t.List[T]],
+                [self._handle_single_option(message, choices[0])],
+            )
 
         question = inquirer.Checkbox(
             SINGLE_INPUT,
             message=message
             + " (select: \u2192 | deselect: \u2190 | navigate: \u2191, \u2193)",
             choices=choices,
             default=default,
@@ -290,7 +287,30 @@
             raise exceptions.UserCancelledPrompt(f"User cancelled {message} prompt")
 
         # If the user enters one of the strings representing `None`, return None.
         if answers[SINGLE_INPUT] in nonestrings:
             return None
 
         return answers[SINGLE_INPUT]
+
+    def _handle_single_option(
+        self, message: str, choice: t.Union[ChoiceID, t.Tuple[ChoiceID, T]]
+    ) -> t.Union[ChoiceID, T]:
+        """
+        Rather than ask the user to choose between 1 option, prompt for confirmation.
+        """
+        name: ChoiceID
+        value: t.Union[ChoiceID, T]
+        # When the choice is a tuple, we unpack the display name and the returned value.
+        # Otherwise, the choice is a ChoiceID and should be used as both the display
+        # name and the returned value.
+        if isinstance(choice, tuple):
+            name, value = choice
+        else:
+            name, value = choice, choice
+
+        if not self.confirm(
+            f"{message} - only one option is available. Proceed with {name}?",
+            default=True,
+        ):
+            raise exceptions.UserCancelledPrompt(f"User cancelled {message} prompt")
+        return value
```

## orquestra/sdk/_base/cli/_dorq/_workflow/_list.py

```diff
@@ -2,45 +2,48 @@
 # Â© Copyright 2022 Zapata Computing Inc.
 ################################################################################
 """
 Code for 'orq workflow list'.
 """
 import typing as t
 
+from orquestra.sdk import exceptions as exceptions
 from orquestra.sdk.schema.configs import ConfigName
-from orquestra.sdk.schema.workflow_run import WorkflowRun
+from orquestra.sdk.schema.workflow_run import ProjectId, WorkflowRun, WorkspaceId
 
 from .. import _arg_resolvers, _repos
 from .._ui import _presenters
 
 
 class Action:
     """
-    Encapsulates app-related logic for handling ``orq workflow view``.
+    Encapsulates app-related logic for handling ``orq workflow list``.
     It's the glue code that connects resolving missing arguments, reading data, and
     presenting the results back to the user.
 
     The module is considered part of the name, so this class should be read as
     ``_dorq._workflow._list.Action``.
     """
 
     def __init__(
         self,
         presenter=_presenters.WFRunPresenter(),
         error_presenter=_presenters.WrappedCorqOutputPresenter(),
         summary_repo=_repos.SummaryRepo(),
         wf_run_repo=_repos.WorkflowRunRepo(),
+        spaces_resolver: t.Optional[_arg_resolvers.SpacesResolver] = None,
         config_resolver: t.Optional[_arg_resolvers.ConfigResolver] = None,
         wf_run_filter_resolver: t.Optional[_arg_resolvers.WFRunFilterResolver] = None,
     ):
         # data sources
         self._wf_run_repo = wf_run_repo
 
         # arg resolvers
         self._config_resolver = config_resolver or _arg_resolvers.ConfigResolver()
+        self._spaces_resolver = spaces_resolver or _arg_resolvers.SpacesResolver()
         self._wf_run_filter_resolver = (
             wf_run_filter_resolver or _arg_resolvers.WFRunFilterResolver()
         )
 
         self._summary_repo = summary_repo
         # text IO
         self._presenter = presenter
@@ -48,33 +51,39 @@
 
     def on_cmd_call(
         self,
         config: t.Optional[t.Sequence[str]],
         limit: t.Optional[int],
         max_age: t.Optional[str],
         state: t.Optional[t.List[str]],
+        workspace_id: t.Optional[str],
+        project_id: t.Optional[str],
         interactive: t.Optional[bool] = False,
     ):
         try:
             self._on_cmd_call_with_exceptions(
                 config=config,
                 limit=limit,
                 max_age=max_age,
                 state=state,
+                workspace_id=workspace_id,
+                project_id=project_id,
                 interactive=interactive,
             )
         except Exception as e:
             self._error_presenter.show_error(e)
 
     def _on_cmd_call_with_exceptions(
         self,
         config: t.Optional[t.Sequence[str]],
         limit: t.Optional[int],
         max_age: t.Optional[str],
         state: t.Optional[t.List[str]],
+        workspace_id: t.Optional[str],
+        project_id: t.Optional[str],
         interactive: t.Optional[bool] = False,
     ):
         # Resolve Arguments
         resolved_configs: t.Sequence[
             ConfigName
         ] = self._config_resolver.resolve_multiple(config)
         resolved_limit = self._wf_run_filter_resolver.resolve_limit(
@@ -85,18 +94,42 @@
         )
         resolved_state = self._wf_run_filter_resolver.resolve_state(
             state, interactive=interactive
         )
 
         # Get wf runs for each config
         wf_runs: t.List[WorkflowRun] = []
-
         for resolved_config in resolved_configs:
+            # Resolve Workspace and Project for this config
+            workspace: t.Optional[WorkspaceId] = None
+            project: t.Optional[ProjectId] = None
+
+            # If nethier workspace or project are specified, leave both as None.
+            if workspace_id or project_id:
+                try:
+                    workspace = self._spaces_resolver.resolve_workspace_id(
+                        resolved_config, workspace_id
+                    )
+                    project = self._spaces_resolver.resolve_project_id(
+                        resolved_config, workspace, project_id, optional=True
+                    )
+                except exceptions.WorkspacesNotSupportedError:
+                    # if handling on the runtime that doesn't support workspaces and
+                    # projects - project and workspace are already set to None, so
+                    # nothing to do.
+                    assert project is None and workspace is None, (
+                        "The project and workspace resolvers disagree about whether "
+                        "spaces are supported. Please report this as a bug."
+                    )
+                    pass
+
             wf_runs += self._wf_run_repo.list_wf_runs(
                 resolved_config,
+                project=project,
+                workspace=workspace,
                 limit=resolved_limit,
                 max_age=resolved_max_age,
                 state=resolved_state,
             )
 
         summary = self._summary_repo.wf_list_summary(wf_runs)
         # Display to the user
```

## orquestra/sdk/_ray/_build_workflow.py

```diff
@@ -1,24 +1,35 @@
+################################################################################
+# Â© Copyright 2023 Zapata Computing Inc.
+################################################################################
+"""
+Translates IR workflow def into a Ray workflow.
+"""
 import os
 import traceback
 import typing as t
 from functools import singledispatch
 from pathlib import Path
 
 from typing_extensions import assert_never
 
 from .. import exceptions, secrets
 from .._base import _exec_ctx, _git_url_utils, _graphs, _log_adapter, dispatch, serde
-from .._base._env import RAY_DOWNLOAD_GIT_IMPORTS_ENV
+from .._base._env import (
+    RAY_DOWNLOAD_GIT_IMPORTS_ENV,
+    RAY_SET_CUSTOM_IMAGE_RESOURCES_ENV,
+)
 from ..kubernetes.quantity import parse_quantity
 from ..schema import _compat, ir, responses, workflow_run
 from . import _client, _id_gen
 from ._client import RayClient
 from ._wf_metadata import InvUserMetadata, pydatic_to_json_dict
 
+DEFAULT_IMAGE_TEMPLATE = "hub.nexus.orquestra.io/zapatacomputing/orquestra-sdk-base:{}"
+
 
 def _arg_from_graph(argument_id: ir.ArgumentId, workflow_def: ir.WorkflowDef):
     try:
         return workflow_def.constant_nodes[argument_id]
     except KeyError:
         pass
 
@@ -144,15 +155,15 @@
     ray_options: t.Mapping,
     ray_args: t.Iterable[t.Any],
     ray_kwargs: t.Mapping[str, t.Any],
     args_artifact_nodes: t.Mapping,
     kwargs_artifact_nodes: t.Mapping,
     n_outputs: t.Optional[int],
     project_dir: t.Optional[Path],
-    user_fn_ref: t.Optional[ir.FunctionRef] = None,
+    user_fn_ref: t.Optional[ir.FunctionRef],
 ) -> _client.FunctionNode:
     """
     Prepares a Ray task that fits a single ir.TaskInvocation. The result is a
     node in a Ray DAG.
 
     Args:
         client: Ray API facade
@@ -184,17 +195,17 @@
         wrapped = ArgumentUnwrapper(
             user_fn=user_fn,
             args_artifact_nodes=args_artifact_nodes,
             kwargs_artifact_nodes=kwargs_artifact_nodes,
             deserialize=serialization,
         )
 
-        logger = _log_adapter.workflow_logger()
-        try:
-            with _exec_ctx.ray():
+        with _exec_ctx.ray():
+            logger = _log_adapter.workflow_logger()
+            try:
                 wrapped_return = wrapped(*inner_args, **inner_kwargs)
 
                 packed: responses.WorkflowResult = (
                     serde.result_from_artifact(wrapped_return, ir.ArtifactFormat.AUTO)
                     if serialization
                     else wrapped_return
                 )
@@ -212,21 +223,21 @@
                 else:
                     unpacked = (packed,)
 
                 return TaskResult(
                     packed=packed,
                     unpacked=unpacked,
                 )
-        except Exception as e:
-            # Log the stacktrace as a single log line.
-            logger.exception(traceback.format_exc())
-
-            # We need to stop further execution of this workflow. If we don't raise, Ray
-            # will think the task succeeded with a return value `None`.
-            raise e
+            except Exception as e:
+                # Log the stacktrace as a single log line.
+                logger.exception(traceback.format_exc())
+
+                # We need to stop further execution of this workflow. If we don't
+                # raise, Ray will think the task succeeded with a return value `None`.
+                raise e
 
     named_remote = client.add_options(_ray_remote, **ray_options)
     dag_node = named_remote.bind(*ray_args, **ray_kwargs)
 
     return dag_node
 
 
@@ -306,14 +317,24 @@
         else:
             ray_kwargs[name] = ir_node
             ray_kwargs_artifact_nodes[name] = None
 
     return ray_kwargs, ray_kwargs_artifact_nodes
 
 
+def _ray_resources_for_custom_image(image_name: str) -> t.Mapping[str, float]:
+    """
+    Custom Ray resources we set to power running Orquestra tasks on custom Docker
+    images. The values are coupled with Compute Engine server-side set up.
+    """
+    # The format for custom image strings is described in the ADR:
+    # https://zapatacomputing.atlassian.net/wiki/spaces/ORQSRUN/pages/688259073/2023-05-05+Ray+resources+syntax+for+custom+images
+    return {f"image:{image_name}": 1}
+
+
 def make_ray_dag(
     client: RayClient,
     workflow_def: ir.WorkflowDef,
     workflow_run_id: workflow_run.WorkflowRunId,
     project_dir: t.Optional[Path] = None,
 ):
     # a mapping of "artifact ID" <-> "the ray Future needed to get the value"
@@ -353,15 +374,30 @@
             # By default, Ray will only retry tasks that fail due to a "system error".
             # For example, if the worker process crashes or exits early.
             # Normal Python exceptions are NOT retried.
             # So, we turn max_retries down to 0.
             "max_retries": 0,
         }
 
-        # Task resources
+        # Set custom image
+        if os.getenv(RAY_SET_CUSTOM_IMAGE_RESOURCES_ENV) is not None:
+            # This makes an assumption that only "new" IRs will get to this point
+            assert workflow_def.metadata is not None, "Expected a >=0.45.0 IR"
+            sdk_version = workflow_def.metadata.sdk_version.original
+
+            # Custom "Ray resources" request. The entries need to correspond to the ones
+            # used when starting the Ray cluster. See also:
+            # https://docs.ray.io/en/latest/ray-core/scheduling/resources.html#custom-resources
+            ray_options["resources"] = _ray_resources_for_custom_image(
+                invocation.custom_image
+                or user_task.custom_image
+                or DEFAULT_IMAGE_TEMPLATE.format(sdk_version)
+            )
+
+        # Non-custom task resources
         if invocation.resources is not None:
             if invocation.resources.cpu is not None:
                 cpu = parse_quantity(invocation.resources.cpu)
                 cpu_int = cpu.to_integral_value()
                 ray_options["num_cpus"] = int(cpu_int) if cpu == cpu_int else float(cpu)
             if invocation.resources.memory is not None:
                 memory = parse_quantity(invocation.resources.memory)
@@ -401,21 +437,25 @@
             "name": None,
             "metadata": None,
             "runtime_env": None,
             "catch_exceptions": True,
             # Set to avoid retrying when the worker crashes.
             # See the comment with the invocation's options for more details.
             "max_retries": 0,
+            # Custom "Ray resources" request. We don't need any for the aggregation
+            # step.
+            "resources": None,
         },
         ray_args=pos_args,
         ray_kwargs={},
         args_artifact_nodes=pos_args_artifact_nodes,
         kwargs_artifact_nodes={},
         n_outputs=len(pos_args),
         project_dir=None,
+        user_fn_ref=None,
     )
 
     # Data aggregation step is run with catch_exceptions=True - so it returns tuple of
     # return value and Exception. Here the exception is caught and rethrown in more
     # user-friendly fashion
     @client.remote
     def handle_data_aggregation_error(result: t.Tuple[t.Any, Exception]):
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## orquestra/sdk/_ray/_client.py

```diff
@@ -87,37 +87,42 @@
             ray_remote_fn,
             *,
             name: str,
             metadata: t.Dict[str, t.Any],
             runtime_env: t.Optional[RuntimeEnv],
             catch_exceptions: t.Optional[bool],
             max_retries: int,
+            resources: t.Optional[t.Mapping[str, float]] = None,
             num_cpus: t.Optional[t.Union[int, float]] = None,
             num_gpus: t.Optional[t.Union[int, float]] = None,
             memory: t.Optional[t.Union[int, float]] = None,
         ):
             # The type hint for 'ray.workflow.options' kwargs is invalid. We can
             # work it around by Any.
             workflow_opts: t.Any = {
                 "task_id": name,
                 "metadata": metadata,
                 "catch_exceptions": catch_exceptions,
             }
-            ray_optional_opts = {}
+
+            ray_optional_kwargs: t.Dict[str, t.Any] = {}
             if num_cpus is not None:
-                ray_optional_opts["num_cpus"] = num_cpus
+                ray_optional_kwargs["num_cpus"] = num_cpus
             if num_gpus is not None:
-                ray_optional_opts["num_gpus"] = num_gpus
+                ray_optional_kwargs["num_gpus"] = num_gpus
             if memory is not None:
-                ray_optional_opts["memory"] = memory
+                ray_optional_kwargs["memory"] = memory
+            if resources is not None:
+                ray_optional_kwargs["resources"] = resources
+
             return ray_remote_fn.options(
                 **ray.workflow.options(**workflow_opts),
                 runtime_env=runtime_env,
                 max_retries=max_retries,
-                **ray_optional_opts,
+                **ray_optional_kwargs,
             )
 
         # ----- Ray Workflow -----
 
         def workflow_init(self):
             ray.workflow.init()
```

## orquestra/sdk/_ray/_dag.py

```diff
@@ -21,26 +21,28 @@
 from orquestra.sdk.schema.responses import WorkflowResult
 
 from .. import exceptions
 from .._base import _services, serde
 from .._base._db import WorkflowDB
 from .._base._env import RAY_GLOBAL_WF_RUN_ID_ENV
 from .._base._spaces._structs import ProjectRef
-from .._base.abc import ArtifactValue, LogReader, RuntimeInterface
+from .._base.abc import LogReader, RuntimeInterface
 from ..schema import ir
 from ..schema.configs import RuntimeConfiguration
 from ..schema.local_database import StoredWorkflowRun
 from ..schema.workflow_run import (
+    ProjectId,
     RunStatus,
     State,
     TaskInvocationId,
     TaskRun,
     TaskRunId,
     WorkflowRun,
     WorkflowRunId,
+    WorkspaceId,
 )
 from . import _client, _id_gen, _ray_logs
 from ._build_workflow import TaskResult, make_ray_dag
 from ._client import RayClient
 from ._wf_metadata import InvUserMetadata, WfUserMetadata, pydatic_to_json_dict
 
 
@@ -236,15 +238,18 @@
 
         # Turn off internal Ray logs, unless there is an error
         # If Ray is set to configure logging, this will be overridden
         logger = logging.getLogger("ray")
         logger.setLevel(logging.ERROR)
 
         client = RayClient()
-        client.init(**dataclasses.asdict(ray_params))
+        try:
+            client.init(**dataclasses.asdict(ray_params))
+        except ConnectionError as e:
+            raise exceptions.RayNotRunningError from e
 
         try:
             client.workflow_init()
         except ValueError as e:
             message = (
                 "This is likely due to a race condition in starting the local "
                 "runtime. Please try again."
@@ -280,31 +285,33 @@
                 "Project and workspace IDs will be ignored.",
                 category=exceptions.UnsupportedRuntimeFeature,
             )
 
         global_run_id = os.getenv(RAY_GLOBAL_WF_RUN_ID_ENV)
         wf_run_id = global_run_id or _generate_wf_run_id(workflow_def)
 
-        # dag = make_ray_dag(self._client, workflow_def, wf_run_id, self._project_dir)
-        dag = make_ray_dag(self._client, workflow_def, wf_run_id)
+        dag = make_ray_dag(
+            self._client,
+            workflow_def=workflow_def,
+            workflow_run_id=wf_run_id,
+            project_dir=self._project_dir,
+        )
         wf_user_metadata = WfUserMetadata(workflow_def=workflow_def)
 
         # Unfortunately, Ray doesn't validate uniqueness of workflow IDs. Let's
         # hope we won't get a collision.
         _ = self._client.run_dag_async(
             dag,
             workflow_id=wf_run_id,
             metadata=pydatic_to_json_dict(wf_user_metadata),
         )
 
-        config_name: str
-        config_name = self._config.config_name
         wf_run = StoredWorkflowRun(
             workflow_run_id=wf_run_id,
-            config_name=config_name,
+            config_name=self._config.config_name,
             workflow_def=workflow_def,
         )
         with WorkflowDB.open_project_db(self._project_dir) as db:
             db.save_workflow_run(wf_run)
 
         return wf_run_id
 
@@ -476,26 +483,37 @@
 
     def list_workflow_runs(
         self,
         *,
         limit: t.Optional[int] = None,
         max_age: t.Optional[timedelta] = None,
         state: t.Optional[t.Union[State, t.List[State]]] = None,
+        workspace: t.Optional[WorkspaceId] = None,
+        project: t.Optional[ProjectId] = None,
     ) -> t.List[WorkflowRun]:
         """
         List the workflow runs, with some filters
 
         Args:
             limit: Restrict the number of runs to return, prioritising the most recent.
             max_age: Only return runs younger than the specified maximum age.
             state: Only return runs of runs with the specified status.
+            workspace: Only return runs from the specified workspace. Not supported
+                on this runtime.
 
         Returns:
                 A list of the workflow runs
+
+        Raises:
+            WorkspacesNotSupportedError: when a workspace or project is specified.
         """
+        if workspace or project:
+            raise exceptions.WorkspacesNotSupportedError(
+                "Filtering by workspace or project is not supported on Ray runtimes."
+            )
         now = datetime.now(timezone.utc)
 
         if state is not None:
             if not isinstance(state, list):
                 state_list = [state]
             else:
                 state_list = state
```

## orquestra/sdk/secrets/_api.py

```diff
@@ -7,24 +7,34 @@
 import typing as t
 
 from .. import exceptions as sdk_exc
 from .._base import _dsl, _exec_ctx
 from . import _auth, _exceptions, _models
 
 
+def _translate_to_zri(workspace_id: str, secret_name: str) -> str:
+    """
+    Create ZRI from workspace_id and secret_name
+    """
+    return f"zri:v1::0:{workspace_id}:secret:{secret_name}"
+
+
 def get(
     name: str,
     *,
+    workspace_id: t.Optional[str] = None,
     config_name: t.Optional[str] = None,
 ) -> str:
     """
     Retrieves secret value from the remote vault.
 
     Args:
         name: secret identifier.
+        workspace_id: ID of the workspace. Using platform-defined default if omitted -
+            - currently it is personal workspace
         config_name: config entry to use to communicate with Orquestra Platform.
             Required when used from a local machine. Ignored when
             ORQUESTRA_PASSPORT_FILE env variable is set.
 
     Raises:
         orquestra.sdk.exceptions.ConfigNameNotFoundError: when no matching config was
             found.
@@ -44,31 +54,37 @@
         return t.cast(str, _dsl.Secret(name=name, config_name=config_name))
 
     try:
         client = _auth.authorized_client(config_name)
     except sdk_exc.ConfigNameNotFoundError:
         raise
 
+    if workspace_id:
+        name = _translate_to_zri(workspace_id, name)
+
     try:
         return client.get_secret(name).value
     # explicit rethrows of known errors
     except _exceptions.InvalidTokenError as e:
         raise sdk_exc.UnauthorizedError() from e
     except _exceptions.SecretNotFoundError as e:
         raise sdk_exc.NotFoundError(f"Couldn't find secret named {name}") from e
 
 
 def list(
     *,
+    workspace_id: t.Optional[str] = None,
     config_name: t.Optional[str] = None,
 ) -> t.Sequence[str]:
     """
     Lists all secret names.
 
     Args:
+        workspace_id: ID of the workspace. Using platform-defined default if omitted -
+            - currently it is personal workspace
         config_name: config entry to use to communicate with Orquestra Platform.
             Required when used from a local machine. Ignored when
             ORQUESTRA_PASSPORT_FILE env variable is set.
 
     Raises:
         orquestra.sdk.exceptions.ConfigNameNotFoundError: when no matching config was
             found.
@@ -79,32 +95,35 @@
     """
     try:
         client = _auth.authorized_client(config_name)
     except sdk_exc.ConfigNameNotFoundError:
         raise
 
     try:
-        return [obj.name for obj in client.list_secrets()]
+        return [obj.name for obj in client.list_secrets(workspace_id)]
     # explicit rethrows of known errors
     except _exceptions.InvalidTokenError as e:
         raise sdk_exc.UnauthorizedError() from e
 
 
 def set(
     name: str,
     value: str,
     *,
+    workspace_id: t.Optional[str] = None,
     config_name: t.Optional[str] = None,
 ):
     """
     Sets secret value at the remote vault. Overwrites already existing secrets.
 
     Args:
         name: secret identifier.
         value: new secret name.
+        workspace_id: workspace in which secret will be created. Using platform-defined
+            default if omitted - currently it is personal workspace
         config_name: config entry to use to communicate with Orquestra Platform.
             Required when used from a local machine. Ignored when
             ORQUESTRA_PASSPORT_FILE env variable is set.
 
     Raises:
         orquestra.sdk.exceptions.ConfigNameNotFoundError: when no matching config was
             found.
@@ -114,33 +133,41 @@
     try:
         client = _auth.authorized_client(config_name)
     except sdk_exc.ConfigNameNotFoundError:
         raise
 
     try:
         try:
-            client.create_secret(_models.SecretDefinition(name=name, value=value))
+            client.create_secret(
+                _models.SecretDefinition(
+                    name=name, value=value, resourceGroup=workspace_id
+                )
+            )
         except _exceptions.SecretAlreadyExistsError:
+            if workspace_id:
+                name = _translate_to_zri(workspace_id, name)
             client.update_secret(name, value)
     # explicit rethrows of known errors
     except _exceptions.InvalidTokenError as e:
         raise sdk_exc.UnauthorizedError() from e
 
 
 def delete(
     name: str,
     *,
+    workspace_id: t.Optional[str] = None,
     config_name: t.Optional[str] = None,
 ):
     """
     Deletes secret from the remote vault.
 
     Args:
         name: secret identifier.
-        value: new secret name.
+        workspace_id: ID of the workspace. Using platform-defined default if omitted -
+            - currently it is personal workspace
         config_name: config entry to use to communicate with Orquestra Platform.
             Required when used from a local machine. Ignored when
             ORQUESTRA_PASSPORT_FILE env variable is set.
 
     Raises:
         orquestra.sdk.exceptions.ConfigNameNotFoundError: when no matching config was
             found.
@@ -149,15 +176,16 @@
         orquestra.sdk.exceptions.UnauthorizedError: when the authorization with the
             remote vault failed.
     """
     try:
         client = _auth.authorized_client(config_name)
     except sdk_exc.ConfigNameNotFoundError:
         raise
-
+    if workspace_id:
+        name = _translate_to_zri(workspace_id, name)
     try:
         client.delete_secret(name)
     # explicit rethrows of known errors
     except _exceptions.SecretNotFoundError as e:
         raise sdk_exc.NotFoundError(f"Secret {name} not found") from e
     except _exceptions.InvalidTokenError as e:
         raise sdk_exc.UnauthorizedError() from e
```

## orquestra/sdk/secrets/_client.py

```diff
@@ -10,19 +10,21 @@
 from urllib.parse import urljoin
 
 import requests
 from requests import codes
 
 from . import _exceptions
 from ._models import (
+    ListSecretsRequest,
     SecretDefinition,
     SecretName,
     SecretNameObj,
     SecretValue,
     SecretValueObj,
+    WorkspaceId,
 )
 
 API_ACTIONS = {
     "list_secrets": "/api/config/secrets",
     "create_secret": "/api/config/secrets",
     "get_secret": "/api/config/secrets/{}",
     "update_secret": "/api/config/secrets/{}",
@@ -56,17 +58,22 @@
         session = requests.Session()
         session.headers["Content-Type"] = "application/json"
         session.headers["Authorization"] = f"Bearer {token}"
         return cls(base_uri=base_uri, session=session)
 
     # --- helpers ---
 
-    def _get(self, endpoint: str) -> requests.Response:
+    def _get(
+        self, endpoint: str, query_params: t.Optional[t.Mapping] = None
+    ) -> requests.Response:
         """Helper method for GET requests"""
-        response = self._session.get(urljoin(self._base_uri, endpoint))
+        response = self._session.get(
+            urljoin(self._base_uri, endpoint),
+            params=query_params,
+        )
 
         return response
 
     def _post(
         self, endpoint: str, body_params: t.Optional[t.Mapping]
     ) -> requests.Response:
         """Helper method for POST requests"""
@@ -96,21 +103,28 @@
         if resp.status_code == requests.codes.NOT_FOUND:
             raise _exceptions.SecretNotFoundError(secret_name=name)
 
         _handle_common_errors(resp)
 
         return SecretDefinition.parse_obj(resp.json()["data"]["details"])
 
-    def list_secrets(self) -> t.Sequence[SecretNameObj]:
+    def list_secrets(
+        self, workspace_id: t.Optional[WorkspaceId]
+    ) -> t.Sequence[SecretNameObj]:
         """
         Raises:
             InvalidTokenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
         """
-        resp = self._get(API_ACTIONS["list_secrets"])
+        resp = self._get(
+            API_ACTIONS["list_secrets"],
+            query_params=ListSecretsRequest(workspace=workspace_id).dict()
+            if workspace_id
+            else None,
+        )
         _handle_common_errors(resp)
 
         return [SecretNameObj.parse_obj(d) for d in resp.json()["data"]]
 
     # --- mutations ---
 
     def create_secret(self, new_secret: SecretDefinition):
```

## orquestra/sdk/secrets/_models.py

```diff
@@ -2,18 +2,22 @@
 # Â© Copyright 2022 Zapata Computing Inc.
 ################################################################################
 """
 Models for accessing the Config Service API.
 
 API spec: https://github.com/zapatacomputing/config-service/tree/main/openapi/src
 """
+from typing import Optional
+
 import pydantic
 
 SecretName = str
 SecretValue = str
+ResourceGroup = str
+WorkspaceId = str
 
 
 class SecretNameObj(pydantic.BaseModel):
     """
     Model for
     https://github.com/zapatacomputing/config-service/blob/3f275a52149fb2b74c6a8c01726cce4f390a1533/openapi/src/schemas/SecretName.yaml
 
@@ -40,7 +44,17 @@
     """
     Model for
     https://github.com/zapatacomputing/config-service/blob/3f275a52149fb2b74c6a8c01726cce4f390a1533/openapi/src/schemas/SecretDefinition.yaml
     """
 
     name: SecretName
     value: SecretValue
+    resourceGroup: Optional[ResourceGroup]
+
+
+class ListSecretsRequest(pydantic.BaseModel):
+    """
+    Model for
+    https://github.com/zapatacomputing/config-service/blob/fbfc4627450bc9a460278b242738e55210e7bf03/openapi/src/parameters/query/workspace.yaml
+    """
+
+    workspace: WorkspaceId
```

## Comparing `orquestra_sdk-0.48.0.dist-info/LICENSE` & `orquestra_sdk-0.49.1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `orquestra_sdk-0.48.0.dist-info/METADATA` & `orquestra_sdk-0.49.1.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,37 +1,38 @@
 Metadata-Version: 2.1
 Name: orquestra-sdk
-Version: 0.48.0
+Version: 0.49.1
 Summary: "Compose Orquestra workflows using a Python DSL"
 Home-page: https://github.com/zapatacomputing/orquestra-workflow-sdk
 Author: Zapata Computing Inc.
 Author-email: info@zapatacomputing.com
 License: Apache License 2.0
 Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3
 Classifier: Operating System :: OS Independent
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Topic :: Scientific/Engineering
 Requires-Python: >=3.8
 Description-Content-Type: text/markdown; charset=UTF-8
 License-File: LICENSE
 Requires-Dist: GitPython
+Requires-Dist: PyJWT (~=2.6)
 Requires-Dist: aiohttp (~=3.8)
 Requires-Dist: argcomplete
 Requires-Dist: click (~=8.0)
 Requires-Dist: cloudpickle (==2.2.1)
 Requires-Dist: cloup (~=2.0)
 Requires-Dist: dill (==0.3.6)
 Requires-Dist: filelock (>=3.3.2)
 Requires-Dist: graphviz
 Requires-Dist: importlib-metadata (~=4.0)
 Requires-Dist: inquirer (~=3.0)
 Requires-Dist: packaging (>=21)
 Requires-Dist: pip-api (==0.0.30)
-Requires-Dist: pydantic (<2)
+Requires-Dist: pydantic (<2,>=1.10.8)
 Requires-Dist: pygments (~=2.0)
 Requires-Dist: pyyaml
 Requires-Dist: requests (~=2.28)
 Requires-Dist: tabulate
 Requires-Dist: typing-extensions (>=4.1.0)
 Requires-Dist: wrapt
 Provides-Extra: all
```

## Comparing `orquestra_sdk-0.48.0.dist-info/RECORD` & `orquestra_sdk-0.49.1.dist-info/RECORD`

 * *Files 9% similar despite different names*

```diff
@@ -1,87 +1,89 @@
-orquestra/sdk/__init__.py,sha256=dK43fHFmiF_UygBSRk0lCwgSn175NDea2ZEdKPw4oz4,1494
-orquestra/sdk/exceptions.py,sha256=5MAXR1fJlq-qNdpviKLr41rBf-FD8ObWnlRTQbwGsyo,6076
+orquestra/sdk/__init__.py,sha256=ne_3HPdHwHaVon2czUCJMNCaY2sIq1sHGxYtz1MDxiA,1538
+orquestra/sdk/exceptions.py,sha256=dchEASsrb2hmJDuFJMquA8zV2I2WTjSpxPK3GlvT8zc,7183
 orquestra/sdk/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 orquestra/sdk/_base/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/_base/_ast.py,sha256=boa4KsrCkNqVSspmrhmVN8m9Ka8BH5tO-2eQnkrtyLQ,8563
 orquestra/sdk/_base/_config.py,sha256=Ik9M6aGxmGO6AcdRvs-EBx-2ZiLFV1n9ydhRL5Y6gB0,24929
-orquestra/sdk/_base/_dsl.py,sha256=_omxe2SX5z8is_51Lyjn6SsDlc5af4EnF-b7TRVDREw,36433
-orquestra/sdk/_base/_env.py,sha256=wb8PdmJIAWeeK7OugLxIVmVDrWJOz2qf5Vr9-4Hi-hU,1999
-orquestra/sdk/_base/_exec_ctx.py,sha256=pbHejxYg_rIDREizzuzlFWn1JzgUbvT7PBZQEZv2MnY,2338
+orquestra/sdk/_base/_dsl.py,sha256=WC_WC0thjgjIZWxUmNMfXk1odaE5UfIqbFTXJiY-lYU,36681
+orquestra/sdk/_base/_env.py,sha256=BZ5aP0S3GIKEe7RBzfF63lKXOWQK8HYfnutU9n4B9mU,2461
+orquestra/sdk/_base/_exec_ctx.py,sha256=1ZoMjsF9H-9oFym9BP5T6M_A7u4Q0133kOIBAK-2lD4,2465
 orquestra/sdk/_base/_factory.py,sha256=3c77X5DIR7PomySU1tmRjWsqnNLN_4zwjT5-7S_OfkI,1776
 orquestra/sdk/_base/_git_url_utils.py,sha256=BE8N9xM5eFN4juUhmw-CLuQL_F5oQmqnEJgoYU0zJes,3638
 orquestra/sdk/_base/_graphs.py,sha256=fkoDOjh65a79y9hC8IWe6CZL6fcSO5tXXpgWqK52hNM,3021
-orquestra/sdk/_base/_in_process_runtime.py,sha256=nZ506HHzTnrYvqn8AKFaZa_6iTq0P3balBNkmIxlCEo,11135
-orquestra/sdk/_base/_log_adapter.py,sha256=BEDE1vkZdeWLj-8JU-ajOubKGMEFww8ig3BMoR3aqC0,6476
+orquestra/sdk/_base/_in_process_runtime.py,sha256=VR_kIFic_Hjyj06DBXug6W9oPcPzVZL08frFg3T2yxs,12934
+orquestra/sdk/_base/_jwt.py,sha256=-VH1s1KHXxvdwNI8U7OgXXCB2-6l1OW-N9hsiMvsP-c,1104
+orquestra/sdk/_base/_log_adapter.py,sha256=OE1kFfnj5pmLERcVkSXbJqflrzpVW3R06qp6DhMPTOw,5245
 orquestra/sdk/_base/_retry.py,sha256=2wtkwRPYNyT_eBQ4NuA7AweIsyGeX8WHiLAk3KpuJ34,1407
-orquestra/sdk/_base/_services.py,sha256=WaiLQoX5IDjNniLHk32A2zP6X4ysKGD8lqDQHXkje2A,4331
+orquestra/sdk/_base/_services.py,sha256=MlUZDt8cWhmMA41mLzSghX1-inzGUj24QYDmR9uvjG4,4180
 orquestra/sdk/_base/_traversal.py,sha256=bN9M0QTS1q4L7XYqZTavuKWiSbXaK6hYSlvN7rs3Z5g,32145
 orquestra/sdk/_base/_viz.py,sha256=gVPZ7ZgKsbdAMF6ojlOIdMHIRJZPztTwHUmdP27hNQA,4629
-orquestra/sdk/_base/_workflow.py,sha256=y5uuMSHluqpMafMIq4lloAdv432N27MrubRgFs-PCDo,26166
-orquestra/sdk/_base/abc.py,sha256=Cr6ijkJFxLybs5vAtKBxxiLY8vxq88Ju7xkeYkFZOf8,8817
-orquestra/sdk/_base/dispatch.py,sha256=278KAwkihqY8cGnGkQj5dMQDfIahaIouaQ7niq9zHtw,11810
+orquestra/sdk/_base/_workflow.py,sha256=Elab8nSbZQNwb7_NwGZ4m3UMrmNfU4T4QmK0htJ0e-o,24415
+orquestra/sdk/_base/abc.py,sha256=p_PglCwNWAcqa8ZkGHk2cbsmjCPBgZGB6zYbzIixus8,9135
+orquestra/sdk/_base/dispatch.py,sha256=t4Haqb50W5LrDeAFNh23dszNZFnA9CkiIbhZtsCe1yM,11844
 orquestra/sdk/_base/loader.py,sha256=D7pAsKiAQXUoTL-jR_dOGZ2Kb4qL5Nd3PuFlcx2awgQ,6001
 orquestra/sdk/_base/serde.py,sha256=jpoW-hWRiVFkXqv6vtRgebZjZZPBPq5dDzUJG10uYJY,7004
-orquestra/sdk/_base/_api/__init__.py,sha256=wCxwKSyOvhRuAHWOc86Y8fkyzpT20r1RGklzKwEysHg,624
+orquestra/sdk/_base/_api/__init__.py,sha256=1vzKQsIbKwhBl-dr5Jp_g8iJdDga7duGm_yXAeW00Xw,664
 orquestra/sdk/_base/_api/_config.py,sha256=B5IlN1BQO9xjiNI19RspzUzV-2zkvUSEB8g8o55Rcik,18506
-orquestra/sdk/_base/_api/_task_run.py,sha256=oL2f9ssj0wNJslG8vV_tSpbqXVWpCDSJa1CQ3WY0VKA,9505
-orquestra/sdk/_base/_api/_wf_run.py,sha256=Zih4o5Xn7rAKEEZAqAyMS0OzXUoVD7fcKL9XECVF-c0,21243
+orquestra/sdk/_base/_api/_task_run.py,sha256=ZHc6eYh1rp_7N_nHIBZvJjIbZqUIuDhdqoR6HO9Ejag,13764
+orquestra/sdk/_base/_api/_wf_run.py,sha256=nWhqvMUs19YRV9fGimA0McMTZ8yWTd9s-rmF1vU8Hjk,18923
 orquestra/sdk/_base/_conversions/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/_base/_conversions/_ids.py,sha256=XzGDloJatAsYT0Xh2xxa8wjoVrHCcyd5GjB7d4tiuq0,3509
 orquestra/sdk/_base/_conversions/_imports.py,sha256=bSBe5hze_nIQNFP8QDp6EbVS7tQnxONLyW_IfvyFlvA,7074
 orquestra/sdk/_base/_conversions/_invocations.py,sha256=HbjQJUBaxIRySl-SxBf5NgDm2cUZPLayzzODtuMzTZw,12943
 orquestra/sdk/_base/_conversions/_yaml_exporter.py,sha256=Jkzsl9ewDPaPMIUokTgEHMvZjNrgrN4mXG0S8oBnrz8,3905
 orquestra/sdk/_base/_db/__init__.py,sha256=PuHjzdpfVyenO9-b6kYLAgss_Zote-j3ypBjCxf9pA0,360
 orquestra/sdk/_base/_db/_db.py,sha256=bp9ZzMUQ0cIO0nsTIPzgqwA4_8LoHM0n-hZYm0nhks0,5107
 orquestra/sdk/_base/_db/_migration.py,sha256=05RJ1X00yOGGnEwlzhmuFuztT0qCqi2hC-paSKGl3Nk,894
 orquestra/sdk/_base/_driver/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
-orquestra/sdk/_base/_driver/_ce_runtime.py,sha256=yc4SXV4I_6YqsqedsN_T3SDFA_BLl0CGK1JjU5qnohs,19734
-orquestra/sdk/_base/_driver/_client.py,sha256=jAIOdm5UQa9gnoHElBuReMxD_x9xd5hGwC24LR9MG9Y,24868
+orquestra/sdk/_base/_driver/_ce_runtime.py,sha256=qZ3k-o6VEW_GUAILQd-iRFYNBZqfmtA4aBcmQ35knOc,20258
+orquestra/sdk/_base/_driver/_client.py,sha256=17Ihyw7SN456Q5RzEz-DIV-oBwciS9z204ilqpIZTQM,25247
 orquestra/sdk/_base/_driver/_exceptions.py,sha256=93BSuSRJYU9sR_IW_Awr9Q-bOms4JUtYwpD5YySC5Xs,4748
-orquestra/sdk/_base/_driver/_models.py,sha256=WryGoaQcIj1ZgTteRZXzjKHFJ8rkWuRg1uA-itsT5AQ,9208
+orquestra/sdk/_base/_driver/_models.py,sha256=NzJ5yZdmYRNisISb9lv92ngr3lD8MPXjuxrCEgWVNmM,9314
 orquestra/sdk/_base/_qe/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/_base/_qe/_client.py,sha256=qrlEGDobbrEVhGNzUtwO7kcgFC9Ia6CU-8UfqbTLjQ8,7212
-orquestra/sdk/_base/_qe/_qe_runtime.py,sha256=RBki1wLd4lOhVMaxQsM1v436jf1QvxQxBFt-42rq9ZA,34116
+orquestra/sdk/_base/_qe/_qe_runtime.py,sha256=yB_cjMDDlMuJQQkUy1WSYHzt3k0Qu8uME3Yi5_vdTps,34726
 orquestra/sdk/_base/_spaces/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/_base/_spaces/_api.py,sha256=Ghu1h67ntZ4vB5SJiCD7x4g6z8aua4JY8eWYYZ_j2QM,1734
+orquestra/sdk/_base/_spaces/_resolver.py,sha256=dyrEf0i3KxBH7ouf_Ze05YkbQj_HJaFuMqkgjE8A8Wk,1555
 orquestra/sdk/_base/_spaces/_structs.py,sha256=8EdEm9QOQ7tm2aUSkAIycSHOoiuSmGANCn29wPXWcMw,704
 orquestra/sdk/_base/_testing/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/_base/_testing/_connections.py,sha256=rWJR4jOytfFy9Hol7fREeHKmg5NuC3-panAstzY-MKE,4031
-orquestra/sdk/_base/_testing/_example_wfs.py,sha256=a1UEYOeh3N2QTJMjqOk4Jz2qzY5lX2p9i3gjAIP1ykI,6800
+orquestra/sdk/_base/_testing/_example_wfs.py,sha256=09jsJJOWHSxxey98l5uWmH_hEc0JDo_5DeHtn6Ivz5E,7793
 orquestra/sdk/_base/_testing/_ipc.py,sha256=jDpwNAfGBuYj-Vf8k5C-8JQnFvoBVldkEswshfnvIzY,1754
 orquestra/sdk/_base/_testing/_long_import.py,sha256=CQ2vLXnvZmmSrX0c4vi9agcWVox7S7Bxuy7eouQ_FZA,261
-orquestra/sdk/_base/cli/_dorq/_arg_resolvers.py,sha256=w8x7JWU-ng0D4GQ9yUJe-aBTZ_viL-hWLFTR4HXhi5E,12293
+orquestra/sdk/_base/cli/_dorq/_arg_resolvers.py,sha256=K9jRIIGxggkOc7kt2A1KFRqk-KEIxUfbs7muQumrEVA,16844
 orquestra/sdk/_base/cli/_dorq/_cli_logs.py,sha256=XRSkORkipkHgdOyX41u7BOwszB3qp9kvY836BGqP0jw,698
 orquestra/sdk/_base/cli/_dorq/_dumpers.py,sha256=jb189V-isc1QeCN0Ti-erUH2v8-GAbhftoBhBGKi_Mc,3032
-orquestra/sdk/_base/cli/_dorq/_entry.py,sha256=2lSWe-NA3X5J66BDMVtCYJ9gr3boN7vW1Pl6Bz4bE5c,10432
-orquestra/sdk/_base/cli/_dorq/_repos.py,sha256=8oTFNQEZX0iEZoNy5LBbT-FdK-htlPvA66V51LwUBUA,21884
-orquestra/sdk/_base/cli/_dorq/_login/_login.py,sha256=NCVfNfdiRHSRRhTZ19yuVjGVWG73PcBgdD3ZedGKZNg,3043
+orquestra/sdk/_base/cli/_dorq/_entry.py,sha256=7mNE0Fkjjxf_yAf_cwm-YKm-84iaVQJ3t977NdYOPkM,10859
+orquestra/sdk/_base/cli/_dorq/_repos.py,sha256=eAfh2jEZzEPihC9pJUNRfCDBBAxvIBfXSg7dsRM4ARM,23124
+orquestra/sdk/_base/cli/_dorq/_login/_login.py,sha256=nFjZnGm7M2eycqXSd6lmcWYUp9_G2VQoratAw-VsQ94,5360
 orquestra/sdk/_base/cli/_dorq/_login/_login_server.py,sha256=hAC9M8PZaNNhj-nbkBajyMQoxu0dQgwFesmlwGcjVpc,1694
 orquestra/sdk/_base/cli/_dorq/_services/_down.py,sha256=7hW0i4fen-3f_CRyklcF0RMlR4VMQjDvkfEYzYWNiwQ,1621
 orquestra/sdk/_base/cli/_dorq/_services/_status.py,sha256=WGYYMAC8pUfIb9Jv0HJ7WMtiriiRBAYhk2O1MqY4M-U,1327
-orquestra/sdk/_base/cli/_dorq/_services/_up.py,sha256=BlKMsOpRNK2oD1f00KrPX44QMlKcGmyk8tM78VTvtFE,2135
+orquestra/sdk/_base/cli/_dorq/_services/_up.py,sha256=P3tnCe6Pvj7MaJaZUXo3zaTiw52Y6hFQoo6_OPg1qE0,2656
 orquestra/sdk/_base/cli/_dorq/_task/_logs.py,sha256=4ea8Lg5KivWP6B3VyiS1Tv7fyUUQ_T6DLTvk5LBAMU8,3106
 orquestra/sdk/_base/cli/_dorq/_task/_results.py,sha256=2m8wEQ4YyBgz3QkIRQ8vDNNNdfsoVcmOGBSMRUHl1UM,3626
 orquestra/sdk/_base/cli/_dorq/_ui/__init__.py,sha256=nyIdSAJuZC_UDkwayYOvKpw-YJNvKu7n-vFY0I2-2tQ,367
-orquestra/sdk/_base/cli/_dorq/_ui/_errors.py,sha256=fgxawIXMQ-qXYVKNIKbwieSjOa0kfmckTO6bEDkAQbU,4107
+orquestra/sdk/_base/cli/_dorq/_ui/_errors.py,sha256=lk1DtH38D2NEdxXDlNLYVDpS1K4CotI-9GMDJt63EnU,5520
 orquestra/sdk/_base/cli/_dorq/_ui/_models.py,sha256=Zr2f7gEPahHq7KHdOFSG7gxFFniOe_DcLX32kQKUrtA,1648
-orquestra/sdk/_base/cli/_dorq/_ui/_presenters.py,sha256=I_QzN7g__xN-Sebyb-TGP_6ral1vSSi2dk17kEa_-E8,10300
-orquestra/sdk/_base/cli/_dorq/_ui/_prompts.py,sha256=HJQbyiBTU6nWgYfQuyMPo0nmtTFM2-nAmxWI5cIJ_Iw,9394
+orquestra/sdk/_base/cli/_dorq/_ui/_presenters.py,sha256=VazobkXETJii2jL7Gbtd3-xM28UwM9de4RJ2ktpeH7E,11287
+orquestra/sdk/_base/cli/_dorq/_ui/_prompts.py,sha256=asiXA775dItSKeEeKebWKw65W4o-AfXF68h3O3Zp49w,10249
 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/color.py,sha256=FyabLjvjXvTHHVPjz7kCt05AcYhy3CjVvqq-UAQxrss,624
 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/per_command.py,sha256=GJuqOLZq2BfCgSn14DODYXM_-eJBd6x3a78JDG_4f94,7794
-orquestra/sdk/_base/cli/_dorq/_workflow/_list.py,sha256=2zkcmkKDyK0TcZb-a16pABkF4Y_fw7ZUHFt285WMbe0,3463
+orquestra/sdk/_base/cli/_dorq/_workflow/_list.py,sha256=4CANU1u-auE7FEiuLwYwOka-H3tTynIT5i5nqEhqVHk,5180
 orquestra/sdk/_base/cli/_dorq/_workflow/_logs.py,sha256=ZoVMk1OmXdS8950_zfb88yXS0yUb5dpM50QOSiRWoCI,2739
 orquestra/sdk/_base/cli/_dorq/_workflow/_results.py,sha256=3rbRSBSvOfyAia2-NREeMUWxaRbldPdVQ-norwWjOl8,3140
 orquestra/sdk/_base/cli/_dorq/_workflow/_stop.py,sha256=wVRYxCm_KWvAVNuQMtpNDZmo4cwWiTpvt43GZoaVLrM,2507
 orquestra/sdk/_base/cli/_dorq/_workflow/_submit.py,sha256=6ffYI3T8056JoRb6_LA7ANpnun3dxxr-6B50abfDOjg,4406
 orquestra/sdk/_base/cli/_dorq/_workflow/_view.py,sha256=2bnKN1kMTbacy0PUMXAFGhfQ4GPZlaIhwnTaI8Zu9zg,2138
 orquestra/sdk/_ray/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
-orquestra/sdk/_ray/_build_workflow.py,sha256=_xirtclMTESal9AHcblMqvKqcA3A3EXHbX8LFU5yxY0,16431
-orquestra/sdk/_ray/_client.py,sha256=oavtnzkkVdrG8DYx1kyI9HXiKzS7tU-zs6UCZNGIOlY,6612
-orquestra/sdk/_ray/_dag.py,sha256=29_tuW7RJxtwt8eF0-SsQSVej7I8Vi4xMvUBsSZvFpU,20571
+orquestra/sdk/_ray/_build_workflow.py,sha256=HqEJgAbVcxp7VWwAU6KVm3fgoAxeexXXZGm3m6Pci1M,18315
+orquestra/sdk/_ray/_client.py,sha256=yBzHwT0u6TRPx3P-ComceErjSZVvGVhmNiv671dTGt4,6808
+orquestra/sdk/_ray/_dag.py,sha256=T2at2RHd6xVZuicsm-kgHTVLqbiXNXO4DYvgfgcUFgo,21176
 orquestra/sdk/_ray/_id_gen.py,sha256=VELgM5qq2pmHZIuDIKdbtYACcGRdY2aZvt9jxOEmJQ8,867
 orquestra/sdk/_ray/_ray_logs.py,sha256=qMNJ1Af_cFshTTPxchQf45B9xL5mHwZLIeQfrUcL5WU,4387
 orquestra/sdk/_ray/_wf_metadata.py,sha256=9DKDFw5rUepke5PYYm7cMEknvlqMH12Zl71pmbVxFbA,1278
 orquestra/sdk/examples/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/examples/exportable_wf.py,sha256=vd7yx2aelszLOwxpWJkrvzZ9HSl22Je-fB6LEzEna68,1558
 orquestra/sdk/examples/workflow_defs.py,sha256=1z_MrqEPnScNescLLF4eWDepm5fwxcIIagMU8AFfUKs,1116
 orquestra/sdk/kubernetes/__init__.py,sha256=fmqiLNRiTWLjlWlynWbcgaBq6N5YkP-qoM2qgZluuM4,318
@@ -93,19 +95,19 @@
 orquestra/sdk/schema/configs.py,sha256=M3PjmFvZsOxpK4dQlvd-ttUgkLoRibvkOUGmzdPXVkA,1474
 orquestra/sdk/schema/ir.py,sha256=_IRxvIpi2LB4UniqHGeCgmNUz9D1QMIyuxJvwC0rna8,14987
 orquestra/sdk/schema/local_database.py,sha256=E1F5_7DD32N1lxO1U-6P2u7K0HdC1oZkxa8pRjJG4pE,832
 orquestra/sdk/schema/responses.py,sha256=sYCGJOhkHYcJ_08v8KapqlJwrZQah-7Ipp7dI3HoFjA,4745
 orquestra/sdk/schema/workflow_run.py,sha256=vdGS9SjJslNjpBLeunIAxCb0V_RtAmOL71TqKqJRwzg,1478
 orquestra/sdk/schema/yaml_model.py,sha256=Y58Hm6rHILeOx3rMp6L7BQKkR35U3iprOexDqoGi6ro,4114
 orquestra/sdk/secrets/__init__.py,sha256=Ayi-FYjTmw7TwuQiDPf06in9q26o7jJ27ZTCvGEwc98,1104
-orquestra/sdk/secrets/_api.py,sha256=9wdOgqawNCfDM7UfWtBP7V34-DnDP0ypUlCSJdBCaqc,5356
+orquestra/sdk/secrets/_api.py,sha256=24vuCZrIINGk4OUbBRbZQPzmBPvRQLtszRJPQ3YG8uQ,6596
 orquestra/sdk/secrets/_auth.py,sha256=bubkhPp1K557VeUNOKMvBwStUsL1Oet1ZwW5ldsrsjo,2090
-orquestra/sdk/secrets/_client.py,sha256=DD8zwvLYArgIsTy7G8HGfudT91c4Y0tBGO_AZfdCdOo,5243
+orquestra/sdk/secrets/_client.py,sha256=MOfBkqHQOpHCaznHZhvvP20x9u0XFrVg_tGtCoGtF6c,5600
 orquestra/sdk/secrets/_exceptions.py,sha256=V7I9v07EAp4gcaJqtkONqJcnGvH8khJInQ_P5IF4sP8,1222
-orquestra/sdk/secrets/_models.py,sha256=fIHZqrAJdHQCHHAPdKV9bkTZTeQymB8CRj5nJoQ63DQ,1319
+orquestra/sdk/secrets/_models.py,sha256=kzVe5R3J5wTZAHwosjMXyI0mSpTp0bpyXI73M0IPgb4,1679
 orquestra/sdk/v2/__init__.py,sha256=hXnYIFBFQmJ59Bf-2XpFl2F1qyzWo1QHBG32cdSxlds,1072
-orquestra_sdk-0.48.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-orquestra_sdk-0.48.0.dist-info/METADATA,sha256=xfmMkymi7v0tC-3_eaXB0B6LrbvvgXQmhKi0G1HAZ9g,3089
-orquestra_sdk-0.48.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-orquestra_sdk-0.48.0.dist-info/entry_points.txt,sha256=wYumKiNDhktX8S5sw7K-_vXnBRpUdWN4sZ9nfjwDRsM,67
-orquestra_sdk-0.48.0.dist-info/top_level.txt,sha256=I3GLQbK_gqa5pjIjuEVYddNALTZjwfdtgqvscclR78M,10
-orquestra_sdk-0.48.0.dist-info/RECORD,,
+orquestra_sdk-0.49.1.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+orquestra_sdk-0.49.1.dist-info/METADATA,sha256=IZzeRyH1iHYy-wS2-Mgaq7n0WJRPSRbk9zZ5GIRH7n0,3127
+orquestra_sdk-0.49.1.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+orquestra_sdk-0.49.1.dist-info/entry_points.txt,sha256=wYumKiNDhktX8S5sw7K-_vXnBRpUdWN4sZ9nfjwDRsM,67
+orquestra_sdk-0.49.1.dist-info/top_level.txt,sha256=I3GLQbK_gqa5pjIjuEVYddNALTZjwfdtgqvscclR78M,10
+orquestra_sdk-0.49.1.dist-info/RECORD,,
```

