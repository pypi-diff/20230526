# Comparing `tmp/RegScale_CLI-5.3.1-py3-none-any.whl.zip` & `tmp/RegScale_CLI-5.4.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,95 +1,113 @@
-Zip file size: 237497 bytes, number of entries: 93
--rw-r--r--  2.0 unx       22 b- defN 23-May-19 03:02 regscale/__init__.py
--rw-r--r--  2.0 unx    15147 b- defN 23-May-19 03:02 regscale/regscale.py
--rw-r--r--  2.0 unx      270 b- defN 23-May-19 03:02 regscale/airflow/__init__.py
--rw-r--r--  2.0 unx      262 b- defN 23-May-19 03:02 regscale/ansible/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-19 03:02 regscale/core/__init__.py
--rw-r--r--  2.0 unx      129 b- defN 23-May-19 03:02 regscale/core/app/__init__.py
--rw-r--r--  2.0 unx    14666 b- defN 23-May-19 03:02 regscale/core/app/api.py
--rw-r--r--  2.0 unx    13607 b- defN 23-May-19 03:02 regscale/core/app/application.py
--rw-r--r--  2.0 unx     1145 b- defN 23-May-19 03:02 regscale/core/app/logz.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-19 03:02 regscale/core/app/internal/__init__.py
--rw-r--r--  2.0 unx    27117 b- defN 23-May-19 03:02 regscale/core/app/internal/admin_actions.py
--rw-r--r--  2.0 unx    31088 b- defN 23-May-19 03:02 regscale/core/app/internal/assessments_editor.py
--rw-r--r--  2.0 unx      979 b- defN 23-May-19 03:02 regscale/core/app/internal/catalog.py
--rw-r--r--  2.0 unx    16188 b- defN 23-May-19 03:02 regscale/core/app/internal/comparison.py
--rw-r--r--  2.0 unx    15364 b- defN 23-May-19 03:02 regscale/core/app/internal/control_editor.py
--rw-r--r--  2.0 unx     5948 b- defN 23-May-19 03:02 regscale/core/app/internal/encrypt.py
--rw-r--r--  2.0 unx    40204 b- defN 23-May-19 03:02 regscale/core/app/internal/evidence.py
--rw-r--r--  2.0 unx     2367 b- defN 23-May-19 03:02 regscale/core/app/internal/healthcheck.py
--rw-r--r--  2.0 unx     6513 b- defN 23-May-19 03:02 regscale/core/app/internal/login.py
--rw-r--r--  2.0 unx     8815 b- defN 23-May-19 03:02 regscale/core/app/internal/migrations.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-19 03:02 regscale/core/app/public/__init__.py
--rw-r--r--  2.0 unx    11234 b- defN 23-May-19 03:02 regscale/core/app/public/emass.py
--rw-r--r--  2.0 unx    62097 b- defN 23-May-19 03:02 regscale/core/app/public/fedramp.py
--rw-r--r--  2.0 unx     8996 b- defN 23-May-19 03:02 regscale/core/app/public/nist_catalog.py
--rw-r--r--  2.0 unx    87595 b- defN 23-May-19 03:02 regscale/core/app/public/oscal.py
--rw-r--r--  2.0 unx     6125 b- defN 23-May-19 03:02 regscale/core/app/public/otx.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-19 03:02 regscale/core/app/utils/__init__.py
--rw-r--r--  2.0 unx    23417 b- defN 23-May-19 03:02 regscale/core/app/utils/app_utils.py
--rw-r--r--  2.0 unx    10613 b- defN 23-May-19 03:02 regscale/core/app/utils/regscale_utils.py
--rw-r--r--  2.0 unx     1605 b- defN 23-May-19 03:02 regscale/core/app/utils/threadhandler.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-19 03:02 regscale/core/app/utils/catalog_utils/__init__.py
--rw-r--r--  2.0 unx     9213 b- defN 23-May-19 03:02 regscale/core/app/utils/catalog_utils/compare_catalog.py
--rw-r--r--  2.0 unx     4467 b- defN 23-May-19 03:02 regscale/core/app/utils/catalog_utils/diagnostic_catalog.py
--rw-r--r--  2.0 unx     2723 b- defN 23-May-19 03:02 regscale/core/app/utils/catalog_utils/export_catalog.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-19 03:02 regscale/exceptions/__init__.py
--rw-r--r--  2.0 unx      195 b- defN 23-May-19 03:02 regscale/exceptions/license_exception.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-19 03:02 regscale/integrations/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-19 03:02 regscale/integrations/commercial/__init__.py
--rw-r--r--  2.0 unx    16420 b- defN 23-May-19 03:02 regscale/integrations/commercial/ad.py
--rw-r--r--  2.0 unx    12972 b- defN 23-May-19 03:02 regscale/integrations/commercial/aws.py
--rw-r--r--  2.0 unx    46871 b- defN 23-May-19 03:02 regscale/integrations/commercial/defender.py
--rw-r--r--  2.0 unx     8069 b- defN 23-May-19 03:02 regscale/integrations/commercial/jira.py
--rw-r--r--  2.0 unx    27319 b- defN 23-May-19 03:02 regscale/integrations/commercial/okta.py
--rw-r--r--  2.0 unx    29643 b- defN 23-May-19 03:02 regscale/integrations/commercial/qualys.py
--rw-r--r--  2.0 unx    11751 b- defN 23-May-19 03:02 regscale/integrations/commercial/servicenow.py
--rw-r--r--  2.0 unx    63112 b- defN 23-May-19 03:02 regscale/integrations/commercial/stig.py
--rw-r--r--  2.0 unx    22771 b- defN 23-May-19 03:02 regscale/integrations/commercial/tenable.py
--rw-r--r--  2.0 unx    62395 b- defN 23-May-19 03:02 regscale/integrations/commercial/wiz.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-19 03:02 regscale/integrations/public/__init__.py
--rw-r--r--  2.0 unx    18680 b- defN 23-May-19 03:02 regscale/integrations/public/cisa.py
--rw-r--r--  2.0 unx      153 b- defN 23-May-19 03:02 regscale/models/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-19 03:02 regscale/models/app_models/__init__.py
--rw-r--r--  2.0 unx     7553 b- defN 23-May-19 03:02 regscale/models/app_models/catalog_compare.py
--rw-r--r--  2.0 unx     4006 b- defN 23-May-19 03:02 regscale/models/app_models/click.py
--rw-r--r--  2.0 unx    13918 b- defN 23-May-19 03:02 regscale/models/app_models/control_editor.py
--rw-r--r--  2.0 unx      889 b- defN 23-May-19 03:02 regscale/models/app_models/pipeline.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-19 03:02 regscale/models/integration_models/__init__.py
--rw-r--r--  2.0 unx     7858 b- defN 23-May-19 03:02 regscale/models/integration_models/azure_alerts.py
--rw-r--r--  2.0 unx      872 b- defN 23-May-19 03:02 regscale/models/integration_models/recommendations.py
--rw-r--r--  2.0 unx     8319 b- defN 23-May-19 03:02 regscale/models/integration_models/tenable.py
--rw-r--r--  2.0 unx     1833 b- defN 23-May-19 03:02 regscale/models/integration_models/wiz.py
--rw-r--r--  2.0 unx      257 b- defN 23-May-19 03:02 regscale/models/regscale_models/__init__.py
--rw-r--r--  2.0 unx     6688 b- defN 23-May-19 03:02 regscale/models/regscale_models/assessment.py
--rw-r--r--  2.0 unx     9064 b- defN 23-May-19 03:02 regscale/models/regscale_models/asset.py
--rw-r--r--  2.0 unx     7157 b- defN 23-May-19 03:02 regscale/models/regscale_models/checklist.py
--rw-r--r--  2.0 unx     1906 b- defN 23-May-19 03:02 regscale/models/regscale_models/components.py
--rw-r--r--  2.0 unx    10977 b- defN 23-May-19 03:02 regscale/models/regscale_models/control_implementation.py
--rw-r--r--  2.0 unx     1465 b- defN 23-May-19 03:02 regscale/models/regscale_models/control_objective.py
--rw-r--r--  2.0 unx     6359 b- defN 23-May-19 03:02 regscale/models/regscale_models/implementation_objective.py
--rw-r--r--  2.0 unx     3032 b- defN 23-May-19 03:02 regscale/models/regscale_models/implementation_option.py
--rw-r--r--  2.0 unx     2850 b- defN 23-May-19 03:02 regscale/models/regscale_models/interconnects.py
--rw-r--r--  2.0 unx    10210 b- defN 23-May-19 03:02 regscale/models/regscale_models/issue.py
--rw-r--r--  2.0 unx     4892 b- defN 23-May-19 03:02 regscale/models/regscale_models/modules.py
--rw-r--r--  2.0 unx      232 b- defN 23-May-19 03:02 regscale/models/regscale_models/objective.py
--rw-r--r--  2.0 unx     2353 b- defN 23-May-19 03:02 regscale/models/regscale_models/ports_protocols.py
--rw-r--r--  2.0 unx     2415 b- defN 23-May-19 03:02 regscale/models/regscale_models/requirements.py
--rw-r--r--  2.0 unx     5524 b- defN 23-May-19 03:02 regscale/models/regscale_models/security_control.py
--rw-r--r--  2.0 unx     5886 b- defN 23-May-19 03:02 regscale/models/regscale_models/securityplans.py
--rw-r--r--  2.0 unx    26139 b- defN 23-May-19 03:02 regscale/models/regscale_models/stig.py
--rw-r--r--  2.0 unx     1425 b- defN 23-May-19 03:02 regscale/models/regscale_models/threat.py
--rw-r--r--  2.0 unx     2242 b- defN 23-May-19 03:02 regscale/models/regscale_models/user.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-19 03:02 regscale/validation/__init__.py
--rw-r--r--  2.0 unx      422 b- defN 23-May-19 03:02 regscale/validation/address.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-19 03:02 tests/mocks/__init__.py
--rw-r--r--  2.0 unx       99 b- defN 23-May-19 03:02 tests/mocks/objects.py
--rw-r--r--  2.0 unx     1039 b- defN 23-May-19 03:02 tests/mocks/response.py
--rw-r--r--  2.0 unx      260 b- defN 23-May-19 03:02 tests/mocks/xml.py
--rw-r--r--  2.0 unx     1076 b- defN 23-May-19 03:02 RegScale_CLI-5.3.1.dist-info/LICENSE
--rw-r--r--  2.0 unx     6611 b- defN 23-May-19 03:02 RegScale_CLI-5.3.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-May-19 03:02 RegScale_CLI-5.3.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       52 b- defN 23-May-19 03:02 RegScale_CLI-5.3.1.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       26 b- defN 23-May-19 03:02 RegScale_CLI-5.3.1.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     8867 b- defN 23-May-19 03:02 RegScale_CLI-5.3.1.dist-info/RECORD
-93 files, 923132 bytes uncompressed, 223099 bytes compressed:  75.8%
+Zip file size: 249011 bytes, number of entries: 111
+-rw-r--r--  2.0 unx       22 b- defN 23-May-26 18:22 regscale/__init__.py
+-rw-r--r--  2.0 unx    15147 b- defN 23-May-26 18:22 regscale/regscale.py
+-rw-r--r--  2.0 unx      270 b- defN 23-May-26 18:22 regscale/airflow/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/airflow/tasks/__init__.py
+-rw-r--r--  2.0 unx     3308 b- defN 23-May-26 18:22 regscale/airflow/tasks/cli.py
+-rw-r--r--  2.0 unx      262 b- defN 23-May-26 18:22 regscale/ansible/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/core/__init__.py
+-rw-r--r--  2.0 unx     1553 b- defN 23-May-26 18:22 regscale/core/login.py
+-rw-r--r--  2.0 unx      129 b- defN 23-May-26 18:22 regscale/core/app/__init__.py
+-rw-r--r--  2.0 unx    14666 b- defN 23-May-26 18:22 regscale/core/app/api.py
+-rw-r--r--  2.0 unx    13607 b- defN 23-May-26 18:22 regscale/core/app/application.py
+-rw-r--r--  2.0 unx     1145 b- defN 23-May-26 18:22 regscale/core/app/logz.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/core/app/internal/__init__.py
+-rw-r--r--  2.0 unx    27214 b- defN 23-May-26 18:22 regscale/core/app/internal/admin_actions.py
+-rw-r--r--  2.0 unx    31088 b- defN 23-May-26 18:22 regscale/core/app/internal/assessments_editor.py
+-rw-r--r--  2.0 unx      979 b- defN 23-May-26 18:22 regscale/core/app/internal/catalog.py
+-rw-r--r--  2.0 unx    16694 b- defN 23-May-26 18:22 regscale/core/app/internal/comparison.py
+-rw-r--r--  2.0 unx    15364 b- defN 23-May-26 18:22 regscale/core/app/internal/control_editor.py
+-rw-r--r--  2.0 unx     5948 b- defN 23-May-26 18:22 regscale/core/app/internal/encrypt.py
+-rw-r--r--  2.0 unx    40204 b- defN 23-May-26 18:22 regscale/core/app/internal/evidence.py
+-rw-r--r--  2.0 unx     2367 b- defN 23-May-26 18:22 regscale/core/app/internal/healthcheck.py
+-rw-r--r--  2.0 unx     6513 b- defN 23-May-26 18:22 regscale/core/app/internal/login.py
+-rw-r--r--  2.0 unx     9712 b- defN 23-May-26 18:22 regscale/core/app/internal/migrations.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/core/app/public/__init__.py
+-rw-r--r--  2.0 unx    11879 b- defN 23-May-26 18:22 regscale/core/app/public/emass.py
+-rw-r--r--  2.0 unx    62097 b- defN 23-May-26 18:22 regscale/core/app/public/fedramp.py
+-rw-r--r--  2.0 unx     9000 b- defN 23-May-26 18:22 regscale/core/app/public/nist_catalog.py
+-rw-r--r--  2.0 unx    87151 b- defN 23-May-26 18:22 regscale/core/app/public/oscal.py
+-rw-r--r--  2.0 unx     6125 b- defN 23-May-26 18:22 regscale/core/app/public/otx.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/core/app/utils/__init__.py
+-rw-r--r--  2.0 unx    23177 b- defN 23-May-26 18:22 regscale/core/app/utils/app_utils.py
+-rw-r--r--  2.0 unx    10613 b- defN 23-May-26 18:22 regscale/core/app/utils/regscale_utils.py
+-rw-r--r--  2.0 unx     1605 b- defN 23-May-26 18:22 regscale/core/app/utils/threadhandler.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/core/app/utils/catalog_utils/__init__.py
+-rw-r--r--  2.0 unx     9213 b- defN 23-May-26 18:22 regscale/core/app/utils/catalog_utils/compare_catalog.py
+-rw-r--r--  2.0 unx     4467 b- defN 23-May-26 18:22 regscale/core/app/utils/catalog_utils/diagnostic_catalog.py
+-rw-r--r--  2.0 unx     2727 b- defN 23-May-26 18:22 regscale/core/app/utils/catalog_utils/export_catalog.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/core/static/__init__.py
+-rw-r--r--  2.0 unx      383 b- defN 23-May-26 18:22 regscale/core/static/regex.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/core/utils/__init__.py
+-rw-r--r--  2.0 unx      583 b- defN 23-May-26 18:22 regscale/core/utils/urls.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/exceptions/__init__.py
+-rw-r--r--  2.0 unx      195 b- defN 23-May-26 18:22 regscale/exceptions/license_exception.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/integrations/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/integrations/commercial/__init__.py
+-rw-r--r--  2.0 unx    16252 b- defN 23-May-26 18:22 regscale/integrations/commercial/ad.py
+-rw-r--r--  2.0 unx    12972 b- defN 23-May-26 18:22 regscale/integrations/commercial/aws.py
+-rw-r--r--  2.0 unx    46871 b- defN 23-May-26 18:22 regscale/integrations/commercial/defender.py
+-rw-r--r--  2.0 unx     8720 b- defN 23-May-26 18:22 regscale/integrations/commercial/jira.py
+-rw-r--r--  2.0 unx    30770 b- defN 23-May-26 18:22 regscale/integrations/commercial/okta.py
+-rw-r--r--  2.0 unx    31580 b- defN 23-May-26 18:22 regscale/integrations/commercial/qualys.py
+-rw-r--r--  2.0 unx    12466 b- defN 23-May-26 18:22 regscale/integrations/commercial/servicenow.py
+-rw-r--r--  2.0 unx    63112 b- defN 23-May-26 18:22 regscale/integrations/commercial/stig.py
+-rw-r--r--  2.0 unx    22730 b- defN 23-May-26 18:22 regscale/integrations/commercial/tenable.py
+-rw-r--r--  2.0 unx    62395 b- defN 23-May-26 18:22 regscale/integrations/commercial/wiz.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/integrations/public/__init__.py
+-rw-r--r--  2.0 unx    18680 b- defN 23-May-26 18:22 regscale/integrations/public/cisa.py
+-rw-r--r--  2.0 unx      153 b- defN 23-May-26 18:22 regscale/models/__init__.py
+-rw-r--r--  2.0 unx     4865 b- defN 23-May-26 18:22 regscale/models/config.py
+-rw-r--r--  2.0 unx     3453 b- defN 23-May-26 18:22 regscale/models/platform.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/models/app_models/__init__.py
+-rw-r--r--  2.0 unx     7553 b- defN 23-May-26 18:22 regscale/models/app_models/catalog_compare.py
+-rw-r--r--  2.0 unx     4006 b- defN 23-May-26 18:22 regscale/models/app_models/click.py
+-rw-r--r--  2.0 unx    13918 b- defN 23-May-26 18:22 regscale/models/app_models/control_editor.py
+-rw-r--r--  2.0 unx      889 b- defN 23-May-26 18:22 regscale/models/app_models/pipeline.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/models/integration_models/__init__.py
+-rw-r--r--  2.0 unx     7858 b- defN 23-May-26 18:22 regscale/models/integration_models/azure_alerts.py
+-rw-r--r--  2.0 unx      872 b- defN 23-May-26 18:22 regscale/models/integration_models/recommendations.py
+-rw-r--r--  2.0 unx     8319 b- defN 23-May-26 18:22 regscale/models/integration_models/tenable.py
+-rw-r--r--  2.0 unx     1833 b- defN 23-May-26 18:22 regscale/models/integration_models/wiz.py
+-rw-r--r--  2.0 unx      257 b- defN 23-May-26 18:22 regscale/models/regscale_models/__init__.py
+-rw-r--r--  2.0 unx     6688 b- defN 23-May-26 18:22 regscale/models/regscale_models/assessment.py
+-rw-r--r--  2.0 unx     9064 b- defN 23-May-26 18:22 regscale/models/regscale_models/asset.py
+-rw-r--r--  2.0 unx     7157 b- defN 23-May-26 18:22 regscale/models/regscale_models/checklist.py
+-rw-r--r--  2.0 unx     1906 b- defN 23-May-26 18:22 regscale/models/regscale_models/components.py
+-rw-r--r--  2.0 unx    10977 b- defN 23-May-26 18:22 regscale/models/regscale_models/control_implementation.py
+-rw-r--r--  2.0 unx     1465 b- defN 23-May-26 18:22 regscale/models/regscale_models/control_objective.py
+-rw-r--r--  2.0 unx     6359 b- defN 23-May-26 18:22 regscale/models/regscale_models/implementation_objective.py
+-rw-r--r--  2.0 unx     3032 b- defN 23-May-26 18:22 regscale/models/regscale_models/implementation_option.py
+-rw-r--r--  2.0 unx     2850 b- defN 23-May-26 18:22 regscale/models/regscale_models/interconnects.py
+-rw-r--r--  2.0 unx    10210 b- defN 23-May-26 18:22 regscale/models/regscale_models/issue.py
+-rw-r--r--  2.0 unx     4892 b- defN 23-May-26 18:22 regscale/models/regscale_models/modules.py
+-rw-r--r--  2.0 unx      232 b- defN 23-May-26 18:22 regscale/models/regscale_models/objective.py
+-rw-r--r--  2.0 unx     2353 b- defN 23-May-26 18:22 regscale/models/regscale_models/ports_protocols.py
+-rw-r--r--  2.0 unx     2415 b- defN 23-May-26 18:22 regscale/models/regscale_models/requirements.py
+-rw-r--r--  2.0 unx     5524 b- defN 23-May-26 18:22 regscale/models/regscale_models/security_control.py
+-rw-r--r--  2.0 unx     5886 b- defN 23-May-26 18:22 regscale/models/regscale_models/securityplans.py
+-rw-r--r--  2.0 unx    26139 b- defN 23-May-26 18:22 regscale/models/regscale_models/stig.py
+-rw-r--r--  2.0 unx     1425 b- defN 23-May-26 18:22 regscale/models/regscale_models/threat.py
+-rw-r--r--  2.0 unx     2242 b- defN 23-May-26 18:22 regscale/models/regscale_models/user.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/utils/__init__.py
+-rw-r--r--  2.0 unx     3893 b- defN 23-May-26 18:22 regscale/utils/shell.py
+-rw-r--r--  2.0 unx       48 b- defN 23-May-26 18:22 regscale/utils/string.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 regscale/validation/__init__.py
+-rw-r--r--  2.0 unx      422 b- defN 23-May-26 18:22 regscale/validation/address.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 tests/mocks/__init__.py
+-rw-r--r--  2.0 unx       99 b- defN 23-May-26 18:22 tests/mocks/objects.py
+-rw-r--r--  2.0 unx     1039 b- defN 23-May-26 18:22 tests/mocks/response.py
+-rw-r--r--  2.0 unx      260 b- defN 23-May-26 18:22 tests/mocks/xml.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 tests/regscale/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 tests/regscale/core/__init__.py
+-rw-r--r--  2.0 unx     1172 b- defN 23-May-26 18:22 tests/regscale/core/test_login.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-26 18:22 tests/regscale/models/__init__.py
+-rw-r--r--  2.0 unx      810 b- defN 23-May-26 18:22 tests/regscale/models/test_config.py
+-rw-r--r--  2.0 unx      856 b- defN 23-May-26 18:22 tests/regscale/models/test_platform.py
+-rw-r--r--  2.0 unx     1076 b- defN 23-May-26 18:22 RegScale_CLI-5.4.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     6635 b- defN 23-May-26 18:22 RegScale_CLI-5.4.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-26 18:22 RegScale_CLI-5.4.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       52 b- defN 23-May-26 18:22 RegScale_CLI-5.4.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       26 b- defN 23-May-26 18:22 RegScale_CLI-5.4.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    10392 b- defN 23-May-26 18:22 RegScale_CLI-5.4.0.dist-info/RECORD
+111 files, 953619 bytes uncompressed, 232193 bytes compressed:  75.7%
```

## zipnote {}

```diff
@@ -3,20 +3,29 @@
 
 Filename: regscale/regscale.py
 Comment: 
 
 Filename: regscale/airflow/__init__.py
 Comment: 
 
+Filename: regscale/airflow/tasks/__init__.py
+Comment: 
+
+Filename: regscale/airflow/tasks/cli.py
+Comment: 
+
 Filename: regscale/ansible/__init__.py
 Comment: 
 
 Filename: regscale/core/__init__.py
 Comment: 
 
+Filename: regscale/core/login.py
+Comment: 
+
 Filename: regscale/core/app/__init__.py
 Comment: 
 
 Filename: regscale/core/app/api.py
 Comment: 
 
 Filename: regscale/core/app/application.py
@@ -96,14 +105,26 @@
 
 Filename: regscale/core/app/utils/catalog_utils/diagnostic_catalog.py
 Comment: 
 
 Filename: regscale/core/app/utils/catalog_utils/export_catalog.py
 Comment: 
 
+Filename: regscale/core/static/__init__.py
+Comment: 
+
+Filename: regscale/core/static/regex.py
+Comment: 
+
+Filename: regscale/core/utils/__init__.py
+Comment: 
+
+Filename: regscale/core/utils/urls.py
+Comment: 
+
 Filename: regscale/exceptions/__init__.py
 Comment: 
 
 Filename: regscale/exceptions/license_exception.py
 Comment: 
 
 Filename: regscale/integrations/__init__.py
@@ -147,14 +168,20 @@
 
 Filename: regscale/integrations/public/cisa.py
 Comment: 
 
 Filename: regscale/models/__init__.py
 Comment: 
 
+Filename: regscale/models/config.py
+Comment: 
+
+Filename: regscale/models/platform.py
+Comment: 
+
 Filename: regscale/models/app_models/__init__.py
 Comment: 
 
 Filename: regscale/models/app_models/catalog_compare.py
 Comment: 
 
 Filename: regscale/models/app_models/click.py
@@ -237,14 +264,23 @@
 
 Filename: regscale/models/regscale_models/threat.py
 Comment: 
 
 Filename: regscale/models/regscale_models/user.py
 Comment: 
 
+Filename: regscale/utils/__init__.py
+Comment: 
+
+Filename: regscale/utils/shell.py
+Comment: 
+
+Filename: regscale/utils/string.py
+Comment: 
+
 Filename: regscale/validation/__init__.py
 Comment: 
 
 Filename: regscale/validation/address.py
 Comment: 
 
 Filename: tests/mocks/__init__.py
@@ -255,26 +291,44 @@
 
 Filename: tests/mocks/response.py
 Comment: 
 
 Filename: tests/mocks/xml.py
 Comment: 
 
-Filename: RegScale_CLI-5.3.1.dist-info/LICENSE
+Filename: tests/regscale/__init__.py
+Comment: 
+
+Filename: tests/regscale/core/__init__.py
+Comment: 
+
+Filename: tests/regscale/core/test_login.py
+Comment: 
+
+Filename: tests/regscale/models/__init__.py
+Comment: 
+
+Filename: tests/regscale/models/test_config.py
+Comment: 
+
+Filename: tests/regscale/models/test_platform.py
+Comment: 
+
+Filename: RegScale_CLI-5.4.0.dist-info/LICENSE
 Comment: 
 
-Filename: RegScale_CLI-5.3.1.dist-info/METADATA
+Filename: RegScale_CLI-5.4.0.dist-info/METADATA
 Comment: 
 
-Filename: RegScale_CLI-5.3.1.dist-info/WHEEL
+Filename: RegScale_CLI-5.4.0.dist-info/WHEEL
 Comment: 
 
-Filename: RegScale_CLI-5.3.1.dist-info/entry_points.txt
+Filename: RegScale_CLI-5.4.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: RegScale_CLI-5.3.1.dist-info/top_level.txt
+Filename: RegScale_CLI-5.4.0.dist-info/top_level.txt
 Comment: 
 
-Filename: RegScale_CLI-5.3.1.dist-info/RECORD
+Filename: RegScale_CLI-5.4.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## regscale/__init__.py

```diff
@@ -1 +1 @@
-__version__ = "5.3.1"
+__version__ = "5.4.0"
```

## regscale/core/app/internal/admin_actions.py

```diff
@@ -72,14 +72,25 @@
 )
 def send_reminders(days: int):
     """
     Get Assessments, Issues, Tasks, Data Calls, Security Plans, and Workflows
     for the users that have email notifications enabled, email comes
     from support@regscale.com.
     """
+    get_and_send_reminders(days)
+
+
+def get_and_send_reminders(days: int = 30) -> None:
+    """
+    Function to get and send reminders for users in RegScale that have email notifications
+    enabled and have upcoming or outstanding Tasks, Assessments, Data Calls, Issues, Security Plans,
+    and Workflows
+    :param int days: # of days to look for upcoming and/or outstanding items, default is 30 days
+    :return: None
+    """
     app = check_license()
     api = Api(app)
     config = {}
     try:
         # load the config from YAML
         config = app.load_config()
     except FileNotFoundError:
@@ -221,203 +232,179 @@
         # format the date to a string the server will recognize
         before_date = before_date.strftime("%Y-%m-%dT%H:%M:%S")
         after_date = after_date.strftime("%Y-%m-%dT%H:%M:%S")
 
         # get all the assessments, issues, tasks, data calls, security plans and workflows
         # for the user we can email, using the # of days entered by the user using graphql,
         # if no days were entered, the default is 30 days
-        query = (
-            """
-        query {
-          assessments(
-            take: 50
-            skip: 0
-            order: { plannedFinish: DESC }
-            where: {
-              leadAssessorId: { eq: """
-            + f'"{user["id"]}"'
-            + """ }
-              plannedFinish: { lte: """
-            + f'"{before_date}"'
-            + """ }
-              status: { nin: ["Complete", "Cancelled"] }
-            }
-          ) {
-            items {
+        query = f"""
+            query {{
+              assessments(
+                take: 50
+                skip: 0
+                order: {{ plannedFinish: DESC }}
+                where: {{
+                  leadAssessorId: {{ eq: "{user["id"]}" }}
+              plannedFinish: {{ lte: "{before_date}" }}
+              status: {{ nin: ["Complete", "Cancelled"] }}
+            }}
+          ) {{
+            items {{
               uuid
               id
               title
               leadAssessorId
               assessmentType
               plannedFinish
               createdById
               dateCreated
               status
               assessmentResult
               actualFinish
-            }
+            }}
             totalCount
-            pageInfo {
+            pageInfo {{
               hasNextPage
-            }
-          }
+            }}
+          }}
           dataCalls(
             take: 50
             skip: 0
-            order: { dateDue: DESC }
-            where: {
-              createdById: { eq: """
-            + f'"{user["id"]}"'
-            + """ }
-              dateDue: { lte: """
-            + f'"{before_date}"'
-            + """ }
-              status: { nin: ["Completed", "Cancelled"] }
-            }
-          ) {
-            items {
+            order: {{ dateDue: DESC }}
+            where: {{
+              createdById: {{ eq: "{user["id"]}" }}
+              dateDue: {{ lte: "{before_date}" }}
+              status: {{ nin: ["Completed", "Cancelled"] }}
+            }}
+          ) {{
+            items {{
               uuid
               id
               title
               dataCallLeadId
               dateDue
               createdById
               dateCreated
               status
-            }
+            }}
             totalCount
-            pageInfo {
+            pageInfo {{
               hasNextPage
-            }
-          }
+            }}
+          }}
           securityPlans(
             take: 50
             skip: 0
-            order: { expirationDate: DESC }
-            where: {
-              systemOwnerId: { eq: """
-            + f'"{before_date}"'
-            + """ }
-              expirationDate: { lte: "2023-01-18T04:08:32" }
-            }
-          ) {
-            items {
+            order: {{ expirationDate: DESC }}
+            where: {{
+              systemOwnerId: {{ eq: "{user["id"]}" }}
+              expirationDate: {{ lte: "{before_date}" }}
+            }}
+          ) {{
+            items {{
               uuid
               id
               systemName
               systemOwnerId
               status
               systemType
               expirationDate
               overallCategorization
               createdById
               dateCreated
-            }
+            }}
             totalCount
-            pageInfo {
+            pageInfo {{
               hasNextPage
-            }
-          }
+            }}
+          }}
           workflowInstances(
             take: 50
             skip: 0
-            order: { startDate: DESC }
-            where: {
-              ownerId: { eq: """
-            + f'"{user["id"]}"'
-            + """ }
-              status: {neq: "Complete"}
-              startDate: { gte: """
-            + f'"{after_date}"'
-            + """ }
-              endDate: { eq: null }
-            }
-          ) {
-            items {
+            order: {{ startDate: DESC }}
+            where: {{
+              ownerId: {{ eq: "{user["id"]}" }}
+              status: {{ neq: "Complete" }}
+              startDate: {{ gte: "{after_date}" }}
+              endDate: {{ eq: null }}
+            }}
+          ) {{
+            items {{
               id
               name
               status
               startDate
               endDate
               comments
               currentStep
               createdById
               dateCreated
               lastUpdatedById
               ownerId
               atlasModule
               parentId
-            }
+            }}
             totalCount
-            pageInfo {
+            pageInfo {{
               hasNextPage
-            }
-          }
+            }}
+          }}
           tasks(
             take: 50
             skip: 0
-            order: { dueDate: DESC }
-            where: {
-              assignedToId: { eq: """
-            + f'"{user["id"]}"'
-            + """ }
-              dueDate: { lte: """
-            + f'"{before_date}"'
-            + """ }
-              status: { nin: ["Closed", "Cancelled"] }
-            }
-          ) {
-            items {
+            order: {{ dueDate: DESC }}
+            where: {{
+              assignedToId: {{ eq: "{user["id"]}" }}
+              dueDate: {{ lte: "{before_date}" }}
+              status: {{ nin: ["Closed", "Cancelled"] }}
+            }}
+          ) {{
+            items {{
               uuid
               id
               title
               assignedToId
               dueDate
               createdById
               status
               percentComplete
-            }
+            }}
             totalCount
-            pageInfo {
+            pageInfo {{
               hasNextPage
-            }
-          }
+            }}
+          }}
           issues(
             take: 50
             skip: 0
-            order: { dueDate: DESC }
-            where: {
-              issueOwnerId: { eq: """
-            + f'"{user["id"]}"'
-            + """ }
-              dueDate: { lte: """
-            + f'"{before_date}"'
-            + """ }
-              status: { nin: ["Closed", "Cancelled"] }
-            }
-          ) {
-            items {
+            order: {{ dueDate: DESC }}
+            where: {{
+              issueOwnerId: {{ eq: "{user["id"]}" }}
+              dueDate: {{ lte: "{before_date}" }}
+              status: {{ nin: ["Closed", "Cancelled"] }}
+            }}
+          ) {{
+            items {{
               uuid
               id
               title
               issueOwnerId
               severityLevel
               createdById
               dateCreated
               status
               dueDate
-            }
+            }}
             totalCount
-            pageInfo {
+            pageInfo {{
               hasNextPage
-            }
-          }
-        }
+            }}
+          }}
+        }}
         """
-        )
         # get the data from GraphQL
         res_data = api.graph(query=query)
 
         # create list that has dictionaries of the user's pipeline and categories
         pipelines = {
             "Assessments": {"Pipeline": res_data["assessments"]["items"]},
             "Issues": {"Pipeline": res_data["issues"]["items"]},
```

## regscale/core/app/internal/comparison.py

```diff
@@ -81,25 +81,45 @@
     type=click.STRING,
     help="Enter unique key to compare the files.",
     prompt="Enter the key/column to compare files",
     required=True,
 )
 @regscale_id()
 @regscale_module()
-def compare_files(
+def compare_files_cli(
     old_file: str,
     new_file: str,
     most_recent_in_file_path: Path,
     most_recent_file_type: str,
     key: str,
     regscale_id: int,
     regscale_module: str,
 ):
     """Compare the two given files while using the provided key for any differences.
     Supports csv, xls and xlsx files."""
+    compare_files(
+        old_file=old_file,
+        new_file=new_file,
+        most_recent_in_file_path=most_recent_in_file_path,
+        most_recent_file_type=most_recent_file_type,
+        key=key,
+        regscale_id=regscale_id,
+        regscale_module=regscale_module,
+    )
+
+
+def compare_files(
+    key: str,
+    regscale_id: int,
+    regscale_module: str,
+    old_file: str = None,
+    new_file: str = None,
+    most_recent_in_file_path: Path = None,
+    most_recent_file_type: str = None,
+):
     app = check_license()
     api = Api(app)
 
     # see if provided RegScale Module is an accepted option
     verify_provided_module(regscale_module)
 
     # see if most_recent_in argument was used, get the old and new file
```

## regscale/core/app/internal/migrations.py

```diff
@@ -1,114 +1,149 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """Performs data processing for bulk processing"""
 
 # standard python imports
-import json
-from os import sep
+from pathlib import Path
 from typing import Tuple
 
 import click
 import requests
 
 from regscale.core.app.api import Api
 from regscale.core.app.application import Application
 from regscale.core.app.logz import create_logger
 from regscale.core.app.utils.app_utils import (
     check_file_path,
     create_progress_object,
+    error_and_exit,
     save_data_to,
 )
 from regscale.core.app.utils.regscale_utils import get_all_from_module
 from regscale.core.app.utils.threadhandler import create_threads, thread_assignment
 
-app = Application()
-config = app.config
-api = Api(app)
-
-logger = create_logger()
 job_progress = create_progress_object()
 process_counter = []
 
 
 @click.group()
 def migrations():
     """Performs data processing for legacy data to migrate data formats or perform bulk processing."""
 
 
 @migrations.command(name="inheritance_converter")
 def inheritance_converter():
     """
     Migrates all data from legacy one to one system to the new one to many system.
     """
+    convert_inheritance()
+
+
+@migrations.command(name="issue_linker")
+def issue_linker():
+    """
+    Provides linkage to the lineage of the issue (deep links to parent records in the tree).
+    """
+    link_issues()
+
+
+@migrations.command(name="assessment_linker")
+def assessment_linker():
+    """
+    Provides linkage to the lineage of the assessment (deep links to parent records in the tree).
+    """
+    link_assessments()
+
+
+@migrations.command(name="risk_linker")
+def risk_linker():
+    """
+    Provides linkage to the lineage of the risk (deep links to parent records in the tree).
+    """
+    link_risks()
+
+
+def convert_inheritance() -> None:
+    """
+    Migrates all data from legacy one to one system to the new one to many system
+    :return: None
+    """
+    app = Application()
+    config = app.config
+    api = Api(app)
+
+    logger = create_logger()
     # retrieve all inherited controls
     try:
-        logger.info("Retrieving all existing inherited controls")
-        inheritedControls = api.get(
+        logger.info("Retrieving all existing inherited controls.")
+        inherited_controls = api.get(
             url=config["domain"] + "/api/inheritance/getAllInheritedControls"
         ).json()
         logger.info(
-            "%s inherited controls retrieved from RegScale.", len(inheritedControls)
+            "%i inherited controls retrieved from RegScale.", len(inherited_controls)
         )
     except requests.exceptions.RequestException as ex:
         logger.error("Unable to retrieve inherited controls\n%s", ex)
 
     # output inherited controls list
-    with open("./artifacts/inheritedControls.json", "w") as outfile:
-        outfile.write(json.dumps(inheritedControls, indent=4))
-
+    save_data_to(
+        file=Path("./artifacts/inheritedControls.json"),
+        data=inherited_controls,
+    )
     # loop through each inherited control
-    inhNewCTRLs = []
-    for inh in inheritedControls:
-        bPublic = 0
-        if inh["isPublic"] is True:
-            bPublic = 1
+    new_inherited_controls = []
+    for inherited_control in inherited_controls:
         # create new control and map to new schema
-        newCTRL = {
+        new_control = {
             "id": 0,
-            "isPublic": bPublic,
-            "parentId": int(inh["parentId"]),
-            "parentModule": inh["parentModule"],
-            "baseControlId": int(inh["id"]),
-            "inheritedControlId": int(inh["inheritedControlId"]),
+            "isPublic": inherited_control["isPublic"] is True,
+            "parentId": int(inherited_control["parentId"]),
+            "parentModule": inherited_control["parentModule"],
+            "baseControlId": int(inherited_control["id"]),
+            "inheritedControlId": int(inherited_control["inheritedControlId"]),
         }
-        inhNewCTRLs.append(newCTRL)
+        new_inherited_controls.append(new_control)
 
     # output the new control list
-    with open("./artifacts/inheritedControlMappings.json", "w") as outfile:
-        outfile.write(json.dumps(inhNewCTRLs, indent=4))
-    logger.info("%s controls remapped to new inheritance engine", len(inhNewCTRLs))
+    save_data_to(
+        file=Path("./artifacts/inheritedControlMappings.json"),
+        data=new_inherited_controls,
+    )
+    logger.info(
+        "%i controls remapped to new inheritance engine", len(new_inherited_controls)
+    )
 
     # loop through and create each controls
-    inheritanceNew = []
+    new_inheritance = []
     logger.info("Beginning the process to upload and create new Inherited controls")
     url_inheritance = f'{config["domain"]}/api/inheritedControls'
-    for n in inhNewCTRLs:
+    for n in new_inherited_controls:
         try:
             print(n)
             response = api.post(url_inheritance, json=n)
-            newControl = response.json()
-            logger.info("New inherited control mapping: %s", newControl["id"])
-            inheritanceNew.append(newControl)
+            created_control = response.json()
+            logger.info("New inherited control mapping: %s", created_control["id"])
+            new_inheritance.append(created_control)
         except requests.exceptions.RequestException as ex:
-            print(ex)
-            logger.error("Unable to save new inherited control")
-            quit()
+            error_and_exit(f"Unable to save new inherited control.\n{ex}")
 
     # output the new control list
-    with open("./artifacts/newInheritedControlMappings.json", "w") as outfile:
-        outfile.write(json.dumps(inheritanceNew, indent=4))
-    logger.info("%s controls saved to the new inheritance system", len(inheritanceNew))
+    save_data_to(
+        file=Path("./artifacts/newInheritedControlMappings.json"),
+        data=new_inheritance,
+    )
+    logger.info("%i controls saved to the new inheritance system", len(new_inheritance))
 
 
-@migrations.command(name="issue_linker")
-def issue_linker():
+def link_issues() -> None:
     """
     Provides linkage to the lineage of the issue (deep links to parent records in the tree).
+    :return: None
     """
+    logger = create_logger()
     module = "issues"
 
     api, regscale_issues = initialize_and_fetch_data(module)
 
     with job_progress:
         # create task to process issues
         processing_issues = job_progress.add_task(
@@ -128,19 +163,20 @@
             "%s/%s %s processed from RegScale.",
             len(process_counter),
             len(regscale_issues),
             module.title(),
         )
 
 
-@migrations.command(name="assessment_linker")
-def assessment_linker():
+def link_assessments() -> None:
     """
     Provides linkage to the lineage of the assessment (deep links to parent records in the tree).
+    :return: None
     """
+    logger = create_logger()
     module = "assessments"
 
     api, regscale_assessments = initialize_and_fetch_data(module)
 
     with job_progress:
         # create task to process issues
         processing_issues = job_progress.add_task(
@@ -160,19 +196,20 @@
             "%s/%s %s processed from RegScale.",
             len(process_counter),
             len(regscale_assessments),
             module.title(),
         )
 
 
-@migrations.command(name="risk_linker")
-def risk_linker():
+def link_risks() -> None:
     """
     Provides linkage to the lineage of the risk (deep links to parent records in the tree).
+    :return: None
     """
+    logger = create_logger()
     module = "risks"
 
     api, regscale_risks = initialize_and_fetch_data(module)
 
     with job_progress:
         # create task to process issues
         processing_issues = job_progress.add_task(
@@ -185,15 +222,15 @@
             process=process_data,
             args=(api, regscale_risks, module, processing_issues),
             thread_count=len(regscale_risks),
         )
 
         # notify user of outcome
         logger.info(
-            "%s/%s %s processed from RegScale.",
+            "%i/%i %s processed from RegScale.",
             len(process_counter),
             len(regscale_risks),
             module.title(),
         )
 
 
 def initialize_and_fetch_data(module: str) -> Tuple[Api, list[dict]]:
@@ -203,46 +240,47 @@
     :param str module: python module
     :return: Tuple[Api object, list of data of provided module from RegScale API]
     :rtype: Tuple[Api, list[dict]]
     """
     # load the config from YAML
     app = Application()
     api = Api(app)
+    logger = create_logger()
 
     # get the data of provided module from RegScale via API
     regscale_data = get_all_from_module(api=api, module=module)
 
     # verify artifacts folder exists
     check_file_path("artifacts")
 
     # write out risks data to file
     save_data_to(
-        file_name=f"artifacts{sep}RegScale{module.title()}",
-        file_type=".json",
+        file=Path(f"./artifacts/RegScale{module.title()}.json"),
         data=regscale_data,
     )
     logger.info(
         "Writing out RegScale risk list to the artifacts folder (see RegScale%sList.json).",
         module.title(),
     )
     logger.info(
-        "%s %s retrieved for processing from RegScale.", len(regscale_data), module
+        "%i %s retrieved for processing from RegScale.", len(regscale_data), module
     )
     return api, regscale_data
 
 
 def process_data(args: Tuple, thread: int) -> None:
     """
     Function to utilize threading and process the data from RegScale
     :param Tuple args: Tuple of args to use during the process
     :param int thread: Thread number of current thread
     :raises: General error if unable to retrieve data from RegScale API
     :return: None
     """
     # set up local variables from args passed
+    logger = create_logger()
     api, regscale_data, module, task = args
 
     # find which records should be executed by the current thread
     threads = thread_assignment(thread=thread, total_items=len(regscale_data))
     # iterate through the thread assignment items and process them
     for i in range(len(threads)):
         # set the recommendation for the thread for later use in the function
@@ -257,9 +295,9 @@
                 "Processing %s #: %s Result: %s",
                 module[:-1].title(),
                 item["id"],
                 process_result.text,
             )
             process_counter.append(item)
         except Exception:
-            logger.error("Unable to process Issue # %s.", item["id"])
+            logger.error("Unable to process Issue # %i.", item["id"])
         job_progress.update(task, advance=1)
```

## regscale/core/app/public/emass.py

```diff
@@ -21,30 +21,53 @@
     error_and_exit,
     get_current_datetime,
     get_file_type,
     reformat_str_date,
 )
 from regscale.models import regscale_id
 
-logger = create_logger()
 SKIP_ROWS: int = 7
 COLUMNS = ["L", "M", "N", "O"]
-job_progress = create_progress_object()
 
 
 @click.group()
 def emass():
     """[BETA] Performs bulk processing of eMASS files (Upload trusted data only)."""
 
 
 @emass.command("get_template")
 def get_template():
     """
     Fetch a template for the eMASS controls document
     """
+    fetch_template_from_blob()
+
+
+@emass.command("populate_controls")
+@click.option(
+    "--file_name",
+    type=click.Path(exists=True, dir_okay=False, file_okay=True),
+    required=True,
+    prompt="Enter the full file path of the eMASS controls document.",
+    help="Enter the full file path of the eMASS controls document to populate with RegScale data.",
+)
+@regscale_id(help="Enter the desired SSP ID # from RegScale.")
+def populate_workbook(file_name: click.Path, regscale_id: int) -> None:
+    """
+    [BETA] Populate controls from a System Security Plan in RegScale into an eMASS formatted excel workbook.
+    """
+    populate_emass_workbook(file_name=file_name, regscale_id=regscale_id)
+
+
+def fetch_template_from_blob() -> None:
+    """
+    Fetch a template for the eMASS controls document
+    :return: None
+    """
+    logger = create_logger()
     app = Application()
     api = Api(app)
 
     # check if the artifacts folder exists
     check_file_path("artifacts")
 
     # get the template from the API
@@ -55,27 +78,22 @@
 
     # write the template to a file
     with open(f".{os.sep}artifacts{os.sep}eMASS_Template.xlsx", "wb") as f:
         f.write(template.content)
     logger.info(f"Template saved to .{os.sep}artifacts{os.sep}eMASS_Template.xlsx")
 
 
-@emass.command("populate_controls")
-@click.option(
-    "--file_name",
-    type=click.Path(exists=True, dir_okay=False, file_okay=True),
-    required=True,
-    prompt="Enter the full file path of the eMASS controls document.",
-    help="Enter the full file path of the eMASS controls document to populate with RegScale data.",
-)
-@regscale_id(help="Enter the desired SSP ID # from RegScale.")
-def populate_workbook(file_name: click.Path, regscale_id: int) -> None:
+def populate_emass_workbook(file_name: Path, regscale_id: int) -> None:
     """
-    [BETA] Populate controls from a System Security Plan in RegScale into an eMASS formatted excel workbook.
+    Function to populate an eMASS workbook with control assessments from RegScale
+    :param Path file_name: Path to the eMASS control workbook
+    :param int regscale_id: ID of the SSP in RegScale to get the controls & assessments from
+    :return: None
     """
+    logger = create_logger()
     # make sure the user gave a path to an Excel workbook
     if get_file_type(file_name) not in [".xlsx", ".xls"]:
         error_and_exit(
             "Please provide a file path to an Excel workbook in .xlsx or .xls format."
         )
 
     # convert file_name to a Path object
@@ -128,53 +146,51 @@
     Populate controls from a System Security Plan in RegScale into an eMASS formatted excel workbook
     :param Path file_name: path to the Excel workbook to populate with controls from SSP
     :param int ssp_id: ID for a System Security Plan from RegScale
     :param Api api: API Object
     :return: Path to output file
     :rtype: Path
     """
+    job_progress = create_progress_object()
+    logger = create_logger()
     # create the GraphQL query
-    query = (
-        """
-    query {
-      controls:controlImplementations(
-        take: 50
-        skip: 0
-        where: {
-          parentId: { eq: """
-        + str(ssp_id)
-        + """ }
-          parentModule: { eq: "securityplans" }
-          assessments: { any: true }
-        }
-      ) {
-        items {
+    query = f"""
+        query {{
+          controls:controlImplementations(
+            take: 50
+            skip: 0
+            where: {{
+              parentId: {{ eq: {ssp_id} }}
+          parentModule: {{ eq: "securityplans" }}
+          assessments: {{ any: true }}
+        }}
+      ) {{
+        items {{
           id
-          control {
+          control {{
             controlId
-          }
-          assessments {
+          }}
+          assessments {{
             id
             actualFinish
             assessmentResult
             summaryOfResults
-            leadAssessor {
+            leadAssessor {{
               firstName
               lastName
-            }
-          }
-        }
+            }}
+          }}
+        }}
         totalCount
-        pageInfo {
+        pageInfo {{
           hasNextPage
-        }
-      }
-    }
+        }}
+      }}
+    }}
     """
-    )
 
     # get the data from GraphQL
     response = api.graph(query=query)
 
     # try to get the items from the GraphQL response
     try:
         controls = response["controls"]["items"]
```

## regscale/core/app/public/nist_catalog.py

```diff
@@ -1,14 +1,14 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """ Module to allow sorting nist catalog controls into RegScale """
 
 # standard python imports
 import re
-from os import sep
+from pathlib import Path
 from typing import Tuple
 
 import click
 from requests import JSONDecodeError
 
 from regscale.core.app.api import Api, normalize_url
 from regscale.core.app.application import Application
@@ -18,32 +18,18 @@
     check_file_path,
     save_data_to,
     create_progress_object,
 )
 from regscale.core.app.utils.threadhandler import create_threads, thread_assignment
 
 # initialize Application and Api objects
-app = Application()
-api = Api(app)
-config = app.config
+
 logger = create_logger()
 job_progress = create_progress_object()
 
-# update api limits depending on maxThreads
-api.pool_connections = (
-    config["maxThreads"]
-    if api.pool_connections < config["maxThreads"]
-    else api.pool_connections
-)
-api.pool_maxsize = (
-    config["maxThreads"]
-    if api.pool_maxsize < config["maxThreads"]
-    else api.pool_maxsize
-)
-
 # create global variables for threads to store successful
 # and failed control updates
 updated_controls, failed_controls = [], []
 
 
 @click.group()
 def nist():
@@ -65,14 +51,28 @@
 
 def sort_controls_by_id(catalog_id: int) -> None:
     """
     Sort the provided catalog's controls in RegScale with the provided ID #
     :param int catalog_id: ID # of the catalog in RegScale to sort controls for
     :return: None
     """
+    app = Application()
+    api = Api(app)
+    config = app.config
+    # update api limits depending on maxThreads
+    api.pool_connections = (
+        config["maxThreads"]
+        if api.pool_connections < config["maxThreads"]
+        else api.pool_connections
+    )
+    api.pool_maxsize = (
+        config["maxThreads"]
+        if api.pool_maxsize < config["maxThreads"]
+        else api.pool_maxsize
+    )
     security_control_count: int = 0
 
     # get all controls by catalog
     url_controls_get_all = (
         f"{app.config['domain']}/api/SecurityControls/getAllByCatalog/{catalog_id}"
     )
 
@@ -96,16 +96,15 @@
         )
         error_and_exit(
             f"No controls were received for catalog #{catalog_id}.\nPlease verify: {catalog_url}"
         )
     # verify artifacts directory exists before saving the received security controls
     check_file_path("artifacts")
     save_data_to(
-        file_name=f"artifacts{sep}regscale-catalog-{catalog_id}-controls",
-        file_type=".json",
+        file=Path(f"./artifacts/regscale-catalog-{catalog_id}-controls.json"),
         data=security_control_data,
     )
 
     # loop over the controls - original split with hyphen
     sorted_controls: list = []
     for control in security_control_data:
         # get the original sort ID
@@ -121,16 +120,15 @@
             else:
                 control_new_number = original_id
             control["sortId"] = control_new_number
             sorted_controls.append(control_new_number)
 
     # output the RegScale controls
     save_data_to(
-        file_name=f"artifacts{sep}catalog-{catalog_id}-sorted-control-ids",
-        file_type=".json",
+        file=Path(f"artifacts/catalog-{catalog_id}-sorted-control-ids.json"),
         data=sorted_controls,
     )
 
     # loop over the controls - second sort with period
     second_sort = []
     for ctrl in security_control_data:
         # get the original sort ID
@@ -149,16 +147,15 @@
             ctrl["sortId"] = control_new_number
             second_sort.append(control_new_number)
         else:
             second_sort.append(ctrl["sortId"])
 
     # output the RegScale controls
     save_data_to(
-        file_name=f"artifacts{sep}second-sorted-control-ids",
-        file_type=".json",
+        file=Path("./artifacts/second-sorted-control-ids.json"),
         data=second_sort,
     )
 
     # create threads to process all controls
     with job_progress:
         logger.info(
             "%s security control(s) will be updated.",
@@ -167,15 +164,15 @@
         # create progress bar and update the controls in RegScale
         updating_controls = job_progress.add_task(
             f"[#f8b737]Updating {security_control_count} security control(s)...",
             total=security_control_count,
         )
         create_threads(
             process=update_security_controls,
-            args=(security_control_data, updating_controls),
+            args=(security_control_data, api, updating_controls),
             thread_count=security_control_count,
         )
     # output the result
     logger.info(
         "Updated %s/%s control(s) successfully with %s failure(s).",
         security_control_count,
         len(updated_controls),
@@ -187,25 +184,25 @@
     """
     Function to utilize threading and update security controls in RegScale
     :param Tuple args: Tuple of args to use during the process
     :param int thread: Thread number of current thread
     :return: None
     """
     # set up local variables from args passed
-    security_control_data, task = args
+    security_control_data, api, task = args
 
     # find which records should be executed by the current thread
     threads = thread_assignment(thread=thread, total_items=len(security_control_data))
 
     # iterate through the thread assignment items and process them
     for i in range(len(threads)):
         # set the control for the thread & update it in RegScale
         control = security_control_data[threads[i]]
 
-        control_url = f'{config["domain"]}/api/SecurityControls/{control["id"]}'
+        control_url = f'{api.config["domain"]}/api/SecurityControls/{control["id"]}'
 
         # update control in RegScale
         response = api.put(control_url, json=control)
 
         # verify update was successful
         if response.status_code == 200:
             logger.debug(
```

## regscale/core/app/public/oscal.py

```diff
@@ -6,15 +6,14 @@
 import dataclasses
 import json
 import re
 import tempfile
 import uuid
 from os import remove, sep
 from pathlib import Path
-from subprocess import CalledProcessError, run
 from typing import Tuple
 
 import click
 import pandas as pd
 import requests
 import xmltodict
 import yaml
@@ -28,20 +27,19 @@
     check_file_path,
     create_progress_object,
     error_and_exit,
     find_keys,
     get_file_name,
     reformat_str_date,
     save_data_to,
-    check_url,
 )
 from regscale.core.app.utils.threadhandler import create_threads, thread_assignment
-from regscale.models.regscale_models.security_control import SecurityControl
 from regscale.models.regscale_models.components import Component
 from regscale.models.regscale_models.control_implementation import ControlImplementation
+from regscale.models.regscale_models.security_control import SecurityControl
 
 # create global variables
 job_progress = create_progress_object()
 logger = create_logger()
 app = Application()
 config = app.config
 api = Api(app)
@@ -586,16 +584,15 @@
                 "title": citation,
                 "links": links,
             }
             resources.append(res)
 
     # Write to file to visualize the output
     save_data_to(
-        file_name=f"processing{sep}resources",
-        file_type=".json",
+        file=Path("./processing/resources.json"),
         data=resources,
         output_log=False,
     )
     # convert data to pandas dataframe
     raw_data = pd.DataFrame(resources)
 
     # copy the columns of data that we want while renaming them to a specific case
@@ -759,56 +756,50 @@
                     "parentControl": obj["parentControl"],
                 }
                 assessments.append(new_test)
         objectives = processed_objectives
 
     # Write to file to visualize the output
     save_data_to(
-        file_name=f"processing{sep}families",
-        file_type=".json",
+        file=Path("./processing/families.json"),
         data=families,
         output_log=False,
     )
 
     # Write to file to visualize the output
     save_data_to(
-        file_name=f"processing{sep}controls",
-        file_type=".json",
+        file=Path("./processing/controls.json"),
         data=oscal_controls,
         output_log=False,
     )
 
     # Write to file to visualize the output
     save_data_to(
-        file_name=f"processing{sep}parameters",
-        file_type=".json",
+        file=Path("./processing/parameters.json"),
         data=parameters,
         output_log=False,
     )
 
     # Write to file to visualize the output
     save_data_to(
-        file_name=f"processing{sep}parts",
-        file_type=".json",
+        file=Path("./processing/parts.json"),
         data=parts,
         output_log=False,
     )
 
     # Write to file to visualize the output
     save_data_to(
-        file_name=f"processing{sep}tests",
-        file_type=".json",
+        file=Path("./processing/tests.json"),
         data=assessments,
         output_log=False,
     )
 
     # Write to file to visualize the output
     save_data_to(
-        file_name=f"processing{sep}objectives",
-        file_type=".json",
+        file=Path("./processing/objectives.json"),
         data=objectives,
         output_log=False,
     )
 
     # output the items processed from the provided OSCAL catalog
     logger.info(
         "%s familys, %s controls, %s parameters, %s objectives %s parts & %s assessments processed from %s.",
@@ -849,24 +840,22 @@
             logger.info(
                 "%s/%s OSCAL controls created in RegScale.",
                 len(new_regscale_controls),
                 len(oscal_controls),
             )
             # Write to file to visualize the output
             save_data_to(
-                file_name=f"processing{sep}mappedControls",
-                file_type=".json",
+                file=Path("./processing/mappedControls.json"),
                 data=new_controls,
                 output_log=False,
             )
         # Write to file to visualize the output
         if upload_flag:
             save_data_to(
-                file_name=f"processing{sep}newControls",
-                file_type=".json",
+                file=Path("./processing/newControls.json"),
                 data=new_regscale_controls,
                 output_log=False,
             )
         else:
             with open(
                 f"processing{sep}newControls.json", "r", encoding="utf-8-sig"
             ) as infile:
@@ -898,16 +887,15 @@
                     "%s/%s OSCAL parameters created in RegScale.",
                     len(new_params),
                     len(parameters),
                 )
 
                 # output the result
                 save_data_to(
-                    file_name=f"processing{sep}newParameters",
-                    file_type=".json",
+                    file=Path("processing/newParameters.json"),
                     data=new_params,
                     output_log=False,
                 )
             if assessments:
                 # log the information
                 logger.debug("Posting %s assessments to RegScale.", len(assessments))
                 # create task for creating assessments
@@ -925,16 +913,15 @@
                         config,
                         assigning_tests,
                     ),
                     thread_count=len(assessments),
                 )
                 # output the result
                 save_data_to(
-                    file_name=f"processing{sep}newTests",
-                    file_type=".json",
+                    file=Path("./processing/newTests.json"),
                     data=new_tests,
                     output_log=False,
                 )
                 # log the outcome
                 logger.info(
                     "%s/%s assessments created in RegScale.",
                     len(new_tests),
@@ -976,16 +963,15 @@
 
                     # log the outcome
                     logger.info(
                         "%s objectives created in RegScale.", len(new_objectives)
                     )
                     # output the result
                     save_data_to(
-                        file_name=f"processing{sep}newObjectives",
-                        file_type=".json",
+                        file=Path("./processing/newObjectives.json"),
                         data=new_objectives,
                         output_log=False,
                     )
             else:
                 # log the information
                 logger.debug(
                     "Analyzing %s objectives for posting to RegScale.", len(objectives)
@@ -1052,16 +1038,15 @@
                     "%s objectives analyzed & %s objectives updated in RegScale.",
                     len(obj_list),
                     len(updates),
                 )
             if errors:
                 # output the errors
                 save_data_to(
-                    file_name=f"processing{sep}errors",
-                    file_type=".json",
+                    file=Path("./processing/errors.json"),
                     data=new_objectives,
                 )
             if obj_to_controls:
                 # create task for creating objectives
                 inserting_controls_from_objectives = job_progress.add_task(
                     f"[#c42843]Creating {len(new_objectives)} control(s) from objectives..."
                 )
```

## regscale/core/app/utils/app_utils.py

```diff
@@ -421,81 +421,80 @@
                 # If you have chunk encoded response uncomment if
                 # and set chunk_size parameter to None.
                 # if chunk:
                 file.write(chunk)
     return path / local_filename
 
 
-def save_data_to(file_name: str, file_type: str, data, output_log: bool = True) -> None:
+def save_data_to(file: Path, data, output_log: bool = True) -> None:
     """
     Function to save the provided data to the provided file_name and file_type
-    :param str file_name: Desired name to save the file as
-    :param str file_type: Desired file type
+    :param Path file: Path to the file to save the data to
     :param data: The data to save to the file
     :param bool output_log: Output info in console during function's execution, defaults to True
     :raises: PermissionError if the file already exists and is opened
     :raises: TypeError if data provided for json cannot be converted to a json object
     :raises: General Error if unable to save json data with .write() after trying json.dump() method
     :return: None
     """
     # check the file type, so we can export the data to the correct file
-    if file_type.lower() not in [".csv", ".json", ".xlsx"]:
+    if file.suffix.lower() not in [".csv", ".json", ".xlsx"]:
         # notify the user an incorrect file type was provided
-        error_and_exit(f"Unsupported file type provided, {file_type} is not supported.")
+        error_and_exit(
+            f"Unsupported file type provided, {file.suffix} is not supported."
+        )
     if output_log:
-        logger.info("Prepping data to be saved to %s%s", file_name, file_type)
+        logger.info("Prepping data to be saved to %s", file.name)
     try:
-        if file_type.lower() == ".csv":
+        if file.suffix.lower() == ".csv":
             # convert the provided data to a pandas dataframe
             d_frame = pd.DataFrame(data)
 
             # transpose the dataset
             d_frame = d_frame.transpose()
 
             # try to save the data as a csv file
-            d_frame.to_csv(file_name + file_type)
+            d_frame.to_csv(file)
             if output_log:
-                logger.info("Data successfully saved to: %s%s", file_name, file_type)
-        elif file_type.lower() == ".xlsx":
+                logger.info("Data successfully saved to: %s", file.name)
+        elif file.suffix.lower() == ".xlsx":
             # convert the provided data to a pandas dataframe
             d_frame = pd.DataFrame(data)
 
             # transpose the dataset
             d_frame = d_frame.transpose()
 
-            d_frame.to_excel(file_name + file_type)
+            d_frame.to_excel(file)
             if output_log:
-                logger.info("Data successfully saved to: %s%s", file_name, file_type)
-        elif file_type.lower() == ".json":
+                logger.info("Data successfully saved to: %s", file.name)
+        elif file.suffix.lower() == ".json":
             try:
-                with open(file_name + file_type, "w", encoding="utf-8") as outfile:
+                with open(file, "w", encoding="utf-8") as outfile:
                     json.dump(data, outfile, indent=4)
                 if output_log:
-                    logger.info("Data successfully saved to %s%s", file_name, file_type)
+                    logger.info("Data successfully saved to %s", file.name)
             except json.JSONDecodeError as err:
                 error_and_exit(
-                    f"Unable to save {file_name}{file_type} due to a decode error.\n{err}\n{data}"
+                    f"Unable to save {file.name} due to a decode error.\n{err}\n{data}"
                 )
             except TypeError:
                 try:
-                    with open(file_name, "w", encoding="utf-8") as outfile:
+                    with open(file, "w", encoding="utf-8") as outfile:
                         outfile.write(data)
                     if output_log:
-                        logger.info(
-                            "Data successfully saved to %s%s", file_name, file_type
-                        )
+                        logger.info("Data successfully saved to %s", file.name)
                 except Exception as err:
                     error_and_exit(
-                        f"Unable to save {file_name}{file_type} due to an unexpected error.\
+                        f"Unable to save {file.name} due to an unexpected error.\
                             \nError: {err}\n{data}"
                     )
     except PermissionError:
         # notify user unable to save because the file is open
         error_and_exit(
-            f"Unable to save {file_name}{file_type}. Please verify it is closed and try again."
+            f"Unable to save {file.name}. Please verify it is closed and try again."
         )
 
 
 def remove_nested_dict(data: dict, skip_keys: list = None) -> dict:
     """
     Function to remove nested dictionaries in the provided dictionary,
     also allows the option to remove a key from the provided dictionary
```

## regscale/core/app/utils/catalog_utils/export_catalog.py

```diff
@@ -1,22 +1,23 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """ Add functionality to export catalog via API."""
 
 # Standard Imports
 import operator
 import sys
+from pathlib import Path
 
 import click  # type: ignore
 import requests  # type: ignore
 
 from regscale.core.app.api import Api
 from regscale.core.app.application import Application
-from regscale.core.app.utils.app_utils import save_data_to
 from regscale.core.app.logz import create_logger
+from regscale.core.app.utils.app_utils import save_data_to
 from regscale.models.app_models.catalog_compare import CatalogCompare
 
 
 def display_menu() -> None:
     """
     Function to display the menu for the catalog export and handle exporting the selected catalog
     :return: None
@@ -59,16 +60,15 @@
                 logger.warning(
                     "This is a paid catalog, please contact RegScale customer support."
                 )
                 sys.exit()
             break
     new_catalog = get_new_catalog(url=download_url)
     save_data_to(
-        file_name=f"{catalog_name}",
-        file_type=".json",
+        file=Path(f"{catalog_name}.json"),
         data=new_catalog,
     )
 
 
 def get_new_catalog(url: str) -> dict:
     """
     Function to download a catalog via API call
```

## regscale/integrations/commercial/ad.py

```diff
@@ -1,15 +1,15 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """ Integrate Azure Active Directory in RegScale """
 
 
 # standard python imports
 from json import JSONDecodeError
-from os import sep
+from pathlib import Path
 
 import click
 import msal
 
 from regscale import __version__
 from regscale.core.app.api import Api
 from regscale.core.app.application import Application
@@ -186,16 +186,15 @@
             error_and_exit(f"Unknown Error! {ex}\nData: {groups_data}")
 
     # verify artifacts directory exists
     check_file_path("artifacts")
 
     # save group data to a json file
     save_data_to(
-        file_name=f"artifacts{sep}RegScale-AD-groups",
-        file_type=".json",
+        file=Path(f"./artifacts/RegScale-AD-groups.json"),
         data=groups_data,
     )
 
 
 # retrieves the RegScale groups from Azure AD
 # flake8: noqa: C901
 def get_group(str_group: str) -> None:
@@ -242,16 +241,15 @@
             f"Unable to retrieve group information from Azure Active Directory.\n{ex}"
         )
     # verify artifacts directory exists
     check_file_path("artifacts")
 
     # save group data to json file
     save_data_to(
-        file_name=f"artifacts{sep}adGroupList-{str_group}",
-        file_type=".json",
+        file=Path(f"./artifacts/adGroupList-{str_group}.json"),
         data=groups_data,
     )
 
     # loop through each group to find admins
     if len(groups_data) == 0:
         error_and_exit(f"{str_group} group has not been setup yet in Azure AD.")
     else:
@@ -284,16 +282,15 @@
                 f"Unable to retrieve member list for Azure Active Directory group - {group_id}."
             )
         # verify artifacts directory exists
         check_file_path("artifacts")
 
         # save member data to json file
         save_data_to(
-            file_name=f"artifacts{sep}adMemberList-{group_id}",
-            file_type=".json",
+            file=Path(f"./artifacts/adMemberList-{group_id}.json"),
             data=member_data,
         )
         logger.info(member_data)
         # retrieve the list of RegScale users
         url_users = f'{config["domain"]}/api/accounts/getList'
         try:
             user_response = api.get(url_users)
@@ -341,22 +338,18 @@
                 disable_flag = True
                 for m in member_data["value"]:
                     if m["id"] == u["externalId"]:
                         disable_flag = False
                 if disable_flag:
                     remove_users.append(u)
         # write out new user list to file
-        save_data_to(
-            file_name=f"artifacts{sep}newUsers", file_type=".json", data=new_users
-        )
+        save_data_to(file=Path(f"./artifacts/newUsers.json"), data=new_users)
 
         # write out disabled user list to file
-        save_data_to(
-            file_name=f"artifacts{sep}removeUsers", file_type=".json", data=remove_users
-        )
+        save_data_to(file=Path(f"./artifacts/removeUsers.json"), data=remove_users)
 
         # Logging
         logger.info("%s new user(s) to process.", str(len(new_users)))
 
         # loop through each user
         regscale_new = []
         for us in new_users:
@@ -370,16 +363,15 @@
             except Exception as ex:
                 error_and_exit(
                     f"Unable to create new user {us['userName']}.\nError: {ex}"
                 )
 
         # write out new user list to file
         save_data_to(
-            file_name=f"artifacts{sep}newRegScaleUsers",
-            file_type=".json",
+            file=Path(f"./artifacts/newRegScaleUsers.json"),
             data=regscale_new,
         )
 
         # set the role
         user_role = ""
         if str_group == "RegScale-admin":
             user_role = "Administrator"
```

## regscale/integrations/commercial/jira.py

```diff
@@ -1,14 +1,14 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """ Jira integration for RegScale CLI """
 
 # Standard python imports
 from json import JSONDecodeError
-from os import sep
+from pathlib import Path
 from typing import Tuple
 
 import click
 import requests
 from jira import JIRA
 
 from regscale.core.app.api import Api
@@ -25,14 +25,16 @@
 from regscale.models import regscale_id, regscale_module
 
 # global variables
 job_progress = create_progress_object()
 logger = create_logger()
 update_issues = []
 update_counter = []
+
+
 #####################################################################################################
 #
 # PROCESS ISSUES TO JIRA
 # JIRA CLI Python Docs: https://jira.readthedocs.io/examples.html#issues
 # JIRA API Docs: https://developer.atlassian.com/server/jira/platform/jira-rest-api-examples/
 #
 #####################################################################################################
@@ -60,15 +62,34 @@
     help="Enter the Jira issue type to use when creating new issues from RegScale.",
     prompt="Enter the Jira issue type",
     required=True,
 )
 def issues(
     regscale_id: int, regscale_module: str, jira_project: str, jira_issue_type: str
 ):
-    """Process issues to Jira."""
+    """Sync issues from Jira into RegScale."""
+    sync_issues_from_jira(
+        regscale_id=regscale_id,
+        regscale_module=regscale_module,
+        jira_project=jira_project,
+        jira_issue_type=jira_issue_type,
+    )
+
+
+def sync_issues_from_jira(
+    regscale_id: int, regscale_module: str, jira_project: str, jira_issue_type: str
+) -> None:
+    """
+    Sync issues from Jira into RegScale as issues
+    :param int regscale_id: ID # from RegScale to associate issues with
+    :param str regscale_module: RegScale module to associate issues with
+    :param str jira_project: Name of the project in Jira
+    :param str jira_issue_type: Type of issues to sync from Jira
+    :return: None
+    """
     app = check_license()
     api = Api(app)
     config = app.config
 
     # see if provided RegScale Module is an accepted option
     verify_provided_module(regscale_module)
 
@@ -95,16 +116,15 @@
 
     # make directory if it doesn't exist
     check_file_path("artifacts")
 
     # write issue data to a json file
     if len(issues_data) > 0:
         save_data_to(
-            file_name=f"artifacts{sep}existingRecordIssues",
-            file_type=".json",
+            file=Path("./artifacts/existingRecordIssues.json"),
             data=issues_data,
         )
         logger.info(
             "Writing out RegScale issue list for Record # %s to the artifacts folder (see existingRecordIssues.json).",
             regscale_id,
         )
     logger.info(
```

## regscale/integrations/commercial/okta.py

```diff
@@ -31,14 +31,15 @@
 from regscale.core.app.utils.threadhandler import create_threads, thread_assignment
 from regscale.models.app_models.click import file_types, save_output_to
 
 job_progress = create_progress_object()
 logger = create_logger()
 admin_users = []
 
+
 #####################################################################################################
 #
 # Okta Core API Documentation: https://developer.okta.com/docs/reference/core-okta-api/
 # Okta API Postman Collections: https://developer.okta.com/docs/reference/postman-collections/
 #
 #####################################################################################################
 
@@ -57,27 +58,97 @@
     required=True,
 )
 def authenticate(type: str):
     """
     Authenticate with Okta API by choosing SSWS or Bearer. SSWS is a security token created
     within Okta admin portal and Bearer token needs a private JWK from Okta Admin portal.
     """
-    # Get Status of Client Application
     app = check_license()
     api = Api(app)
     authenticate_with_okta(app, api, type)
 
 
 @okta.command(name="get_active_users")
 @save_output_to()
 @file_types([".csv", ".xlsx"])
 def get_active_users(save_output_to: Path, file_type: str):
     """
     Get active users from Okta API and save them to a .csv or .xlsx file.
     """
+    save_active_users_from_okta(save_output_to=save_output_to, file_type=file_type)
+
+
+@okta.command(name="get_inactive_users")
+@click.option(
+    "--days",
+    type=click.INT,
+    help="The number of days to see if a user hasn't logged in since, default is 30.",
+    default=30,
+    required=True,
+)
+@save_output_to()
+@file_types([".csv", ".xlsx"])
+def get_inactive_users(days: int, save_output_to: Path, file_type: str):
+    """
+    Get users that haven't logged in X days from Okta API and save the output as a .csv or .xlsx file.
+    """
+    save_inactive_users_from_okta(
+        days=days, save_output_to=save_output_to, file_type=file_type
+    )
+
+
+@okta.command(name="get_all_users")
+@save_output_to()
+@file_types([".csv", ".xlsx"])
+def get_all_users(save_output_to: Path, file_type: str):
+    """
+    Get All users from Okta API and save the output to a .csv or .xlsx file.
+    """
+    save_all_users_from_okta(save_output_to=save_output_to, file_type=file_type)
+
+
+@okta.command(name="get_new_users")
+@click.option(
+    "--days",
+    type=click.INT,
+    help="The number of days to see if a user has been added to Okta, default is 30",
+    default=30,
+    required=True,
+)
+@save_output_to()
+@file_types([".csv", ".xlsx"])
+def get_recent_users(days: int, save_output_to: Path, file_type: str):
+    """
+    Get users that were added to Okta in X days.
+    """
+    save_recently_added_users_from_okta(
+        days=days, save_output_to=save_output_to, file_type=file_type
+    )
+
+
+@okta.command(name="get_admin_users")
+@save_output_to()
+@file_types([".csv", ".xlsx"])
+def get_admin_users(save_output_to: Path, file_type: str) -> None:
+    """
+    Get all admin users from Okta API and save the output to .csv or .xlsx file.
+    """
+    save_admin_users_from_okta(save_output_to=save_output_to, file_type=file_type)
+
+
+def save_active_users_from_okta(save_output_to: Path, file_type: str = ".csv") -> None:
+    """
+    Function to get active users from Okta via API and save them to a .csv or .xlsx file
+    :param Path save_output_to: The path to save the output file to
+    :param str file_type: The file type to save the output file as, default is .csv, options are .csv or .xlsx
+    :return: None
+    """
+    if file_type.lower() not in [".csv", ".xlsx"]:
+        error_and_exit("Invalid file type. Please choose .csv or .xlsx.")
+
     # Get Status of Client Application
     app = check_license()
     api = Api(app)
 
     # check if RegScale token is valid:
     if is_valid(app=app):
         # get the token type from init.yaml
@@ -121,28 +192,28 @@
     # Notify user the RegScale token needs to be updated
     else:
         error_and_exit(
             "Login Error: Invalid RegScale credentials. Please log in for a new token."
         )
 
 
-@okta.command(name="get_inactive_users")
-@click.option(
-    "--days",
-    type=click.INT,
-    help="The number of days to see if a user hasn't logged in since, default is 30.",
-    default=30,
-    required=True,
-)
-@save_output_to()
-@file_types([".csv", ".xlsx"])
-def get_inactive_users(days: int, save_output_to: Path, file_type: str):
+def save_inactive_users_from_okta(
+    save_output_to: Path, file_type: str = ".csv", days: int = 30
+) -> None:
     """
-    Get users that haven't logged in X days from Okta API and save the output as a .csv or .xlsx file.
+    Function to get users that haven't logged in X days from Okta API
+    and saves the output as a .csv or .xlsx file.
+    :param Path save_output_to: The path to save the output file to
+    :param str file_type: The file type to save the output file as, defaults to .csv, options are .csv or .xlsx
+    :param int days: The number of days to check for inactive users
+    :return: None
     """
+    if file_type.lower() not in [".csv", ".xlsx"]:
+        error_and_exit("Invalid file type. Please choose .csv or .xlsx.")
+
     # Get Status of Client Application
     app = check_license()
     api = Api(app)
 
     # check if RegScale token is valid:
     if is_valid(app=app):
         # get the token type from init.yaml
@@ -181,21 +252,24 @@
     # Notify user the RegScale token needs to be updated
     else:
         error_and_exit(
             "Login Error: Invalid RegScale credentials. Please log in for a new token."
         )
 
 
-@okta.command(name="get_all_users")
-@save_output_to()
-@file_types([".csv", ".xlsx"])
-def get_all_users(save_output_to: Path, file_type: str):
+def save_all_users_from_okta(save_output_to: Path, file_type: str = ".csv") -> None:
     """
-    Get All users from Okta API and save the output to a .csv or .xlsx file.
+    Function to get all users from Okta via API and saves the output to a .csv or .xlsx file
+    :param Path save_output_to: The path to save the output file to
+    :param str file_type: The file type to save the output file as, defaults to .csv, options are .csv or .xlsx
+    :return: None
     """
+    if file_type.lower() not in [".csv", ".xlsx"]:
+        error_and_exit("Invalid file type. Please choose .csv or .xlsx.")
+
     # Get status of client application
     app = check_license()
     api = Api(app)
 
     # check if RegScale token is valid:
     if is_valid(app=app):
         # get the token type from init.yaml
@@ -221,28 +295,27 @@
     # Notify user the RegScale token needs to be updated
     else:
         error_and_exit(
             "Login Error: Invalid RegScale credentials. Please log in for a new token."
         )
 
 
-@okta.command(name="get_new_users")
-@click.option(
-    "--days",
-    type=click.INT,
-    help="The number of days to see if a user has been added to Okta, default is 30",
-    default=30,
-    required=True,
-)
-@save_output_to()
-@file_types([".csv", ".xlsx"])
-def get_recent_users(days: int, save_output_to: Path, file_type: str):
+def save_recently_added_users_from_okta(
+    save_output_to: Path, file_type: str = ".csv", days: int = 30
+) -> None:
     """
-    Get users that were added to Okta in X days.
+    Function to download users added in the last X days from Okta via API, defaults to last 30 days
+    and saves the output to a .csv or .xlsx file
+    :param Path save_output_to: The path to save the output file to
+    :param str file_type: The file type to save the output file as, .csv or .xlsx, defaults to .csv
+    :param int days: The number of days to check for recently added users, defaults to 30
+    :return: None
     """
+    if file_type.lower() not in [".csv", ".xlsx"]:
+        error_and_exit("Invalid file type. Please choose .csv or .xlsx.")
     # Get Status of Client Application
     app = check_license()
     api = Api(app)
 
     # check if RegScale token is valid:
     if is_valid(app=app):
         # get the token type from init.yaml
@@ -281,21 +354,24 @@
     # Notify user the RegScale token needs to be updated
     else:
         error_and_exit(
             "Login Error: Invalid RegScale credentials. Please log in for a new token."
         )
 
 
-@okta.command(name="get_admin_users")
-@save_output_to()
-@file_types([".csv", ".xlsx"])
-def get_admin_users(save_output_to: Path, file_type: str) -> None:
+def save_admin_users_from_okta(save_output_to: Path, file_type: str = ".csv") -> None:
     """
-    Get all admin users from Okta API and save the output to .csv or .xlsx file.
+    Function to get all admin users from Okta via API and save the output to .csv or .xlsx file
+    :param Path save_output_to: The path to save the output file to
+    :param str file_type: The file type to save the output file as, defaults to .csv, options are .csv or .xlsx
+    :return: None
     """
+    if file_type.lower() not in [".csv", ".xlsx"]:
+        error_and_exit("Invalid file type. Please choose .csv or .xlsx.")
+
     # Get Status of Client Application
     app = check_license()
     api = Api(app)
 
     # check if RegScale token is valid:
     if is_valid(app=app):
         # get the token type from init.yaml
@@ -483,16 +559,15 @@
             # create task for saving file
             saving_file_task = job_progress.add_task(
                 f"[#0866b4]Saving {len(clean_data)} {data_desc} to {file_path}/{file_name}{file_type}...",
                 total=1,
             )
             # save the output to the provided file_path
             save_data_to(
-                file_name=f"{file_path}/{file_name}",
-                file_type=file_type,
+                file=f"{file_path}/{file_name}{file_type}",
                 data=clean_data,
             )
             # mark saving_file_task as complete
             job_progress.update(saving_file_task, advance=1)
             logger.info(
                 "Saved %s %s successfully to %s%s!",
                 len(clean_data),
@@ -667,14 +742,18 @@
             }
             config["oktaScopes"] = "okta.users.read okta.roles.read"
             app.save_config(config)
             logger.info(
                 "Please enter the private key for the application created in Okta admin"
                 + "portal into init.yaml file and try again."
             )
+    else:
+        error_and_exit(
+            "Please enter a valid authentication type for Okta API and try again. Please choose from SSWS or Bearer."
+        )
 
 
 def get_okta_token(config: dict, api: Api, app) -> str:
     """
     Function to create a JWT to get a bearer token from Okta via API
     :param dict config: Application configuration (init.yaml)
     :param Api api: API object
@@ -697,15 +776,15 @@
         "iss": config["oktaClientId"],
         "sub": config["oktaClientId"],
         "exp": int(time.time()) + 600,
     }
 
     # create a signed JWT
     token = python_jwt.generate_jwt(
-        payload_data, jwk_token, "RS256", datetime.timedelta(minutes=5)
+        payload_data, jwk_token, "RS256", timedelta(minutes=5)
     )
 
     # set the headers for the API call
     headers = {
         "Accept": "application/json",
         "Content-Type": "application/x-www-form-urlencoded",
     }
```

## regscale/integrations/commercial/qualys.py

```diff
@@ -1,25 +1,25 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """ Integrates Qualys assets and vulnerabilities into RegScale CLI """
 
 # standard python imports
 import dataclasses
 import os
+import pprint
 from dataclasses import asdict
 from datetime import datetime, timedelta
 from json import JSONDecodeError
 from pathlib import Path
 from typing import Optional, Union
 
 import click
 import requests
 import xmltodict
 from requests import Session
-from rich.console import Console
 
 from regscale.core.app.api import Api
 from regscale.core.app.logz import create_logger
 from regscale.core.app.utils.app_utils import (
     check_file_path,
     check_license,
     create_progress_object,
@@ -37,15 +37,14 @@
 # Qualys API Documentation:
 #   https://qualysguard.qg2.apps.qualys.com/qwebhelp/fo_portal/api_doc/index.htm
 #
 ####################################################################################################
 
 
 # create global variables for the entire module
-console = Console()
 logger = create_logger()
 
 # create progress object to add tasks to for real time updates
 job_progress = create_progress_object()
 HEADERS = {"X-Requested-With": "RegScale CLI"}
 QUALYS_API = Session()
 
@@ -60,65 +59,44 @@
 @save_output_to()
 @click.option(
     "--days",
     type=int,
     default=30,
     help="The number of days to go back for completed scans, default is 30.",
 )
+@click.option(
+    "--export",
+    type=click.BOOL,
+    help="To disable saving the scans as a .json file, use False. Defaults to True.",
+    default=True,
+    prompt=False,
+    required=False,
+)
 def export_past_scans(save_output_to: Path, days: int, export: bool = True):
     """Export scans from Qualys Host that were completed
     in the last x days, defaults to last 30 days
     and defaults to save it as a .json file"""
-    # see if user has enterprise license
-    check_license()
-    date = get_current_datetime("%Y%m%d")
-    results = get_detailed_scans(days)
-    if export:
-        check_file_path(save_output_to)
-        save_data_to(
-            file_name=f"{save_output_to.name}{os.sep}qualys_scans_{date}",
-            file_type=".json",
-            data=results,
-        )
+    export_scans(
+        save_output_to=save_output_to,
+        days=days,
+        export=export,
+    )
 
 
 @qualys.command(name="save_results")
 @save_output_to()
 @click.option(
     "--scan_id",
     type=click.STRING,
     help="Qualys scan reference ID to get results, defaults to all.",
     default="all",
 )
-def save_queries(save_output_to: Path, scan_id: str):
+def save_results(save_output_to: Path, scan_id: str):
     """Get scan results from Qualys using a scan ID or all scans and save them to a .json file."""
-    # see if user has enterprise license
-    check_license()
-
-    check_file_path(save_output_to)
-    with job_progress:
-        if scan_id.lower() == "all":
-            # get all the scan results from Qualys
-            scans = get_scans_summary("all")
-
-            # add task to job progress to let user know # of scans to fetch
-            task1 = job_progress.add_task(
-                f"[#f8b737]Getting scan results for {len(scans['SCAN'])} scan(s)...",
-                total=len(scans["SCAN"]),
-            )
-            # get the scan results from Qualys
-            scan_data = get_scan_results(scans, task1)
-        else:
-            task1 = job_progress.add_task(
-                f"[#f8b737]Getting scan results for {scan_id}...", total=1
-            )
-            # get the scan result for the provided scan id
-            scan_data = get_scan_results(scan_id, task1)
-    # save the scan_data as the provided file_path
-    save_data_to(file_name=save_output_to.name, file_type=".json", data=scan_data)
+    save_scan_results_by_id(save_output_to=save_output_to, scan_id=scan_id)
 
 
 @qualys.command(name="sync_qualys")
 @click.option(
     "--regscale_ssp_id",
     type=click.INT,
     required=True,
@@ -154,14 +132,113 @@
     asset_group_id: int = None,
     asset_group_name: str = None,
 ):
     """
     Query Qualys and sync assets & their associated
     vulnerabilities to a Security Plan in RegScale.
     """
+    sync_qualys_to_regscale(
+        regscale_ssp_id=regscale_ssp_id,
+        create_issue=create_issue,
+        asset_group_id=asset_group_id,
+        asset_group_name=asset_group_name,
+    )
+
+
+@qualys.command(name="get_asset_groups")
+@save_output_to()
+def get_asset_groups(save_output_to: Path):
+    """
+    Get all asset groups from Qualys via API and save them to a .json file.
+    """
+    # see if user has enterprise license
+    check_license()
+
+    date = get_current_datetime("%Y%m%d")
+    check_file_path(save_output_to)
+    asset_groups = get_asset_groups_from_qualys()
+    save_data_to(
+        file=Path(f"{save_output_to}/qualys_asset_groups_{date}.json"),
+        data=asset_groups,
+    )
+
+
+def export_scans(
+    save_output_to: Path,
+    days: int = 30,
+    export: bool = True,
+) -> None:
+    """
+    Function to export scans from Qualys that were completed in the last x days, defaults to 30
+    :param Path save_output_to: Path to save the scans to as a .json file
+    :param int days: # of days of completed scans to export, defaults to 30 days
+    :param bool export: Whether to save the scan data as a .json, defaults to True
+    :return: None
+    """
+    # see if user has enterprise license
+    check_license()
+    date = get_current_datetime("%Y%m%d")
+    results = get_detailed_scans(days)
+    if export:
+        check_file_path(save_output_to)
+        save_data_to(
+            file=Path(f"{save_output_to.name}/qualys_scans_{date}.json"),
+            data=results,
+        )
+    else:
+        pprint(results)
+
+
+def save_scan_results_by_id(save_output_to: Path, scan_id: str):
+    """
+    Function to save the queries from Qualys using an ID a .json file
+    :param Path save_output_to: Path to save the scan results to as a .json file
+    :param int scan_id: Qualys scan ID to get the results for
+    :return: None
+    """
+    # see if user has enterprise license
+    check_license()
+
+    check_file_path(save_output_to)
+    with job_progress:
+        if scan_id.lower() == "all":
+            # get all the scan results from Qualys
+            scans = get_scans_summary("all")
+
+            # add task to job progress to let user know # of scans to fetch
+            task1 = job_progress.add_task(
+                f"[#f8b737]Getting scan results for {len(scans['SCAN'])} scan(s)...",
+                total=len(scans["SCAN"]),
+            )
+            # get the scan results from Qualys
+            scan_data = get_scan_results(scans, task1)
+        else:
+            task1 = job_progress.add_task(
+                f"[#f8b737]Getting scan results for {scan_id}...", total=1
+            )
+            # get the scan result for the provided scan id
+            scan_data = get_scan_results(scan_id, task1)
+    # save the scan_data as the provided file_path
+    save_data_to(file=save_output_to, data=scan_data)
+
+
+def sync_qualys_to_regscale(
+    regscale_ssp_id: int,
+    create_issue: bool = False,
+    asset_group_id: int = None,
+    asset_group_name: str = None,
+) -> None:
+    """
+    Sync Qualys assets and vulnerabilities to a security plan in RegScale
+    :param int regscale_ssp_id: ID # of the SSP in RegScale
+    :param bool create_issue: Flag whether to create an issue in RegScale from Qualys vulnerabilities, defaults to False
+    :param int asset_group_id: Optional filter for assets in Qualys with an asset group ID, defaults to None
+    :param str asset_group_name: Optional filter for assets in Qualys with an asset group name, defaults to None
+    :return: None
+    """
     # see if user has enterprise license
     check_license()
 
     # check if the user provided an asset group id or name
     if asset_group_id:
         # get the assets from Qualys using the group name
         sync_qualys_assets_and_vulns(
@@ -176,33 +253,14 @@
             create_issue=create_issue,
             asset_group_filter=asset_group_id,
         )
     else:
         sync_qualys_assets_and_vulns(ssp_id=regscale_ssp_id, create_issue=create_issue)
 
 
-@qualys.command(name="get_asset_groups")
-@save_output_to()
-def get_asset_groups(save_output_to: Path):
-    """
-    Get all asset groups from Qualys via API and save them to a .json file.
-    """
-    # see if user has enterprise license
-    check_license()
-
-    date = get_current_datetime("%Y%m%d")
-    check_file_path(save_output_to)
-    asset_groups = get_asset_groups_from_qualys()
-    save_data_to(
-        file_name=f"{save_output_to}{os.sep}qualys_asset_groups_{date}",
-        file_type=".json",
-        data=asset_groups,
-    )
-
-
 def get_scan_results(scans: any, task) -> dict:
     """
     Function to retrieve scan results from Qualys using provided scan list and returns a dictionary
     :param any scans: list of scans to retrieve from Qualys
     :param task: task to update in the progress object
     :return: dictionary of detailed Qualys scans
     :rtype: dict
```

## regscale/integrations/commercial/servicenow.py

```diff
@@ -2,15 +2,15 @@
 # -*- coding: utf-8 -*-
 """ Integration of ServiceNow into RegScale CLI tool """
 
 # standard python imports
 import sys
 from copy import deepcopy
 from json import JSONDecodeError
-from os import sep
+from pathlib import Path
 from typing import Tuple
 
 import click
 import requests
 from rich.progress import track
 
 from regscale.core.app.api import Api
@@ -63,14 +63,42 @@
 def issues(
     regscale_id: int,
     regscale_module: str,
     snow_assignment_group: str,
     snow_incident_type: str,
 ):
     """Process issues to ServiceNow."""
+    sync_snow_to_regscale(
+        regscale_id=regscale_id,
+        regscale_module=regscale_module,
+        snow_assignment_group=snow_assignment_group,
+        snow_incident_type=snow_incident_type,
+    )
+
+
+@servicenow.command(name="sync_work_notes")
+def sync_work_notes():
+    """Sync work notes from ServiceNow to existing issues."""
+    sync_notes_to_regscale()
+
+
+def sync_snow_to_regscale(
+    regscale_id: int,
+    regscale_module: str,
+    snow_assignment_group: str,
+    snow_incident_type: str,
+) -> None:
+    """
+    Sync issues from ServiceNow to RegScale via API
+    :param int regscale_id: ID # of record in RegScale to associate issues with
+    :param str regscale_module: RegScale module to associate issues with
+    :param str snow_assignment_group: Snow assignment group to filter for
+    :param str snow_incident_type: Snow incident type to filter for
+    :return: None
+    """
     # initialize variables
     app = Application()
     reg_api = Api(app)
     logger = create_logger()
 
     # see if provided RegScale Module is an accepted option
     verify_provided_module(regscale_module)
@@ -105,16 +133,15 @@
             error_and_exit(f"Unable to fetch issues from RegScale.\n{rex}")
     # make directory if it doesn't exist
     check_file_path("artifacts")
 
     # write out issues data to file
     if len(issues_data) > 0:
         save_data_to(
-            file_name=f"artifacts{sep}existingRecordIssues",
-            file_type=".json",
+            file=Path("./artifacts/existingRecordIssues.json"),
             data=issues_data,
         )
         logger.info(
             "Writing out RegScale issue list for Record # %s to the artifacts folder (see existingRecordIssues.json).",
             regscale_id,
         )
     logger.info(
@@ -202,20 +229,14 @@
         except KeyError as kex:
             logger.error("Unable to find key: %s.", kex)
 
     # output the final result
     logger.info("%i new issue incidents opened in ServiceNow.", int_new)
 
 
-@servicenow.command(name="sync_work_notes")
-def sync_work_notes():
-    """Sync work notes from ServiceNow to existing issues."""
-    sync_notes_to_regscale()
-
-
 def sync_notes_to_regscale() -> None:
     """
     Sync work notes from ServiceNow to existing issues
     :return: None
     """
     app = Application()
     reg_api = Api(app)
```

## regscale/integrations/commercial/tenable.py

```diff
@@ -75,16 +75,15 @@
     check_file_path(save_output_to)
 
     # set the file name
     file_name = f"tenable_scans_{get_current_datetime('%m%d%Y')}"
 
     # save the data as the selected file by the user
     save_data_to(
-        file_name=f"{save_output_to}{os.sep}{file_name}",
-        file_type=file_type,
+        file=Path(f"{save_output_to}/{file_name}{file_type}"),
         data=results,
     )
 
 
 def get_usable_scan_list() -> list:
     """
     Usable Scans from Tenable Host
@@ -131,16 +130,15 @@
     check_file_path(save_output_to)
 
     # set the file name
     file_name = f"tenable_queries_{get_current_datetime('%m%d%Y')}"
 
     # save the data as a .json file
     save_data_to(
-        file_name=f"{save_output_to}{os.sep}{file_name}",
-        file_type=file_type,
+        file=Path(f"{save_output_to}{os.sep}{file_name}{file_type}"),
         data=query_list,
     )
 
 
 def get_queries() -> None:
     """
     List of query definitions
```

## Comparing `RegScale_CLI-5.3.1.dist-info/LICENSE` & `RegScale_CLI-5.4.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `RegScale_CLI-5.3.1.dist-info/METADATA` & `RegScale_CLI-5.4.0.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: RegScale-CLI
-Version: 5.3.1
+Version: 5.4.0
 Summary: Command Line Interface (CLI) for bulk processing/loading data into RegScale
 Home-page: https://github.com/RegScale/regscale-cli
 Author: Travis Howerton
 Author-email: thowerton@regscale.com
 License: MIT
 Platform: UNKNOWN
 Classifier: Operating System :: OS Independent
@@ -31,19 +31,20 @@
 Requires-Dist: numpy (==1.23.3)
 Requires-Dist: openpyxl
 Requires-Dist: pandas
 Requires-Dist: pdfplumber (==0.7.6)
 Requires-Dist: pre-commit
 Requires-Dist: pyTenable
 Requires-Dist: pyaml (==21.10.1)
+Requires-Dist: pydantic
 Requires-Dist: pytest
 Requires-Dist: python-docx
 Requires-Dist: python-jwt (==4.0.0)
 Requires-Dist: regscale-python-ssp
-Requires-Dist: requests (==2.28.2)
+Requires-Dist: requests (==2.31.0)
 Requires-Dist: rich (==13.3.4)
 Requires-Dist: setuptools
 Requires-Dist: static
 Requires-Dist: tools
 Requires-Dist: wheel
 Requires-Dist: xmltodict
 Provides-Extra: airflow
```

## Comparing `RegScale_CLI-5.3.1.dist-info/RECORD` & `RegScale_CLI-5.4.0.dist-info/RECORD`

 * *Files 16% similar despite different names*

```diff
@@ -1,58 +1,67 @@
-regscale/__init__.py,sha256=XehO8pb4GklFJT4padrwyHGgMITY1M6KU3ARht53Mw4,22
+regscale/__init__.py,sha256=xjYaBGUFGg0kGZj_WhuoFyPD8NILPsr79SaMwmYQGSg,22
 regscale/regscale.py,sha256=GbKkPYlIJ06JH--hhrh7VKRpWARYe9IwwJu01Je2l68,15147
 regscale/airflow/__init__.py,sha256=yMwN0Bz4JbM0nl5qY_hPegxo_O2ilhTOL9PY5Njhn-s,270
+regscale/airflow/tasks/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+regscale/airflow/tasks/cli.py,sha256=bsrFOtiHMqK661LG4IwJ0Yxq1T0tk2I14Y9UQpLO76w,3308
 regscale/ansible/__init__.py,sha256=DZmNktNFs5ilDX8vbYdxdjFADjyWZhawWuLk8O27CNM,262
 regscale/core/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+regscale/core/login.py,sha256=vpiEvWz31PgSLvOrNM9QQ3MfqWlJsGdx9jFdYcN9Dj4,1553
 regscale/core/app/__init__.py,sha256=8gm8M1aKTdDNsiBLrWXNKURK3DUThg52FEkZcCEELgM,129
 regscale/core/app/api.py,sha256=i0QyB2418p5zoagOmLAumMFFlzatmzDGlMkhUA3yIWw,14666
 regscale/core/app/application.py,sha256=Zkl-8BPnrMT8xTD2x-MP7rintgKXB4TybrnP-6juoWQ,13607
 regscale/core/app/logz.py,sha256=r16p4XjTEpjB069vYDtwq2Asq7B-ivPK-1b9N1VdEp4,1145
 regscale/core/app/internal/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-regscale/core/app/internal/admin_actions.py,sha256=zON_aIWVvmfqaa-U-CQQtt3MSUbsSFHznVflZpx2XJk,27117
+regscale/core/app/internal/admin_actions.py,sha256=CSALLdTlqF_Gy9W2f-cTTZmd42uKX0ljofr7h10HC1I,27214
 regscale/core/app/internal/assessments_editor.py,sha256=rjFOLtgacdWawEOrRw69bnIY1Cc3NTROf3qpSc-WWpk,31088
 regscale/core/app/internal/catalog.py,sha256=S_bKw6X3G9EG2--gz8WDBAN0iILCBHWlq7_sONx2nLA,979
-regscale/core/app/internal/comparison.py,sha256=wy8ljEbcOx_kIzo1qUJA1xGwdXpXGUdpmTkO1Fc_ZWk,16188
+regscale/core/app/internal/comparison.py,sha256=hYHgLY5f4bc9aOZ7uE2tDAnCvRRRSQaW6lgZpMFa-8I,16694
 regscale/core/app/internal/control_editor.py,sha256=7Q9ptoxrrZcTsU0ETtBL54-1Q1vggfc_eyH9k0N3qPk,15364
 regscale/core/app/internal/encrypt.py,sha256=CRfWU0hTiirBdz8Ff7khaIasOmCR8CQ3Dmff7o1gjUo,5948
 regscale/core/app/internal/evidence.py,sha256=uHfoGmJ7ao4iuGEtVBNVpnot588TU9v1-3cimMeC-sI,40204
 regscale/core/app/internal/healthcheck.py,sha256=0Il1Wa70BKhKBA2VVANFQBD-2PMDEpFzRtYdB0Kj7D0,2367
 regscale/core/app/internal/login.py,sha256=W4jzkQW1yF8hseyIoPNdTDKPcARoZ05dlX3iG4fB0wU,6513
-regscale/core/app/internal/migrations.py,sha256=jAgplqsd2g7cJVtQl7i4t6qXROkFN3gPbz3aWjk60vg,8815
+regscale/core/app/internal/migrations.py,sha256=cBpn5lKN_c8u6O0iLKXtjee70QJGiuc06mw_XwH6Mdo,9712
 regscale/core/app/public/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-regscale/core/app/public/emass.py,sha256=z6nWUV5Hvq52zvL0CniEdE7WW0livvl0te6EGzpLYlE,11234
+regscale/core/app/public/emass.py,sha256=g2UHEVKHkPjhsqYsltXgThhBcC3jZcxL5B1i_VDIaTQ,11879
 regscale/core/app/public/fedramp.py,sha256=-EpBY238tiMoZFRLuC5Tg-I5UBodbQVak-k5DlJHol4,62097
-regscale/core/app/public/nist_catalog.py,sha256=TD9ohsmNCLiBAXzzZyk-j8WcXQQfuJXmmrIVXc7V_Nk,8996
-regscale/core/app/public/oscal.py,sha256=xlc4HJ0tmv-yXG21fvJdLTCu28tDwgqIIylOfjNVjXE,87595
+regscale/core/app/public/nist_catalog.py,sha256=B5UjKEuEE3BiXMfrAbYVsHwVpoMj4a5q5OLhFcoSRHQ,9000
+regscale/core/app/public/oscal.py,sha256=lSnoEoC4aKDneNs2Ck57tgYFlzilM_fAZuvRVgoOCv0,87151
 regscale/core/app/public/otx.py,sha256=fI9WPeeai2f4Hix5R3gk6uGnD3o1pIrt8Is9zySZk_8,6125
 regscale/core/app/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-regscale/core/app/utils/app_utils.py,sha256=W4me48RA4FFLohJlKKR0hXC-boOu3qvN9TYY9Jepef8,23417
+regscale/core/app/utils/app_utils.py,sha256=nlXf62UjhVtoxBK7-FzEeu-oRqZLJBPzFqXNck-2dpc,23177
 regscale/core/app/utils/regscale_utils.py,sha256=f8DPbnxpgqA4MGl5h4l-gtkSqCR4pMVgS4lu_Qzq_eo,10613
 regscale/core/app/utils/threadhandler.py,sha256=1CTYikH-HeeGMhfxhqhVcmCUaBrJiAXQInNUI5iEHDc,1605
 regscale/core/app/utils/catalog_utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/core/app/utils/catalog_utils/compare_catalog.py,sha256=gvDI1tO8AxcyVx4umI9ABQ61nvlmmYBkHaMxCBJZdQM,9213
 regscale/core/app/utils/catalog_utils/diagnostic_catalog.py,sha256=_dwKLGICKNcz6aOsku9wetRN7KK6k8-N0UwzlIgnvEI,4467
-regscale/core/app/utils/catalog_utils/export_catalog.py,sha256=e3HzmQCebMKhMLepYTKn4eNUCVgGCrIX3Z3OoZUy7yM,2723
+regscale/core/app/utils/catalog_utils/export_catalog.py,sha256=QO3x8L5qFs0S5HNxCgbSawQY6-k30VrZwNeN3Dgl0Sc,2727
+regscale/core/static/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+regscale/core/static/regex.py,sha256=Nf0aiAvBxzFWC96Bk2dZYby-y7KrFAVjI3f6I599UIU,383
+regscale/core/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+regscale/core/utils/urls.py,sha256=eQeicRFAap1Z91-ATY1dGG_gJ1g-ChQ9WW2Tj7NV1Fc,583
 regscale/exceptions/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/exceptions/license_exception.py,sha256=5lDYW1uGf7dHFKBkhzYD3FlNnI6W4BICXi24OJyOs_w,195
 regscale/integrations/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/integrations/commercial/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-regscale/integrations/commercial/ad.py,sha256=wjQnaGw1jZwoTUKcdXqX0F-LT4LDbs5UFIJFgf7bn0M,16420
+regscale/integrations/commercial/ad.py,sha256=0j1M_P2jaKMo7rW_3P8IoUe0WmYHV6AKTbpWbYrK2J8,16252
 regscale/integrations/commercial/aws.py,sha256=ScvgZ3ZlEM-U0PDcNfN2bj084cnPDguCnRcVqog1S4s,12972
 regscale/integrations/commercial/defender.py,sha256=P2nqaRTRu78Hha2q-SGjd9dBfH_2mUEr2PrBiDG1moE,46871
-regscale/integrations/commercial/jira.py,sha256=4ukU9MnlWwPnTMpRO7HQ-KI0G5GwLW2qPYmN3y_G7sE,8069
-regscale/integrations/commercial/okta.py,sha256=odEAnhttuG5v7I8fPlUksS52ET_org1YgOvjTyCAWAc,27319
-regscale/integrations/commercial/qualys.py,sha256=u5gf5W7yg7ZhXbZ1NotOCaRPLujnNfEsmI9SkUVULGI,29643
-regscale/integrations/commercial/servicenow.py,sha256=h560RRreWQqC7N83giAt9oRYyKe45Rijgkg17UoFlq4,11751
+regscale/integrations/commercial/jira.py,sha256=YEzu7tg17fDhFYMiIxup6dhQGod1yHDcns8P0GKaaPo,8720
+regscale/integrations/commercial/okta.py,sha256=f1vf05y9qhnblDBc9S1-pVPttUDPNKFzQUJVfAj-RjM,30770
+regscale/integrations/commercial/qualys.py,sha256=USA7ZZKIxH53jd9y1jpuumZeWr55EkC47v60IIA5cMc,31580
+regscale/integrations/commercial/servicenow.py,sha256=Hvn285cputK1YKsGMzmV16BsF5s96mezUe0Mq3V_39Y,12466
 regscale/integrations/commercial/stig.py,sha256=uyglxn_8Lspgxj15hXXxPH3jRpBzEOGEyxenhjh1NVk,63112
-regscale/integrations/commercial/tenable.py,sha256=GR4H5fW4eQvY8lKg-bdj99vQ4YAPrqXNyvKAKAcJgn0,22771
+regscale/integrations/commercial/tenable.py,sha256=-TfDJbYRGunfBFuwCJ5sU1Gtizd0gCM_63T-FIGgA3Y,22730
 regscale/integrations/commercial/wiz.py,sha256=GnsO_AywDz8--p5umHoAi-P1hlSD_q-F2JrurP0t_eE,62395
 regscale/integrations/public/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/integrations/public/cisa.py,sha256=EkiCrxrPIQmyayDwPxS3RMGkJxWyUOcgOwiE2gYGXks,18680
 regscale/models/__init__.py,sha256=I8g3yVQOgPLH_d3UWwHPpwrnfDoHG-VW2S0k4lmkz3o,153
+regscale/models/config.py,sha256=fnF6tTd5DX88VcsKQpMWd3WVDqkLfkOCATnqziJZYjA,4865
+regscale/models/platform.py,sha256=0HCSqXc9JwKdzlO37vJs252ucGzfZEyKI50rnXEGxT4,3453
 regscale/models/app_models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/models/app_models/catalog_compare.py,sha256=l9zI6f0oV2igEoOQU9RpMLriYi7XZng6UR7UcsMyx7k,7553
 regscale/models/app_models/click.py,sha256=JgWwakrKTs2x9cUUMExMma1ag1HBXJbkCMvpZ1mDM40,4006
 regscale/models/app_models/control_editor.py,sha256=g8iHaawU-XstzuZQO0wGp4I4Jx5U199r4OAD6xEpqfE,13918
 regscale/models/app_models/pipeline.py,sha256=13BuBreZESL7SP7ajCFXy8bgaEchTnyGlaRtUMBl0bM,889
 regscale/models/integration_models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/models/integration_models/azure_alerts.py,sha256=I_jcjaLMsQpgabkdtVbalGZ23GeAH8aQCmH9iXlKFhw,7858
@@ -75,19 +84,28 @@
 regscale/models/regscale_models/ports_protocols.py,sha256=qupVuXfeNXxMBW8EviLDgtBJc3id9YvxfcJibHpjojo,2353
 regscale/models/regscale_models/requirements.py,sha256=8EkEUrKKJYb8zC8o_79eoYfpXh97MX4t7zgp8Qz276c,2415
 regscale/models/regscale_models/security_control.py,sha256=EQSiWKCkRMIx03a5OMkIAcyTLebK3Tdjh_b-pQc8QaA,5524
 regscale/models/regscale_models/securityplans.py,sha256=YFoVnigaarEVOQhASTdrOm1BqWELso6EEzk1ytVs4ds,5886
 regscale/models/regscale_models/stig.py,sha256=Y_wGvPJLBD2AOIZ4ff0wmDAx0k7z_-G5Y0kPdUKvVLs,26139
 regscale/models/regscale_models/threat.py,sha256=eRO_tPT4pOTJvMGYAQ9bU7QHs2HnFBLiIWY8Jyu1pQk,1425
 regscale/models/regscale_models/user.py,sha256=mm-1ajFmCFzDeHDAydcANdQMIBehfCRhjWCCoMKZXFY,2242
+regscale/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+regscale/utils/shell.py,sha256=mbZSIF8OPf7w-AnXOUybC6Bnoe0Z_crHkzsljgMEJ44,3893
+regscale/utils/string.py,sha256=l_vlT4_4yrnqoIv4M4kFxhVN73nlkOEyDccxVqE4Pqo,48
 regscale/validation/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 regscale/validation/address.py,sha256=zJnIY7CnM1ZkSlflY1Drk40xjNJKob__QWXlE_ZTmR8,422
 tests/mocks/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tests/mocks/objects.py,sha256=KfCpzXpwWl-3zCLihQ3ZrQONW8Jk7F4UbcAgPz2LnnQ,99
 tests/mocks/response.py,sha256=uupSrzyb8Zs6Cuje5DZPlvLMEpb3R0h6SOx_o7TzZzk,1039
 tests/mocks/xml.py,sha256=ANUjXOyT8KidrqpidmfoOuy9jwi6zjsoy-BUY2Pxep8,260
-RegScale_CLI-5.3.1.dist-info/LICENSE,sha256=ytNhYQ9Rmhj_m-EX2pPq9Ld6tH5wrqqDYg-fCf46WDU,1076
-RegScale_CLI-5.3.1.dist-info/METADATA,sha256=JFCuR35gfC5c5kzOnti9_2izibQaMwJLuD32JjM-BCU,6611
-RegScale_CLI-5.3.1.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-RegScale_CLI-5.3.1.dist-info/entry_points.txt,sha256=zrr7q-ywNBiOJZfZyKIzCdLzeF94lsnbweTQWj8VG-Y,52
-RegScale_CLI-5.3.1.dist-info/top_level.txt,sha256=cYezFj4wbGuaRuyLPNikMoIZf0jEgEIfTfLRVvC9bEs,26
-RegScale_CLI-5.3.1.dist-info/RECORD,,
+tests/regscale/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+tests/regscale/core/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+tests/regscale/core/test_login.py,sha256=VRSV22SXqORduZy-zKMhlXF_3rbO_MOuQpEjRcUghpQ,1172
+tests/regscale/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+tests/regscale/models/test_config.py,sha256=IheTP4zxZqGaBJ7n0_fU5tgtbdX-VXyEe4jTUHoXZAo,810
+tests/regscale/models/test_platform.py,sha256=FPU74dye7gxl-VjFkiXpz3lcBxUQeCEgiU-xghSdXAE,856
+RegScale_CLI-5.4.0.dist-info/LICENSE,sha256=ytNhYQ9Rmhj_m-EX2pPq9Ld6tH5wrqqDYg-fCf46WDU,1076
+RegScale_CLI-5.4.0.dist-info/METADATA,sha256=2e67K-FK3q3fLAhzRnD0maNueXwAjtdLLo8jq1Q2-pM,6635
+RegScale_CLI-5.4.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+RegScale_CLI-5.4.0.dist-info/entry_points.txt,sha256=zrr7q-ywNBiOJZfZyKIzCdLzeF94lsnbweTQWj8VG-Y,52
+RegScale_CLI-5.4.0.dist-info/top_level.txt,sha256=cYezFj4wbGuaRuyLPNikMoIZf0jEgEIfTfLRVvC9bEs,26
+RegScale_CLI-5.4.0.dist-info/RECORD,,
```

